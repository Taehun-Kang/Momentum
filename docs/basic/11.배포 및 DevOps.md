# ë°°í¬ ë° DevOps (Deployment & DevOps)

## 11.1 Railway ë°°í¬ ì„¤ì •

### 11.1.1 í”„ë¡œì íŠ¸ ì„¤ì •

### Railway í”„ë¡œì íŠ¸ ì´ˆê¸°í™”

```bash
# Railway CLI ì„¤ì¹˜
npm install -g @railway/cli

# Railway ë¡œê·¸ì¸
railway login

# ìƒˆ í”„ë¡œì íŠ¸ ìƒì„±
railway init youtube-shorts-curator

# í™˜ê²½ ì„¤ì •
railway link

```

### Railway ì„¤ì • íŒŒì¼ (railway.json)

```json
{
  "$schema": "https://railway.app/railway.schema.json",
  "build": {
    "builder": "NIXPACKS",
    "buildCommand": "npm ci && npm run build",
    "watchPatterns": [
      "backend/**",
      "frontend/**"
    ]
  },
  "deploy": {
    "numReplicas": 2,
    "startCommand": "npm run start:prod",
    "healthcheckPath": "/health",
    "healthcheckTimeout": 30,
    "restartPolicyType": "ON_FAILURE",
    "restartPolicyMaxRetries": 3
  },
  "environments": {
    "production": {
      "build": {
        "NODE_ENV": "production"
      }
    },
    "staging": {
      "build": {
        "NODE_ENV": "staging"
      }
    }
  }
}

```

### ë©€í‹° ì„œë¹„ìŠ¤ êµ¬ì„±

```yaml
# railway.yml - ì„œë¹„ìŠ¤ ì •ì˜
version: 1

services:
  # ë°±ì—”ë“œ API ì„œë²„
  backend:
    source:
      repo: .
      branch: main
      dir: backend
    build:
      builder: NIXPACKS
      buildCommand: npm ci && npm run build
    deploy:
      startCommand: npm run start
      numReplicas: 2
      region: us-west1
      healthcheckPath: /api/health
      env:
        - NODE_ENV=production
        - PORT=${{RAILWAY_PORT}}

  # í”„ë¡ íŠ¸ì—”ë“œ ì •ì  íŒŒì¼ ì„œë²„
  frontend:
    source:
      repo: .
      branch: main
      dir: frontend
    build:
      builder: NIXPACKS
      buildCommand: npm ci && npm run build
    deploy:
      startCommand: npx serve -s dist -l $PORT
      numReplicas: 1
      region: us-west1

  # Redis ìºì‹œ
  redis:
    image: redis:7-alpine
    volumes:
      - redis_data:/data
    deploy:
      numReplicas: 1
      command: redis-server --appendonly yes --requirepass $REDIS_PASSWORD

  # ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì›Œì»¤
  worker:
    source:
      repo: .
      branch: main
      dir: backend
    build:
      builder: NIXPACKS
      buildCommand: npm ci
    deploy:
      startCommand: npm run worker
      numReplicas: 1
      env:
        - NODE_ENV=production

volumes:
  redis_data:

```

### 11.1.2 í™˜ê²½ë³€ìˆ˜ ê´€ë¦¬

### Railway í™˜ê²½ë³€ìˆ˜ ì„¤ì • ìŠ¤í¬ë¦½íŠ¸

```jsx
// scripts/setup-railway-env.js
const { execSync } = require('child_process');
const fs = require('fs');
const path = require('path');

class RailwayEnvManager {
  constructor() {
    this.envFile = path.join(__dirname, '../.env.production');
    this.secrets = this.loadSecrets();
  }

  // .env íŒŒì¼ ë¡œë“œ
  loadSecrets() {
    if (!fs.existsSync(this.envFile)) {
      console.error('.env.production file not found');
      process.exit(1);
    }

    const envContent = fs.readFileSync(this.envFile, 'utf8');
    const secrets = {};

    envContent.split('\n').forEach(line => {
      const [key, value] = line.split('=');
      if (key && value) {
        secrets[key.trim()] = value.trim();
      }
    });

    return secrets;
  }

  // Railwayì— í™˜ê²½ë³€ìˆ˜ ì„¤ì •
  setEnvironmentVariables() {
    const requiredVars = [
      'NODE_ENV',
      'SUPABASE_URL',
      'SUPABASE_ANON_KEY',
      'SUPABASE_SERVICE_ROLE_KEY',
      'YOUTUBE_API_KEY',
      'CLAUDE_API_KEY',
      'JWT_SECRET',
      'ENCRYPTION_KEY',
      'REDIS_URL',
      'REDIS_PASSWORD',
      'SESSION_SECRET',
      'ALLOWED_ORIGINS',
      'SENTRY_DSN',
      'SLACK_WEBHOOK_URL'
    ];

    console.log('Setting Railway environment variables...');

    requiredVars.forEach(varName => {
      if (!this.secrets[varName]) {
        console.warn(`Warning: ${varName} not found in .env file`);
        return;
      }

      try {
        execSync(`railway variables set ${varName}="${this.secrets[varName]}"`, {
          stdio: 'inherit'
        });
        console.log(`âœ“ Set ${varName}`);
      } catch (error) {
        console.error(`âœ— Failed to set ${varName}:`, error.message);
      }
    });

    console.log('\nEnvironment variables setup complete!');
  }

  // í™˜ê²½ë³€ìˆ˜ ê²€ì¦
  validateEnvironment() {
    console.log('\nValidating Railway environment...');

    try {
      const output = execSync('railway variables', { encoding: 'utf8' });
      const deployedVars = output.split('\n').map(line => line.split('=')[0].trim());

      const missing = [];
      Object.keys(this.secrets).forEach(key => {
        if (!deployedVars.includes(key)) {
          missing.push(key);
        }
      });

      if (missing.length > 0) {
        console.warn('\nMissing variables:', missing.join(', '));
      } else {
        console.log('\nâœ“ All environment variables are set correctly');
      }
    } catch (error) {
      console.error('Failed to validate environment:', error.message);
    }
  }

  // í™˜ê²½ë³„ ì„¤ì •
  setupEnvironmentSpecific(environment) {
    const envSpecific = {
      production: {
        NODE_ENV: 'production',
        LOG_LEVEL: 'error',
        ENABLE_MONITORING: 'true'
      },
      staging: {
        NODE_ENV: 'staging',
        LOG_LEVEL: 'debug',
        ENABLE_MONITORING: 'true'
      },
      development: {
        NODE_ENV: 'development',
        LOG_LEVEL: 'debug',
        ENABLE_MONITORING: 'false'
      }
    };

    const config = envSpecific[environment];
    if (!config) {
      console.error(`Unknown environment: ${environment}`);
      return;
    }

    console.log(`\nSetting up ${environment} environment...`);

    Object.entries(config).forEach(([key, value]) => {
      execSync(`railway variables set ${key}="${value}"`, { stdio: 'inherit' });
    });
  }
}

// ì‹¤í–‰
const manager = new RailwayEnvManager();
const environment = process.argv[2] || 'production';

manager.setEnvironmentVariables();
manager.setupEnvironmentSpecific(environment);
manager.validateEnvironment();

```

### ë³´ì•ˆ í™˜ê²½ë³€ìˆ˜ ê´€ë¦¬

```jsx
// config/secrets.js
const crypto = require('crypto');

class SecretsManager {
  constructor() {
    this.algorithm = 'aes-256-gcm';
    this.masterKey = process.env.MASTER_KEY || this.generateMasterKey();
  }

  // ë§ˆìŠ¤í„° í‚¤ ìƒì„±
  generateMasterKey() {
    return crypto.randomBytes(32).toString('hex');
  }

  // ì‹œí¬ë¦¿ ì•”í˜¸í™”
  encryptSecret(secret) {
    const iv = crypto.randomBytes(16);
    const cipher = crypto.createCipheriv(
      this.algorithm,
      Buffer.from(this.masterKey, 'hex'),
      iv
    );

    let encrypted = cipher.update(secret, 'utf8', 'hex');
    encrypted += cipher.final('hex');

    const authTag = cipher.getAuthTag();

    return {
      encrypted,
      iv: iv.toString('hex'),
      authTag: authTag.toString('hex')
    };
  }

  // ì‹œí¬ë¦¿ ë³µí˜¸í™”
  decryptSecret(encryptedData) {
    const decipher = crypto.createDecipheriv(
      this.algorithm,
      Buffer.from(this.masterKey, 'hex'),
      Buffer.from(encryptedData.iv, 'hex')
    );

    decipher.setAuthTag(Buffer.from(encryptedData.authTag, 'hex'));

    let decrypted = decipher.update(encryptedData.encrypted, 'hex', 'utf8');
    decrypted += decipher.final('utf8');

    return decrypted;
  }

  // Railway Secrets ì„¤ì •
  async setupRailwaySecrets() {
    const secrets = {
      DATABASE_URL: process.env.DATABASE_URL,
      API_KEYS: {
        youtube: process.env.YOUTUBE_API_KEY,
        claude: process.env.CLAUDE_API_KEY
      }
    };

    // ë¯¼ê°í•œ ë°ì´í„° ì•”í˜¸í™”
    const encryptedSecrets = {};

    Object.entries(secrets).forEach(([key, value]) => {
      if (typeof value === 'object') {
        encryptedSecrets[key] = {};
        Object.entries(value).forEach(([subKey, subValue]) => {
          encryptedSecrets[key][subKey] = this.encryptSecret(subValue);
        });
      } else {
        encryptedSecrets[key] = this.encryptSecret(value);
      }
    });

    // Railwayì— ì €ì¥
    const secretsJson = JSON.stringify(encryptedSecrets);
    require('child_process').execSync(
      `railway variables set ENCRYPTED_SECRETS='${secretsJson}'`,
      { stdio: 'inherit' }
    );
  }

  // ëŸ°íƒ€ì„ì—ì„œ ì‹œí¬ë¦¿ ë¡œë“œ
  loadSecrets() {
    const encryptedSecrets = JSON.parse(process.env.ENCRYPTED_SECRETS || '{}');
    const decryptedSecrets = {};

    Object.entries(encryptedSecrets).forEach(([key, value]) => {
      if (value.encrypted) {
        decryptedSecrets[key] = this.decryptSecret(value);
      } else if (typeof value === 'object') {
        decryptedSecrets[key] = {};
        Object.entries(value).forEach(([subKey, subValue]) => {
          decryptedSecrets[key][subKey] = this.decryptSecret(subValue);
        });
      }
    });

    return decryptedSecrets;
  }
}

module.exports = new SecretsManager();

```

### 11.1.3 ìë™ ë°°í¬ íŒŒì´í”„ë¼ì¸

### GitHub Actions í†µí•©

```yaml
# .github/workflows/deploy.yml
name: Deploy to Railway

on:
  push:
    branches: [main, staging]
  pull_request:
    types: [opened, synchronize]

env:
  RAILWAY_TOKEN: ${{ secrets.RAILWAY_TOKEN }}

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run tests
        run: npm test

      - name: Run security audit
        run: npm audit --production

      - name: Lint code
        run: npm run lint

  build:
    needs: test
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Build application
        run: npm run build

      - name: Upload build artifacts
        uses: actions/upload-artifact@v3
        with:
          name: build-artifacts
          path: |
            backend/dist
            frontend/dist

  deploy-staging:
    needs: build
    if: github.ref == 'refs/heads/staging'
    runs-on: ubuntu-latest
    environment: staging
    steps:
      - uses: actions/checkout@v3

      - name: Install Railway CLI
        run: npm install -g @railway/cli

      - name: Deploy to Railway Staging
        run: |
          railway link ${{ secrets.RAILWAY_PROJECT_ID }}
          railway environment staging
          railway up --detach

      - name: Run smoke tests
        run: npm run test:smoke:staging

      - name: Notify Slack
        uses: 8398a7/action-slack@v3
        with:
          status: ${{ job.status }}
          text: 'Staging deployment completed'
          webhook_url: ${{ secrets.SLACK_WEBHOOK }}

  deploy-production:
    needs: build
    if: github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    environment: production
    steps:
      - uses: actions/checkout@v3

      - name: Install Railway CLI
        run: npm install -g @railway/cli

      - name: Deploy to Railway Production
        run: |
          railway link ${{ secrets.RAILWAY_PROJECT_ID }}
          railway environment production
          railway up --detach

      - name: Wait for deployment
        run: sleep 60

      - name: Health check
        run: |
          response=$(curl -s -o /dev/null -w "%{http_code}" https://api.ytshorts-curator.com/health)
          if [ $response -ne 200 ]; then
            echo "Health check failed"
            exit 1
          fi

      - name: Create release
        uses: actions/create-release@v1
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        with:
          tag_name: v${{ github.run_number }}
          release_name: Release ${{ github.run_number }}
          body: |
            Automated production deployment
            Commit: ${{ github.sha }}

      - name: Notify team
        uses: 8398a7/action-slack@v3
        with:
          status: ${{ job.status }}
          text: 'Production deployment completed'
          webhook_url: ${{ secrets.SLACK_WEBHOOK }}
          fields: repo,message,commit,author,action,eventName,ref,workflow

```

### ë°°í¬ ìŠ¤í¬ë¦½íŠ¸

```jsx
// scripts/deploy.js
const { execSync } = require('child_process');
const fs = require('fs');
const path = require('path');

class DeploymentManager {
  constructor() {
    this.environment = process.env.DEPLOY_ENV || 'production';
    this.projectId = process.env.RAILWAY_PROJECT_ID;
  }

  // ì‚¬ì „ ë°°í¬ ì²´í¬
  async preDeploymentChecks() {
    console.log('Running pre-deployment checks...\n');

    const checks = [
      this.checkGitStatus,
      this.checkTests,
      this.checkBuild,
      this.checkEnvironmentVariables,
      this.checkDatabaseMigrations,
      this.checkDependencies
    ];

    for (const check of checks) {
      try {
        await check.call(this);
        console.log(`âœ“ ${check.name} passed`);
      } catch (error) {
        console.error(`âœ— ${check.name} failed:`, error.message);
        process.exit(1);
      }
    }

    console.log('\nAll pre-deployment checks passed!');
  }

  // Git ìƒíƒœ í™•ì¸
  checkGitStatus() {
    const status = execSync('git status --porcelain', { encoding: 'utf8' });
    if (status) {
      throw new Error('Uncommitted changes detected');
    }

    const branch = execSync('git branch --show-current', { encoding: 'utf8' }).trim();
    if (this.environment === 'production' && branch !== 'main') {
      throw new Error('Production deployments must be from main branch');
    }
  }

  // í…ŒìŠ¤íŠ¸ ì‹¤í–‰
  checkTests() {
    execSync('npm test', { stdio: 'inherit' });
  }

  // ë¹Œë“œ í™•ì¸
  checkBuild() {
    execSync('npm run build', { stdio: 'inherit' });
  }

  // í™˜ê²½ë³€ìˆ˜ í™•ì¸
  checkEnvironmentVariables() {
    const required = [
      'RAILWAY_TOKEN',
      'RAILWAY_PROJECT_ID',
      'NODE_ENV'
    ];

    const missing = required.filter(v => !process.env[v]);
    if (missing.length > 0) {
      throw new Error(`Missing environment variables: ${missing.join(', ')}`);
    }
  }

  // ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜ í™•ì¸
  async checkDatabaseMigrations() {
    const pending = execSync('npm run db:migrate:status', { encoding: 'utf8' });
    if (pending.includes('pending')) {
      throw new Error('Pending database migrations detected');
    }
  }

  // ì˜ì¡´ì„± í™•ì¸
  checkDependencies() {
    const auditResult = execSync('npm audit --production --json', { encoding: 'utf8' });
    const audit = JSON.parse(auditResult);

    if (audit.metadata.vulnerabilities.high > 0 || audit.metadata.vulnerabilities.critical > 0) {
      throw new Error('High or critical vulnerabilities found in dependencies');
    }
  }

  // ë°°í¬ ì‹¤í–‰
  async deploy() {
    console.log(`\nDeploying to ${this.environment}...`);

    try {
      // Railway í™˜ê²½ ì„¤ì •
      execSync(`railway link ${this.projectId}`, { stdio: 'inherit' });
      execSync(`railway environment ${this.environment}`, { stdio: 'inherit' });

      // ë°°í¬
      const deployOutput = execSync('railway up --json', { encoding: 'utf8' });
      const deployInfo = JSON.parse(deployOutput);

      console.log('\nDeployment initiated:', deployInfo.url);

      // ë°°í¬ ì™„ë£Œ ëŒ€ê¸°
      await this.waitForDeployment(deployInfo.deploymentId);

      // ë°°í¬ í›„ ê²€ì¦
      await this.postDeploymentVerification(deployInfo.url);

      console.log('\nâœ… Deployment successful!');
      return deployInfo;

    } catch (error) {
      console.error('\nâŒ Deployment failed:', error.message);
      await this.rollback();
      process.exit(1);
    }
  }

  // ë°°í¬ ì™„ë£Œ ëŒ€ê¸°
  async waitForDeployment(deploymentId, maxAttempts = 60) {
    console.log('\nWaiting for deployment to complete...');

    for (let i = 0; i < maxAttempts; i++) {
      const status = execSync(
        `railway status --json`,
        { encoding: 'utf8' }
      );

      const deploymentStatus = JSON.parse(status);

      if (deploymentStatus.status === 'SUCCESS') {
        console.log('Deployment completed successfully');
        return;
      } else if (deploymentStatus.status === 'FAILED') {
        throw new Error('Deployment failed');
      }

      process.stdout.write('.');
      await new Promise(resolve => setTimeout(resolve, 5000));
    }

    throw new Error('Deployment timeout');
  }

  // ë°°í¬ í›„ ê²€ì¦
  async postDeploymentVerification(deploymentUrl) {
    console.log('\nRunning post-deployment verification...');

    const checks = [
      () => this.checkHealth(deploymentUrl),
      () => this.checkApiEndpoints(deploymentUrl),
      () => this.runSmokeTests(deploymentUrl)
    ];

    for (const check of checks) {
      await check();
    }
  }

  // í—¬ìŠ¤ì²´í¬
  async checkHealth(baseUrl) {
    const response = await fetch(`${baseUrl}/health`);
    if (!response.ok) {
      throw new Error(`Health check failed: ${response.status}`);
    }

    const health = await response.json();
    console.log('âœ“ Health check passed:', health);
  }

  // API ì—”ë“œí¬ì¸íŠ¸ í™•ì¸
  async checkApiEndpoints(baseUrl) {
    const endpoints = [
      '/api/videos/trending',
      '/api/auth/status',
      '/metrics'
    ];

    for (const endpoint of endpoints) {
      const response = await fetch(`${baseUrl}${endpoint}`);
      if (!response.ok && response.status !== 401) {
        throw new Error(`Endpoint ${endpoint} returned ${response.status}`);
      }
    }

    console.log('âœ“ API endpoints verified');
  }

  // ìŠ¤ëª¨í¬ í…ŒìŠ¤íŠ¸
  async runSmokeTests(deploymentUrl) {
    process.env.API_URL = deploymentUrl;
    execSync('npm run test:smoke', { stdio: 'inherit' });
    console.log('âœ“ Smoke tests passed');
  }

  // ë¡¤ë°±
  async rollback() {
    console.log('\nInitiating rollback...');

    try {
      execSync('railway rollback', { stdio: 'inherit' });
      console.log('Rollback completed');
    } catch (error) {
      console.error('Rollback failed:', error.message);
    }
  }

  // ë°°í¬ ì•Œë¦¼
  async notifyDeployment(deployInfo) {
    const webhook = process.env.SLACK_WEBHOOK_URL;
    if (!webhook) return;

    const message = {
      text: `Deployment to ${this.environment} completed`,
      attachments: [{
        color: 'good',
        fields: [
          {
            title: 'Environment',
            value: this.environment,
            short: true
          },
          {
            title: 'URL',
            value: deployInfo.url,
            short: true
          },
          {
            title: 'Version',
            value: deployInfo.version,
            short: true
          },
          {
            title: 'Deployed by',
            value: process.env.USER || 'CI/CD',
            short: true
          }
        ],
        timestamp: new Date().toISOString()
      }]
    };

    await fetch(webhook, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify(message)
    });
  }
}

// ì‹¤í–‰
async function main() {
  const deployer = new DeploymentManager();

  await deployer.preDeploymentChecks();
  const deployInfo = await deployer.deploy();
  await deployer.notifyDeployment(deployInfo);
}

main().catch(console.error);

```

## 11.2 ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹…

### 11.2.1 ë¡œê·¸ ìˆ˜ì§‘ ì‹œìŠ¤í…œ

### í†µí•© ë¡œê¹… ì„¤ì •

```jsx
// config/logging.js
const winston = require('winston');
const { ElasticsearchTransport } = require('winston-elasticsearch');
const DailyRotateFile = require('winston-daily-rotate-file');
const Sentry = require('@sentry/node');

class LoggingService {
  constructor() {
    this.environment = process.env.NODE_ENV || 'development';
    this.serviceName = 'youtube-shorts-curator';

    // Sentry ì´ˆê¸°í™”
    this.initializeSentry();

    // Winston ë¡œê±° ìƒì„±
    this.logger = this.createLogger();
  }

  // Sentry ì´ˆê¸°í™”
  initializeSentry() {
    if (process.env.SENTRY_DSN) {
      Sentry.init({
        dsn: process.env.SENTRY_DSN,
        environment: this.environment,
        tracesSampleRate: this.environment === 'production' ? 0.1 : 1.0,
        integrations: [
          new Sentry.Integrations.Http({ tracing: true }),
          new Sentry.Integrations.Express({ app: require('express')() })
        ]
      });
    }
  }

  // Winston ë¡œê±° ìƒì„±
  createLogger() {
    const logFormat = winston.format.combine(
      winston.format.timestamp(),
      winston.format.errors({ stack: true }),
      winston.format.json(),
      winston.format.printf(info => {
        const log = {
          timestamp: info.timestamp,
          level: info.level,
          service: this.serviceName,
          environment: this.environment,
          message: info.message,
          ...this.sanitizeMetadata(info)
        };

        return JSON.stringify(log);
      })
    );

    const transports = [
      // ì½˜ì†” ì¶œë ¥
      new winston.transports.Console({
        format: winston.format.combine(
          winston.format.colorize(),
          winston.format.simple()
        )
      })
    ];

    // íŒŒì¼ ë¡œí…Œì´ì…˜
    if (this.environment !== 'development') {
      transports.push(
        new DailyRotateFile({
          filename: 'logs/application-%DATE%.log',
          datePattern: 'YYYY-MM-DD',
          zippedArchive: true,
          maxSize: '20m',
          maxFiles: '14d'
        }),
        new DailyRotateFile({
          filename: 'logs/error-%DATE%.log',
          datePattern: 'YYYY-MM-DD',
          zippedArchive: true,
          maxSize: '20m',
          maxFiles: '30d',
          level: 'error'
        })
      );
    }

    // Elasticsearch ì „ì†¡ (í”„ë¡œë•ì…˜)
    if (process.env.ELASTICSEARCH_URL) {
      transports.push(
        new ElasticsearchTransport({
          level: 'info',
          clientOpts: {
            node: process.env.ELASTICSEARCH_URL,
            auth: {
              username: process.env.ELASTICSEARCH_USER,
              password: process.env.ELASTICSEARCH_PASSWORD
            }
          },
          index: `logs-${this.serviceName}`,
          transformer: this.elasticsearchTransformer.bind(this)
        })
      );
    }

    return winston.createLogger({
      level: process.env.LOG_LEVEL || 'info',
      format: logFormat,
      transports,
      exceptionHandlers: [
        new winston.transports.File({ filename: 'logs/exceptions.log' })
      ],
      rejectionHandlers: [
        new winston.transports.File({ filename: 'logs/rejections.log' })
      ]
    });
  }

  // ë¯¼ê°í•œ ì •ë³´ ì œê±°
  sanitizeMetadata(info) {
    const sensitive = ['password', 'token', 'api_key', 'secret'];
    const metadata = { ...info };

    delete metadata.timestamp;
    delete metadata.level;
    delete metadata.message;

    const sanitize = (obj) => {
      if (typeof obj !== 'object' || obj === null) return obj;

      const sanitized = Array.isArray(obj) ? [] : {};

      for (const key in obj) {
        if (sensitive.some(s => key.toLowerCase().includes(s))) {
          sanitized[key] = '[REDACTED]';
        } else if (typeof obj[key] === 'object') {
          sanitized[key] = sanitize(obj[key]);
        } else {
          sanitized[key] = obj[key];
        }
      }

      return sanitized;
    };

    return sanitize(metadata);
  }

  // Elasticsearch ë³€í™˜
  elasticsearchTransformer(logData) {
    return {
      '@timestamp': logData.timestamp,
      level: logData.level,
      message: logData.message,
      service: this.serviceName,
      environment: this.environment,
      fields: logData.meta
    };
  }

  // êµ¬ì¡°í™”ëœ ë¡œê¹… ë©”ì„œë“œ
  log(level, message, metadata = {}) {
    this.logger.log(level, message, {
      ...metadata,
      correlationId: metadata.correlationId || this.generateCorrelationId()
    });
  }

  info(message, metadata) {
    this.log('info', message, metadata);
  }

  warn(message, metadata) {
    this.log('warn', message, metadata);
  }

  error(message, error, metadata = {}) {
    const errorMetadata = {
      ...metadata,
      error: {
        message: error.message,
        stack: error.stack,
        code: error.code,
        name: error.name
      }
    };

    this.log('error', message, errorMetadata);

    // Sentryì—ë„ ì „ì†¡
    if (process.env.SENTRY_DSN) {
      Sentry.captureException(error, {
        tags: metadata,
        level: 'error'
      });
    }
  }

  // API ìš”ì²­ ë¡œê¹…
  logApiRequest(req, res, responseTime) {
    const logData = {
      method: req.method,
      path: req.path,
      query: req.query,
      statusCode: res.statusCode,
      responseTime,
      userAgent: req.headers['user-agent'],
      ip: req.ip,
      userId: req.userId,
      correlationId: req.correlationId
    };

    if (res.statusCode >= 400) {
      this.warn('API request failed', logData);
    } else {
      this.info('API request', logData);
    }
  }

  // ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ ë¡œê¹…
  logDatabaseQuery(query, duration, error = null) {
    const logData = {
      query: this.sanitizeQuery(query),
      duration,
      success: !error
    };

    if (error) {
      this.error('Database query failed', error, logData);
    } else if (duration > 1000) {
      this.warn('Slow database query', logData);
    } else {
      this.info('Database query', logData);
    }
  }

  // ì¿¼ë¦¬ ë¯¼ê°ì •ë³´ ì œê±°
  sanitizeQuery(query) {
    // ë¹„ë°€ë²ˆí˜¸ ë“± ë¯¼ê°í•œ ì •ë³´ ë§ˆìŠ¤í‚¹
    return query.replace(/password\s*=\s*'[^']*'/gi, "password='[REDACTED]'");
  }

  // ìƒê´€ê´€ê³„ ID ìƒì„±
  generateCorrelationId() {
    return `${Date.now()}-${Math.random().toString(36).substr(2, 9)}`;
  }

  // Express ë¯¸ë“¤ì›¨ì–´
  expressMiddleware() {
    return (req, res, next) => {
      req.correlationId = req.headers['x-correlation-id'] || this.generateCorrelationId();
      req.startTime = Date.now();

      // ì‘ë‹µ ë¡œê¹…
      res.on('finish', () => {
        const responseTime = Date.now() - req.startTime;
        this.logApiRequest(req, res, responseTime);
      });

      next();
    };
  }

  // ë¹„ì •ìƒ ì¢…ë£Œ í•¸ë“¤ë§
  setupExceptionHandlers() {
    process.on('uncaughtException', (error) => {
      this.error('Uncaught exception', error);
      process.exit(1);
    });

    process.on('unhandledRejection', (reason, promise) => {
      this.error('Unhandled rejection', new Error(reason), {
        promise: promise.toString()
      });
    });

    process.on('SIGTERM', () => {
      this.info('SIGTERM received, shutting down gracefully');
      process.exit(0);
    });
  }
}

module.exports = new LoggingService();

```

### ë¶„ì‚° ì¶”ì  (Distributed Tracing)

```jsx
// config/tracing.js
const { NodeTracerProvider } = require('@opentelemetry/sdk-trace-node');
const { Resource } = require('@opentelemetry/resources');
const { SemanticResourceAttributes } = require('@opentelemetry/semantic-conventions');
const { JaegerExporter } = require('@opentelemetry/exporter-jaeger');
const { BatchSpanProcessor } = require('@opentelemetry/sdk-trace-base');
const { registerInstrumentations } = require('@opentelemetry/instrumentation');
const { HttpInstrumentation } = require('@opentelemetry/instrumentation-http');
const { ExpressInstrumentation } = require('@opentelemetry/instrumentation-express');

class TracingService {
  constructor() {
    this.serviceName = 'youtube-shorts-curator';
    this.provider = null;
  }

  // ì¶”ì  ì´ˆê¸°í™”
  initialize() {
    // ë¦¬ì†ŒìŠ¤ ì •ì˜
    const resource = Resource.default().merge(
      new Resource({
        [SemanticResourceAttributes.SERVICE_NAME]: this.serviceName,
        [SemanticResourceAttributes.SERVICE_VERSION]: process.env.APP_VERSION || '1.0.0',
        [SemanticResourceAttributes.DEPLOYMENT_ENVIRONMENT]: process.env.NODE_ENV
      })
    );

    // Provider ìƒì„±
    this.provider = new NodeTracerProvider({
      resource
    });

    // Jaeger Exporter ì„¤ì •
    const jaegerExporter = new JaegerExporter({
      endpoint: process.env.JAEGER_ENDPOINT || 'http://localhost:14268/api/traces',
      serviceName: this.serviceName
    });

    // Span Processor ì¶”ê°€
    this.provider.addSpanProcessor(
      new BatchSpanProcessor(jaegerExporter, {
        maxQueueSize: 100,
        maxExportBatchSize: 10,
        scheduledDelayMillis: 500,
        exportTimeoutMillis: 30000
      })
    );

    // Provider ë“±ë¡
    this.provider.register();

    // ìë™ ê³„ì¸¡ ì„¤ì •
    registerInstrumentations({
      instrumentations: [
        new HttpInstrumentation({
          requestHook: (span, request) => {
            span.setAttribute('http.request.body', JSON.stringify(request.body));
          },
          responseHook: (span, response) => {
            span.setAttribute('http.response.size', response.headers['content-length']);
          }
        }),
        new ExpressInstrumentation({
          requestHook: (span, req) => {
            span.setAttribute('user.id', req.userId);
            span.setAttribute('correlation.id', req.correlationId);
          }
        })
      ]
    });

    console.log('Tracing initialized');
  }

  // ì»¤ìŠ¤í…€ ìŠ¤íŒ¬ ìƒì„±
  createSpan(name, options = {}) {
    const tracer = this.provider.getTracer(this.serviceName);
    return tracer.startSpan(name, options);
  }

  // ë¹„ë™ê¸° ì‘ì—… ì¶”ì 
  async traceAsync(name, fn, attributes = {}) {
    const span = this.createSpan(name);

    // ì†ì„± ì¶”ê°€
    Object.entries(attributes).forEach(([key, value]) => {
      span.setAttribute(key, value);
    });

    try {
      const result = await fn();
      span.setStatus({ code: 1 }); // OK
      return result;
    } catch (error) {
      span.setStatus({
        code: 2, // ERROR
        message: error.message
      });
      span.recordException(error);
      throw error;
    } finally {
      span.end();
    }
  }

  // Express ë¯¸ë“¤ì›¨ì–´
  expressMiddleware() {
    return async (req, res, next) => {
      const span = this.createSpan(`${req.method} ${req.path}`);

      // ìš”ì²­ ì •ë³´ ì¶”ê°€
      span.setAttributes({
        'http.method': req.method,
        'http.url': req.url,
        'http.target': req.path,
        'http.host': req.hostname,
        'http.scheme': req.protocol,
        'http.user_agent': req.headers['user-agent'],
        'user.id': req.userId,
        'correlation.id': req.correlationId
      });

      // ì»¨í…ìŠ¤íŠ¸ì— ìŠ¤íŒ¬ ì¶”ê°€
      req.span = span;

      // ì‘ë‹µ ì²˜ë¦¬
      const originalSend = res.send;
      res.send = function(data) {
        span.setAttributes({
          'http.status_code': res.statusCode,
          'http.response.size': Buffer.byteLength(data)
        });

        if (res.statusCode >= 400) {
          span.setStatus({
            code: 2,
            message: `HTTP ${res.statusCode}`
          });
        }

        span.end();
        return originalSend.call(this, data);
      };

      next();
    };
  }

  // ë°ì´í„°ë² ì´ìŠ¤ ì¶”ì 
  traceDatabaseQuery(queryName, query) {
    return this.traceAsync(`db.${queryName}`, async () => {
      // ì‹¤ì œ ì¿¼ë¦¬ ì‹¤í–‰
      return await executeQuery(query);
    }, {
      'db.system': 'postgresql',
      'db.statement': query.substring(0, 100) // ì¿¼ë¦¬ ì¼ë¶€ë§Œ
    });
  }

  // ì™¸ë¶€ API í˜¸ì¶œ ì¶”ì 
  traceExternalApi(apiName, url, method) {
    return this.traceAsync(`external.${apiName}`, async () => {
      // ì‹¤ì œ API í˜¸ì¶œ
      return await fetch(url, { method });
    }, {
      'http.url': url,
      'http.method': method,
      'peer.service': apiName
    });
  }

  // ì¢…ë£Œ ì²˜ë¦¬
  shutdown() {
    return this.provider.shutdown();
  }
}

module.exports = new TracingService();

```

### 11.2.2 ì—ëŸ¬ ì¶”ì 

### ì—ëŸ¬ ì¶”ì  ì‹œìŠ¤í…œ

```jsx
// monitoring/errorTracking.js
const Sentry = require('@sentry/node');
const { ProfilingIntegration } = require('@sentry/profiling-node');

class ErrorTrackingService {
  constructor() {
    this.initialized = false;
    this.errorQueue = [];
    this.errorPatterns = new Map();
  }

  // ì´ˆê¸°í™”
  initialize(app) {
    if (this.initialized) return;

    Sentry.init({
      dsn: process.env.SENTRY_DSN,
      environment: process.env.NODE_ENV,
      integrations: [
        new Sentry.Integrations.Http({ tracing: true }),
        new Sentry.Integrations.Express({ app }),
        new ProfilingIntegration()
      ],
      tracesSampleRate: this.getTraceSampleRate(),
      profilesSampleRate: 1.0,
      beforeSend: this.beforeSend.bind(this),
      beforeSendTransaction: this.beforeSendTransaction.bind(this)
    });

    this.initialized = true;
    this.startErrorAnalysis();
  }

  // ìƒ˜í”Œë§ ë¹„ìœ¨ ê²°ì •
  getTraceSampleRate() {
    switch (process.env.NODE_ENV) {
      case 'production':
        return 0.1;
      case 'staging':
        return 0.5;
      default:
        return 1.0;
    }
  }

  // ì—ëŸ¬ ì „ì†¡ ì „ ì²˜ë¦¬
  beforeSend(event, hint) {
    // ë¯¼ê°í•œ ì •ë³´ ì œê±°
    if (event.request) {
      event.request = this.sanitizeRequest(event.request);
    }

    // ì—ëŸ¬ ê·¸ë£¹í™”
    const errorKey = this.getErrorKey(hint.originalException);
    this.trackErrorPattern(errorKey);

    // ë°˜ë³µì ì¸ ì—ëŸ¬ í•„í„°ë§
    if (this.isRepetitiveError(errorKey)) {
      return null; // ì „ì†¡í•˜ì§€ ì•ŠìŒ
    }

    // ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
    event.contexts = {
      ...event.contexts,
      app: {
        memory_usage: process.memoryUsage(),
        uptime: process.uptime(),
        node_version: process.version
      }
    };

    return event;
  }

  // íŠ¸ëœì­ì…˜ ì „ì†¡ ì „ ì²˜ë¦¬
  beforeSendTransaction(event) {
    // ëŠë¦° íŠ¸ëœì­ì…˜ë§Œ ì „ì†¡
    if (event.transaction && event.timestamp - event.start_timestamp < 1) {
      return null;
    }
    return event;
  }

  // ìš”ì²­ ì •ë³´ ì •ì œ
  sanitizeRequest(request) {
    const sanitized = { ...request };

    // í—¤ë” ì •ì œ
    if (sanitized.headers) {
      delete sanitized.headers.authorization;
      delete sanitized.headers.cookie;
      delete sanitized.headers['x-api-key'];
    }

    // ì¿¼ë¦¬ íŒŒë¼ë¯¸í„° ì •ì œ
    if (sanitized.query_string) {
      sanitized.query_string = sanitized.query_string.replace(
        /api_key=[^&]*/g,
        'api_key=[REDACTED]'
      );
    }

    // Body ì •ì œ
    if (sanitized.data) {
      const sensitive = ['password', 'token', 'secret'];
      sensitive.forEach(field => {
        if (sanitized.data[field]) {
          sanitized.data[field] = '[REDACTED]';
        }
      });
    }

    return sanitized;
  }

  // ì—ëŸ¬ í‚¤ ìƒì„±
  getErrorKey(error) {
    if (!error) return 'unknown';

    return `${error.name}-${error.message}-${error.stack?.split('\n')[1]?.trim()}`;
  }

  // ì—ëŸ¬ íŒ¨í„´ ì¶”ì 
  trackErrorPattern(errorKey) {
    const pattern = this.errorPatterns.get(errorKey) || {
      count: 0,
      firstSeen: Date.now(),
      lastSeen: Date.now()
    };

    pattern.count++;
    pattern.lastSeen = Date.now();

    this.errorPatterns.set(errorKey, pattern);
  }

  // ë°˜ë³µì ì¸ ì—ëŸ¬ í™•ì¸
  isRepetitiveError(errorKey) {
    const pattern = this.errorPatterns.get(errorKey);
    if (!pattern) return false;

    // 5ë¶„ ë‚´ì— 10ë²ˆ ì´ìƒ ë°œìƒí•œ ì—ëŸ¬ëŠ” í•„í„°ë§
    const fiveMinutes = 5 * 60 * 1000;
    const timeDiff = Date.now() - pattern.firstSeen;

    return timeDiff < fiveMinutes && pattern.count > 10;
  }

  // ì—ëŸ¬ ë¶„ì„ ì‹œì‘
  startErrorAnalysis() {
    // ì£¼ê¸°ì ìœ¼ë¡œ ì—ëŸ¬ íŒ¨í„´ ë¶„ì„
    setInterval(() => {
      this.analyzeErrorPatterns();
      this.cleanupOldPatterns();
    }, 60000); // 1ë¶„ë§ˆë‹¤
  }

  // ì—ëŸ¬ íŒ¨í„´ ë¶„ì„
  analyzeErrorPatterns() {
    const criticalPatterns = [];

    for (const [key, pattern] of this.errorPatterns) {
      // ê¸‰ì¦í•˜ëŠ” ì—ëŸ¬ ê°ì§€
      if (pattern.count > 50) {
        criticalPatterns.push({
          key,
          ...pattern
        });
      }
    }

    if (criticalPatterns.length > 0) {
      this.alertCriticalErrors(criticalPatterns);
    }
  }

  // ì˜¤ë˜ëœ íŒ¨í„´ ì •ë¦¬
  cleanupOldPatterns() {
    const oneHour = 60 * 60 * 1000;
    const now = Date.now();

    for (const [key, pattern] of this.errorPatterns) {
      if (now - pattern.lastSeen > oneHour) {
        this.errorPatterns.delete(key);
      }
    }
  }

  // ì¤‘ìš” ì—ëŸ¬ ì•Œë¦¼
  async alertCriticalErrors(patterns) {
    const webhook = process.env.SLACK_WEBHOOK_URL;
    if (!webhook) return;

    const message = {
      text: 'ğŸš¨ Critical Error Patterns Detected',
      attachments: patterns.map(pattern => ({
        color: 'danger',
        title: pattern.key,
        fields: [
          {
            title: 'Occurrences',
            value: pattern.count,
            short: true
          },
          {
            title: 'Time Range',
            value: `${Math.round((Date.now() - pattern.firstSeen) / 60000)} minutes`,
            short: true
          }
        ]
      }))
    };

    await fetch(webhook, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify(message)
    });
  }

  // ì»¤ìŠ¤í…€ ì—ëŸ¬ ìº¡ì²˜
  captureError(error, context = {}) {
    if (!this.initialized) {
      this.errorQueue.push({ error, context });
      return;
    }

    Sentry.captureException(error, {
      tags: {
        component: context.component,
        action: context.action
      },
      extra: context
    });
  }

  // ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ì„¤ì •
  setUser(user) {
    Sentry.setUser({
      id: user.id,
      email: user.email,
      username: user.name,
      tier: user.tier
    });
  }

  // ë¸Œë ˆë“œí¬ëŸ¼ ì¶”ê°€
  addBreadcrumb(breadcrumb) {
    Sentry.addBreadcrumb({
      timestamp: Date.now() / 1000,
      ...breadcrumb
    });
  }

  // Express ì—ëŸ¬ í•¸ë“¤ëŸ¬
  errorHandler() {
    return Sentry.Handlers.errorHandler({
      shouldHandleError(error) {
        // 404 ì—ëŸ¬ëŠ” ì œì™¸
        if (error.status === 404) {
          return false;
        }
        return true;
      }
    });
  }

  // ìš”ì²­ í•¸ë“¤ëŸ¬
  requestHandler() {
    return Sentry.Handlers.requestHandler({
      user: ['id', 'email'],
      ip: true,
      request: ['method', 'url', 'query_string', 'data'],
      transaction: 'methodPath'
    });
  }
}

module.exports = new ErrorTrackingService();

```

### 11.2.3 ì•Œë¦¼ ì„¤ì •

### í†µí•© ì•Œë¦¼ ì‹œìŠ¤í…œ

```jsx
// monitoring/alerting.js
const nodemailer = require('nodemailer');
const twilio = require('twilio');

class AlertingService {
  constructor() {
    this.channels = this.initializeChannels();
    this.alertRules = this.loadAlertRules();
    this.alertHistory = new Map();
  }

  // ì•Œë¦¼ ì±„ë„ ì´ˆê¸°í™”
  initializeChannels() {
    const channels = {};

    // Slack
    if (process.env.SLACK_WEBHOOK_URL) {
      channels.slack = {
        send: this.sendSlackAlert.bind(this),
        priority: ['critical', 'high', 'medium', 'low']
      };
    }

    // Email
    if (process.env.SMTP_HOST) {
      channels.email = {
        send: this.sendEmailAlert.bind(this),
        priority: ['critical', 'high']
      };

      this.emailTransporter = nodemailer.createTransport({
        host: process.env.SMTP_HOST,
        port: process.env.SMTP_PORT,
        secure: true,
        auth: {
          user: process.env.SMTP_USER,
          pass: process.env.SMTP_PASS
        }
      });
    }

    // SMS (Twilio)
    if (process.env.TWILIO_ACCOUNT_SID) {
      channels.sms = {
        send: this.sendSmsAlert.bind(this),
        priority: ['critical']
      };

      this.twilioClient = twilio(
        process.env.TWILIO_ACCOUNT_SID,
        process.env.TWILIO_AUTH_TOKEN
      );
    }

    // PagerDuty
    if (process.env.PAGERDUTY_ROUTING_KEY) {
      channels.pagerduty = {
        send: this.sendPagerDutyAlert.bind(this),
        priority: ['critical']
      };
    }

    return channels;
  }

  // ì•Œë¦¼ ê·œì¹™ ë¡œë“œ
  loadAlertRules() {
    return {
      // ì‹œìŠ¤í…œ ì•Œë¦¼
      system: {
        high_cpu: {
          threshold: 80,
          duration: 300, // 5ë¶„
          priority: 'high',
          message: 'CPU usage above {value}% for {duration} minutes'
        },
        high_memory: {
          threshold: 90,
          duration: 300,
          priority: 'high',
          message: 'Memory usage above {value}% for {duration} minutes'
        },
        disk_space: {
          threshold: 85,
          priority: 'medium',
          message: 'Disk space usage above {value}%'
        }
      },

      // API ì•Œë¦¼
      api: {
        high_error_rate: {
          threshold: 5, // 5%
          duration: 300,
          priority: 'high',
          message: 'API error rate above {value}% for {duration} minutes'
        },
        slow_response: {
          threshold: 2000, // 2ì´ˆ
          duration: 600,
          priority: 'medium',
          message: 'Average response time above {value}ms for {duration} minutes'
        },
        rate_limit_exceeded: {
          threshold: 1000,
          duration: 60,
          priority: 'medium',
          message: 'Rate limit exceeded {value} times in {duration} minutes'
        }
      },

      // ë¹„ì¦ˆë‹ˆìŠ¤ ì•Œë¦¼
      business: {
        youtube_quota_usage: {
          threshold: 80, // 80%
          priority: 'high',
          message: 'YouTube API quota usage at {value}%'
        },
        low_cache_hit_rate: {
          threshold: 60, // 60%
          duration: 1800, // 30ë¶„
          priority: 'medium',
          message: 'Cache hit rate below {value}% for {duration} minutes'
        },
        payment_failure: {
          threshold: 5,
          duration: 3600,
          priority: 'critical',
          message: '{value} payment failures in the last hour'
        }
      }
    };
  }

  // ì•Œë¦¼ ì „ì†¡
  async sendAlert(alert) {
    // ì¤‘ë³µ ì•Œë¦¼ ë°©ì§€
    if (this.isDuplicateAlert(alert)) {
      return;
    }

    // ì•Œë¦¼ ì´ë ¥ ì €ì¥
    this.recordAlert(alert);

    // ìš°ì„ ìˆœìœ„ë³„ ì±„ë„ ì„ íƒ
    const channels = this.selectChannels(alert.priority);

    // ëª¨ë“  ì±„ë„ì— ì•Œë¦¼ ì „ì†¡
    const results = await Promise.allSettled(
      channels.map(channel => channel.send(alert))
    );

    // ì „ì†¡ ê²°ê³¼ ë¡œê¹…
    results.forEach((result, index) => {
      if (result.status === 'rejected') {
        console.error(`Alert sending failed for channel ${index}:`, result.reason);
      }
    });
  }

  // Slack ì•Œë¦¼
  async sendSlackAlert(alert) {
    const color = {
      critical: 'danger',
      high: 'warning',
      medium: 'warning',
      low: 'good'
    }[alert.priority];

    const message = {
      text: `${this.getPriorityEmoji(alert.priority)} ${alert.title}`,
      attachments: [{
        color,
        fields: [
          {
            title: 'Priority',
            value: alert.priority.toUpperCase(),
            short: true
          },
          {
            title: 'Component',
            value: alert.component,
            short: true
          },
          {
            title: 'Details',
            value: alert.message,
            short: false
          },
          {
            title: 'Time',
            value: new Date().toISOString(),
            short: true
          }
        ],
        actions: alert.actions || []
      }]
    };

    await fetch(process.env.SLACK_WEBHOOK_URL, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify(message)
    });
  }

  // Email ì•Œë¦¼
  async sendEmailAlert(alert) {
    const subject = `[${alert.priority.toUpperCase()}] ${alert.title}`;

    const html = `
      <h2>${alert.title}</h2>
      <p><strong>Priority:</strong> ${alert.priority}</p>
      <p><strong>Component:</strong> ${alert.component}</p>
      <p><strong>Message:</strong> ${alert.message}</p>
      <p><strong>Time:</strong> ${new Date().toISOString()}</p>
      ${alert.details ? `<pre>${JSON.stringify(alert.details, null, 2)}</pre>` : ''}
    `;

    await this.emailTransporter.sendMail({
      from: process.env.ALERT_FROM_EMAIL,
      to: process.env.ALERT_TO_EMAILS,
      subject,
      html
    });
  }

  // SMS ì•Œë¦¼
  async sendSmsAlert(alert) {
    const message = `[${alert.priority.toUpperCase()}] ${alert.title}\n${alert.message}`;

    await this.twilioClient.messages.create({
      body: message.substring(0, 160), // SMS ê¸¸ì´ ì œí•œ
      from: process.env.TWILIO_PHONE_NUMBER,
      to: process.env.ALERT_PHONE_NUMBERS.split(',')
    });
  }

  // PagerDuty ì•Œë¦¼
  async sendPagerDutyAlert(alert) {
    const event = {
      routing_key: process.env.PAGERDUTY_ROUTING_KEY,
      event_action: 'trigger',
      payload: {
        summary: alert.title,
        severity: this.mapPriority(alert.priority),
        source: alert.component,
        custom_details: alert.details
      }
    };

    await fetch('https://events.pagerduty.com/v2/enqueue', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify(event)
    });
  }

  // ì±„ë„ ì„ íƒ
  selectChannels(priority) {
    return Object.entries(this.channels)
      .filter(([name, channel]) => channel.priority.includes(priority))
      .map(([name, channel]) => channel);
  }

  // ì¤‘ë³µ ì•Œë¦¼ í™•ì¸
  isDuplicateAlert(alert) {
    const key = `${alert.component}-${alert.rule}`;
    const lastAlert = this.alertHistory.get(key);

    if (!lastAlert) return false;

    const timeDiff = Date.now() - lastAlert.timestamp;
    const cooldown = this.getCooldownPeriod(alert.priority);

    return timeDiff < cooldown;
  }

  // ì•Œë¦¼ ì´ë ¥ ê¸°ë¡
  recordAlert(alert) {
    const key = `${alert.component}-${alert.rule}`;
    this.alertHistory.set(key, {
      ...alert,
      timestamp: Date.now()
    });

    // ì˜¤ë˜ëœ ì´ë ¥ ì •ë¦¬
    this.cleanupAlertHistory();
  }

  // ì¿¨ë‹¤ìš´ ê¸°ê°„ ê²°ì •
  getCooldownPeriod(priority) {
    const cooldowns = {
      critical: 5 * 60 * 1000,    // 5ë¶„
      high: 15 * 60 * 1000,       // 15ë¶„
      medium: 30 * 60 * 1000,     // 30ë¶„
      low: 60 * 60 * 1000         // 1ì‹œê°„
    };

    return cooldowns[priority] || 30 * 60 * 1000;
  }

  // ìš°ì„ ìˆœìœ„ ì´ëª¨ì§€
  getPriorityEmoji(priority) {
    const emojis = {
      critical: 'ğŸš¨',
      high: 'âš ï¸',
      medium: 'ğŸ“¢',
      low: 'â„¹ï¸'
    };

    return emojis[priority] || 'ğŸ“Œ';
  }

  // ìš°ì„ ìˆœìœ„ ë§¤í•‘ (PagerDuty)
  mapPriority(priority) {
    const mapping = {
      critical: 'critical',
      high: 'error',
      medium: 'warning',
      low: 'info'
    };

    return mapping[priority] || 'info';
  }

  // ì•Œë¦¼ ì´ë ¥ ì •ë¦¬
  cleanupAlertHistory() {
    const oneDay = 24 * 60 * 60 * 1000;
    const now = Date.now();

    for (const [key, alert] of this.alertHistory) {
      if (now - alert.timestamp > oneDay) {
        this.alertHistory.delete(key);
      }
    }
  }

  // ë©”íŠ¸ë¦­ ê¸°ë°˜ ì•Œë¦¼ ì²´í¬
  async checkMetricAlerts(metrics) {
    for (const [category, rules] of Object.entries(this.alertRules)) {
      for (const [ruleName, rule] of Object.entries(rules)) {
        const value = this.getMetricValue(metrics, category, ruleName);

        if (value !== null && this.shouldTriggerAlert(value, rule)) {
          await this.sendAlert({
            title: `${category}.${ruleName} Alert`,
            component: category,
            rule: ruleName,
            priority: rule.priority,
            message: rule.message
              .replace('{value}', value)
              .replace('{duration}', (rule.duration / 60) || 0),
            details: { value, threshold: rule.threshold }
          });
        }
      }
    }
  }

  // ë©”íŠ¸ë¦­ ê°’ ì¶”ì¶œ
  getMetricValue(metrics, category, rule) {
    // ì‹¤ì œ ë©”íŠ¸ë¦­ ë°ì´í„°ì—ì„œ ê°’ ì¶”ì¶œ
    return metrics?.[category]?.[rule] || null;
  }

  // ì•Œë¦¼ íŠ¸ë¦¬ê±° ì—¬ë¶€ í™•ì¸
  shouldTriggerAlert(value, rule) {
    if (rule.threshold === undefined) return false;

    // ì„ê³„ê°’ ë¹„êµ (ìƒí•œ/í•˜í•œì— ë”°ë¼)
    if (rule.type === 'lower_bound') {
      return value < rule.threshold;
    }

    return value > rule.threshold;
  }
}

module.exports = new AlertingService();

```

## 11.3 ë°±ì—… ë° ë³µêµ¬

### 11.3.1 ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—…

### ìë™ ë°±ì—… ì‹œìŠ¤í…œ

```jsx
// backup/databaseBackup.js
const { createClient } = require('@supabase/supabase-js');
const AWS = require('aws-sdk');
const fs = require('fs').promises;
const path = require('path');
const { exec } = require('child_process').promises;

class DatabaseBackupService {
  constructor() {
    this.supabase = createClient(
      process.env.SUPABASE_URL,
      process.env.SUPABASE_SERVICE_ROLE_KEY
    );

    this.s3 = new AWS.S3({
      accessKeyId: process.env.AWS_ACCESS_KEY_ID,
      secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY,
      region: process.env.AWS_REGION
    });

    this.backupBucket = process.env.BACKUP_BUCKET || 'ytshorts-backups';
  }

  // ë°±ì—… ì‹¤í–‰
  async performBackup(type = 'scheduled') {
    const backupId = this.generateBackupId();
    const startTime = Date.now();

    console.log(`Starting ${type} backup: ${backupId}`);

    try {
      // 1. ë°ì´í„°ë² ì´ìŠ¤ ë¤í”„
      const dumpFile = await this.dumpDatabase(backupId);

      // 2. íŒŒì¼ ì••ì¶• ë° ì•”í˜¸í™”
      const encryptedFile = await this.compressAndEncrypt(dumpFile);

      // 3. S3 ì—…ë¡œë“œ
      const s3Location = await this.uploadToS3(encryptedFile, backupId);

      // 4. ë°±ì—… ë©”íƒ€ë°ì´í„° ì €ì¥
      await this.saveBackupMetadata({
        id: backupId,
        type,
        size: await this.getFileSize(encryptedFile),
        duration: Date.now() - startTime,
        location: s3Location,
        status: 'completed'
      });

      // 5. ë¡œì»¬ íŒŒì¼ ì •ë¦¬
      await this.cleanupLocalFiles([dumpFile, encryptedFile]);

      // 6. ì˜¤ë˜ëœ ë°±ì—… ì •ë¦¬
      await this.cleanupOldBackups();

      console.log(`Backup completed: ${backupId}`);

      return {
        success: true,
        backupId,
        location: s3Location
      };

    } catch (error) {
      console.error(`Backup failed: ${backupId}`, error);

      await this.saveBackupMetadata({
        id: backupId,
        type,
        status: 'failed',
        error: error.message
      });

      throw error;
    }
  }

  // ë°ì´í„°ë² ì´ìŠ¤ ë¤í”„
  async dumpDatabase(backupId) {
    const dumpFile = path.join('/tmp', `backup-${backupId}.sql`);

    // pg_dump ëª…ë ¹ ì‹¤í–‰
    const command = `pg_dump ${process.env.DATABASE_URL} \
      --no-owner \
      --no-privileges \
      --exclude-table-data='*.logs' \
      --exclude-table-data='*.sessions' \
      > ${dumpFile}`;

    await exec(command);

    return outputFile;
  }

  // S3 ì—…ë¡œë“œ
  async uploadToS3(file, backupId) {
    const key = `database/${new Date().getFullYear()}/${backupId}.gz.enc`;

    const fileStream = await fs.readFile(file);

    const params = {
      Bucket: this.backupBucket,
      Key: key,
      Body: fileStream,
      ServerSideEncryption: 'AES256',
      StorageClass: 'STANDARD_IA',
      Metadata: {
        'backup-id': backupId,
        'backup-date': new Date().toISOString(),
        'service': 'youtube-shorts-curator'
      }
    };

    await this.s3.upload(params).promise();

    return `s3://${this.backupBucket}/${key}`;
  }

  // ë°±ì—… ë©”íƒ€ë°ì´í„° ì €ì¥
  async saveBackupMetadata(metadata) {
    const { error } = await this.supabase
      .from('backup_history')
      .insert({
        ...metadata,
        created_at: new Date().toISOString()
      });

    if (error) {
      console.error('Failed to save backup metadata:', error);
    }
  }

  // ë°±ì—… ID ìƒì„±
  generateBackupId() {
    const timestamp = new Date().toISOString().replace(/[:-]/g, '').replace(/\..+/, '');
    const random = Math.random().toString(36).substring(2, 8);
    return `backup-${timestamp}-${random}`;
  }

  // íŒŒì¼ í¬ê¸° í™•ì¸
  async getFileSize(file) {
    const stats = await fs.stat(file);
    return stats.size;
  }

  // ë¡œì»¬ íŒŒì¼ ì •ë¦¬
  async cleanupLocalFiles(files) {
    for (const file of files) {
      try {
        await fs.unlink(file);
      } catch (error) {
        console.error(`Failed to delete ${file}:`, error);
      }
    }
  }

  // ì˜¤ë˜ëœ ë°±ì—… ì •ë¦¬
  async cleanupOldBackups() {
    const retentionDays = {
      daily: 7,
      weekly: 30,
      monthly: 365
    };

    // S3ì—ì„œ ì˜¤ë˜ëœ ë°±ì—… ì‚­ì œ
    const cutoffDate = new Date();
    cutoffDate.setDate(cutoffDate.getDate() - retentionDays.daily);

    const listParams = {
      Bucket: this.backupBucket,
      Prefix: 'database/'
    };

    const objects = await this.s3.listObjectsV2(listParams).promise();

    const toDelete = objects.Contents
      .filter(obj => new Date(obj.LastModified) < cutoffDate)
      .map(obj => ({ Key: obj.Key }));

    if (toDelete.length > 0) {
      await this.s3.deleteObjects({
        Bucket: this.backupBucket,
        Delete: { Objects: toDelete }
      }).promise();

      console.log(`Deleted ${toDelete.length} old backups`);
    }
  }

  // ë°±ì—… ë³µì›
  async restoreBackup(backupId) {
    console.log(`Starting restore for backup: ${backupId}`);

    try {
      // 1. ë°±ì—… ë©”íƒ€ë°ì´í„° ì¡°íšŒ
      const { data: backup } = await this.supabase
        .from('backup_history')
        .select('*')
        .eq('id', backupId)
        .single();

      if (!backup) {
        throw new Error('Backup not found');
      }

      // 2. S3ì—ì„œ ë°±ì—… ë‹¤ìš´ë¡œë“œ
      const localFile = await this.downloadFromS3(backup.location);

      // 3. ë³µí˜¸í™” ë° ì••ì¶• í•´ì œ
      const sqlFile = await this.decryptAndDecompress(localFile);

      // 4. ë°ì´í„°ë² ì´ìŠ¤ ë³µì›
      await this.restoreDatabase(sqlFile);

      // 5. ë³µì› í›„ ê²€ì¦
      await this.verifyRestore();

      // 6. ì •ë¦¬
      await this.cleanupLocalFiles([localFile, sqlFile]);

      console.log(`Restore completed for backup: ${backupId}`);

      return { success: true };

    } catch (error) {
      console.error(`Restore failed for backup: ${backupId}`, error);
      throw error;
    }
  }

  // S3ì—ì„œ ë‹¤ìš´ë¡œë“œ
  async downloadFromS3(s3Location) {
    const match = s3Location.match(/s3:\/\/([^\/]+)\/(.+)/);
    if (!match) {
      throw new Error('Invalid S3 location');
    }

    const [, bucket, key] = match;
    const localFile = path.join('/tmp', path.basename(key));

    const params = {
      Bucket: bucket,
      Key: key
    };

    const data = await this.s3.getObject(params).promise();
    await fs.writeFile(localFile, data.Body);

    return localFile;
  }

  // ë³µí˜¸í™” ë° ì••ì¶• í•´ì œ
  async decryptAndDecompress(inputFile) {
    const outputFile = inputFile.replace('.gz.enc', '.sql');

    const command = `openssl enc -aes-256-cbc \
      -d \
      -pbkdf2 \
      -pass pass:${process.env.BACKUP_ENCRYPTION_KEY} \
      -in ${inputFile} | \
      gzip -d > ${outputFile}`;

    await exec(command);

    return outputFile;
  }

  // ë°ì´í„°ë² ì´ìŠ¤ ë³µì›
  async restoreDatabase(sqlFile) {
    // ì£¼ì˜: í”„ë¡œë•ì…˜ì—ì„œëŠ” ë§¤ìš° ì‹ ì¤‘í•˜ê²Œ ì‹¤í–‰
    const command = `psql ${process.env.DATABASE_URL} < ${sqlFile}`;

    await exec(command);
  }

  // ë³µì› ê²€ì¦
  async verifyRestore() {
    // ê¸°ë³¸ì ì¸ í…Œì´ë¸” ì¡´ì¬ í™•ì¸
    const tables = ['users', 'videos', 'search_logs'];

    for (const table of tables) {
      const { data, error } = await this.supabase
        .from(table)
        .select('count')
        .limit(1);

      if (error) {
        throw new Error(`Table ${table} verification failed`);
      }
    }
  }

  // ë°±ì—… ìŠ¤ì¼€ì¤„ ì„¤ì •
  setupBackupSchedule() {
    const cron = require('node-cron');

    // ì¼ì¼ ë°±ì—… (ë§¤ì¼ ìƒˆë²½ 2ì‹œ)
    cron.schedule('0 2 * * *', async () => {
      try {
        await this.performBackup('daily');
      } catch (error) {
        console.error('Daily backup failed:', error);
        await this.alertBackupFailure('daily', error);
      }
    });

    // ì£¼ê°„ ë°±ì—… (ë§¤ì£¼ ì¼ìš”ì¼ ìƒˆë²½ 3ì‹œ)
    cron.schedule('0 3 * * 0', async () => {
      try {
        await this.performBackup('weekly');
      } catch (error) {
        console.error('Weekly backup failed:', error);
        await this.alertBackupFailure('weekly', error);
      }
    });

    // ì›”ê°„ ë°±ì—… (ë§¤ì›” 1ì¼ ìƒˆë²½ 4ì‹œ)
    cron.schedule('0 4 1 * *', async () => {
      try {
        await this.performBackup('monthly');
      } catch (error) {
        console.error('Monthly backup failed:', error);
        await this.alertBackupFailure('monthly', error);
      }
    });

    console.log('Backup schedules configured');
  }

  // ë°±ì—… ì‹¤íŒ¨ ì•Œë¦¼
  async alertBackupFailure(type, error) {
    const alertingService = require('../monitoring/alerting');

    await alertingService.sendAlert({
      title: 'Database Backup Failed',
      component: 'backup',
      rule: 'backup_failure',
      priority: 'high',
      message: `${type} backup failed: ${error.message}`,
      details: {
        type,
        error: error.stack
      }
    });
  }
}

module.exports = new DatabaseBackupService();

### 11.3.2 ì¬í•´ ë³µêµ¬ ê³„íš

#### ì¬í•´ ë³µêµ¬ ì „ëµ (Disaster Recovery Strategy)

```javascript
// disaster-recovery/drPlan.js
class DisasterRecoveryPlan {
  constructor() {
    this.rto = 4 * 60 * 60 * 1000; // Recovery Time Objective: 4ì‹œê°„
    this.rpo = 60 * 60 * 1000;     // Recovery Point Objective: 1ì‹œê°„
    this.healthChecks = new Map();
    this.failoverInProgress = false;
  }

  // DR ê³„íš ì´ˆê¸°í™”
  async initialize() {
    console.log('Initializing Disaster Recovery Plan...');

    // 1. ëª¨ë“  ì„œë¹„ìŠ¤ í—¬ìŠ¤ì²´í¬ ì„¤ì •
    this.setupHealthChecks();

    // 2. ë°±ì—… ì‹œìŠ¤í…œ ê²€ì¦
    await this.verifyBackupSystems();

    // 3. ë³µêµ¬ ì ˆì°¨ ë¬¸ì„œí™”
    this.documentRecoveryProcedures();

    // 4. íŒ€ ì•Œë¦¼ ì²´ê³„ êµ¬ì¶•
    this.setupAlertingChain();

    console.log('DR Plan initialized successfully');
  }

  // í—¬ìŠ¤ì²´í¬ ì„¤ì •
  setupHealthChecks() {
    const services = [
      {
        name: 'primary-api',
        url: process.env.PRIMARY_API_URL,
        interval: 30000, // 30ì´ˆ
        timeout: 5000,
        retries: 3
      },
      {
        name: 'database',
        checker: this.checkDatabase.bind(this),
        interval: 60000, // 1ë¶„
        timeout: 10000,
        retries: 2
      },
      {
        name: 'redis-cache',
        checker: this.checkRedis.bind(this),
        interval: 30000,
        timeout: 3000,
        retries: 3
      },
      {
        name: 'youtube-api',
        checker: this.checkYouTubeAPI.bind(this),
        interval: 300000, // 5ë¶„
        timeout: 15000,
        retries: 1
      }
    ];

    services.forEach(service => {
      this.startHealthCheck(service);
    });
  }

  // ê°œë³„ í—¬ìŠ¤ì²´í¬ ì‹œì‘
  startHealthCheck(service) {
    const check = {
      ...service,
      status: 'unknown',
      lastCheck: null,
      failureCount: 0,
      successCount: 0
    };

    this.healthChecks.set(service.name, check);

    setInterval(async () => {
      await this.performHealthCheck(service);
    }, service.interval);

    // ì´ˆê¸° ì²´í¬ ì‹¤í–‰
    this.performHealthCheck(service);
  }

  // í—¬ìŠ¤ì²´í¬ ìˆ˜í–‰
  async performHealthCheck(service) {
    const check = this.healthChecks.get(service.name);
    let isHealthy = false;

    try {
      if (service.url) {
        // URL ê¸°ë°˜ í—¬ìŠ¤ì²´í¬
        const response = await fetch(service.url, {
          timeout: service.timeout,
          signal: AbortSignal.timeout(service.timeout)
        });
        isHealthy = response.ok;
      } else if (service.checker) {
        // ì»¤ìŠ¤í…€ ì²´ì»¤
        isHealthy = await service.checker();
      }

      if (isHealthy) {
        check.status = 'healthy';
        check.successCount++;
        check.failureCount = 0;
      } else {
        throw new Error('Health check failed');
      }

    } catch (error) {
      check.failureCount++;

      if (check.failureCount >= service.retries) {
        check.status = 'unhealthy';
        await this.handleServiceFailure(service.name, error);
      } else {
        check.status = 'degraded';
      }
    }

    check.lastCheck = new Date().toISOString();
    this.healthChecks.set(service.name, check);
  }

  // ì„œë¹„ìŠ¤ ì¥ì•  ì²˜ë¦¬
  async handleServiceFailure(serviceName, error) {
    console.error(`Service failure detected: ${serviceName}`, error);

    // ì¥ì•  ìœ í˜•ë³„ ëŒ€ì‘
    switch (serviceName) {
      case 'primary-api':
        await this.initiateAPIFailover();
        break;
      case 'database':
        await this.initiateDatabaseFailover();
        break;
      case 'redis-cache':
        await this.handleCacheFailure();
        break;
      case 'youtube-api':
        await this.handleYouTubeAPIFailure();
        break;
    }

    // íŒ€ ì•Œë¦¼
    await this.alertTeam({
      severity: 'critical',
      service: serviceName,
      error: error.message,
      action: 'automatic-failover-initiated'
    });
  }

  // API í˜ì¼ì˜¤ë²„
  async initiateAPIFailover() {
    if (this.failoverInProgress) return;

    this.failoverInProgress = true;
    console.log('Initiating API failover...');

    try {
      // 1. íŠ¸ë˜í”½ ë¼ìš°íŒ… ë³€ê²½
      await this.updateLoadBalancer({
        primary: false,
        secondary: true
      });

      // 2. DNS ì—…ë°ì´íŠ¸
      await this.updateDNS({
        record: 'api.ytshorts-curator.com',
        target: process.env.SECONDARY_API_URL
      });

      // 3. ìºì‹œ ì›Œë°
      await this.warmSecondaryCache();

      // 4. í—¬ìŠ¤ì²´í¬ í™•ì¸
      await this.verifyFailover('api');

      console.log('API failover completed successfully');

    } catch (error) {
      console.error('API failover failed:', error);
      await this.initiateManualRecovery('api', error);
    } finally {
      this.failoverInProgress = false;
    }
  }

  // ë°ì´í„°ë² ì´ìŠ¤ í˜ì¼ì˜¤ë²„
  async initiateDatabaseFailover() {
    console.log('Initiating database failover...');

    try {
      // 1. ì½ê¸° ì „ìš© ëª¨ë“œ í™œì„±í™”
      await this.enableReadOnlyMode();

      // 2. ìŠ¤íƒ ë°”ì´ DB ìŠ¹ê²©
      await this.promoteStandbyDatabase();

      // 3. ì—°ê²° ë¬¸ìì—´ ì—…ë°ì´íŠ¸
      process.env.DATABASE_URL = process.env.STANDBY_DATABASE_URL;

      // 4. ì• í”Œë¦¬ì¼€ì´ì…˜ ì¬ì‹œì‘
      await this.gracefulRestart();

      // 5. ë°ì´í„° ë™ê¸°í™” í™•ì¸
      await this.verifyDatabaseSync();

      console.log('Database failover completed');

    } catch (error) {
      console.error('Database failover failed:', error);
      await this.executeEmergencyBackupRestore();
    }
  }

  // ìºì‹œ ì¥ì•  ì²˜ë¦¬
  async handleCacheFailure() {
    console.log('Handling cache failure...');

    // 1. ìºì‹œ ë°”ì´íŒ¨ìŠ¤ ëª¨ë“œ í™œì„±í™”
    process.env.CACHE_BYPASS = 'true';

    // 2. ë©”ëª¨ë¦¬ ìºì‹œë¡œ í´ë°±
    const memoryCache = require('../services/memoryCache');
    memoryCache.activate();

    // 3. Redis í´ëŸ¬ìŠ¤í„° ì¬êµ¬ì„± ì‹œë„
    try {
      await this.reconfigureRedisCluster();
    } catch (error) {
      console.error('Redis recovery failed, continuing with memory cache');
    }
  }

  // YouTube API ì¥ì•  ì²˜ë¦¬
  async handleYouTubeAPIFailure() {
    console.log('Handling YouTube API failure...');

    // 1. ìºì‹œ ì „ìš© ëª¨ë“œ í™œì„±í™”
    process.env.CACHE_ONLY_MODE = 'true';

    // 2. ëŒ€ì²´ ë°ì´í„° ì†ŒìŠ¤ í™œì„±í™”
    await this.activateAlternativeDataSources();

    // 3. ì‚¬ìš©ìì—ê²Œ ì œí•œëœ ê¸°ëŠ¥ ì•Œë¦¼
    await this.notifyUsersOfDegradedService();
  }

  // ë°±ì—… ì‹œìŠ¤í…œ ê²€ì¦
  async verifyBackupSystems() {
    const backupService = require('./databaseBackup');

    // 1. ìµœì‹  ë°±ì—… í™•ì¸
    const latestBackup = await backupService.getLatestBackup();
    const backupAge = Date.now() - new Date(latestBackup.created_at).getTime();

    if (backupAge > this.rpo) {
      throw new Error(`Latest backup is too old: ${backupAge / 1000 / 60} minutes`);
    }

    // 2. ë°±ì—… ë¬´ê²°ì„± ê²€ì¦
    const isValid = await backupService.verifyBackupIntegrity(latestBackup.id);
    if (!isValid) {
      throw new Error('Latest backup integrity check failed');
    }

    // 3. ë³µêµ¬ í…ŒìŠ¤íŠ¸ (ì›” 1íšŒ)
    if (this.shouldRunRecoveryTest()) {
      await this.runRecoveryTest();
    }
  }

  // ë³µêµ¬ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
  async runRecoveryTest() {
    console.log('Running recovery test...');

    const testEnv = process.env.DR_TEST_ENV;

    try {
      // 1. í…ŒìŠ¤íŠ¸ í™˜ê²½ì— ë°±ì—… ë³µì›
      await this.restoreToTestEnvironment(testEnv);

      // 2. ê¸°ëŠ¥ ê²€ì¦
      await this.verifyFunctionality(testEnv);

      // 3. ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
      const metrics = await this.runPerformanceBenchmark(testEnv);

      // 4. ê²°ê³¼ ë³´ê³ 
      await this.reportRecoveryTestResults({
        success: true,
        duration: metrics.duration,
        rto_achieved: metrics.duration < this.rto
      });

    } catch (error) {
      await this.reportRecoveryTestResults({
        success: false,
        error: error.message
      });
      throw error;
    }
  }

  // ë³µêµ¬ ì ˆì°¨ ë¬¸ì„œí™”
  documentRecoveryProcedures() {
    const procedures = {
      api_failure: [
        '1. API í—¬ìŠ¤ì²´í¬ ì‹¤íŒ¨ í™•ì¸',
        '2. ë¡œë“œë°¸ëŸ°ì„œì—ì„œ ì¥ì•  ì¸ìŠ¤í„´ìŠ¤ ì œì™¸',
        '3. ëŒ€ê¸° ì¸ìŠ¤í„´ìŠ¤ë¡œ íŠ¸ë˜í”½ ë¼ìš°íŒ…',
        '4. DNS ì—…ë°ì´íŠ¸ (í•„ìš”ì‹œ)',
        '5. ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ í™•ì¸',
        '6. ì„œë¹„ìŠ¤ ì •ìƒí™” í™•ì¸'
      ],
      database_failure: [
        '1. ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨ í™•ì¸',
        '2. ì½ê¸° ì „ìš© ëª¨ë“œ ì „í™˜',
        '3. ìŠ¤íƒ ë°”ì´ DB ìƒíƒœ í™•ì¸',
        '4. ìŠ¤íƒ ë°”ì´ DBë¥¼ í”„ë¼ì´ë¨¸ë¦¬ë¡œ ìŠ¹ê²©',
        '5. ì• í”Œë¦¬ì¼€ì´ì…˜ ì—°ê²° ë¬¸ìì—´ ì—…ë°ì´íŠ¸',
        '6. ë°ì´í„° ì¼ê´€ì„± ê²€ì¦'
      ],
      complete_outage: [
        '1. ëª¨ë“  ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸',
        '2. ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì„± ê²€ì¦',
        '3. í´ë¼ìš°ë“œ ì œê³µì ìƒíƒœ í™•ì¸',
        '4. DR ì‚¬ì´íŠ¸ í™œì„±í™”',
        '5. DNS í˜ì¼ì˜¤ë²„ ì‹¤í–‰',
        '6. ì‚¬ìš©ì ì»¤ë®¤ë‹ˆì¼€ì´ì…˜'
      ]
    };

    // ë¬¸ì„œë¥¼ íŒŒì¼ë¡œ ì €ì¥
    require('fs').writeFileSync(
      './docs/disaster-recovery-procedures.json',
      JSON.stringify(procedures, null, 2)
    );
  }

  // ì•Œë¦¼ ì²´ê³„ ì„¤ì •
  setupAlertingChain() {
    this.alertChain = [
      {
        level: 1,
        delay: 0,
        contacts: ['oncall@company.com'],
        method: ['email', 'slack']
      },
      {
        level: 2,
        delay: 15 * 60 * 1000, // 15ë¶„
        contacts: ['team-lead@company.com', 'oncall-backup@company.com'],
        method: ['email', 'slack', 'sms']
      },
      {
        level: 3,
        delay: 30 * 60 * 1000, // 30ë¶„
        contacts: ['cto@company.com', 'devops-team@company.com'],
        method: ['email', 'slack', 'sms', 'phone']
      }
    ];
  }

  // íŒ€ ì•Œë¦¼
  async alertTeam(incident) {
    const startTime = Date.now();

    for (const level of this.alertChain) {
      if (Date.now() - startTime >= level.delay) {
        await this.sendAlerts(level, incident);
      }
    }
  }

  // RTO/RPO ëª¨ë‹ˆí„°ë§
  monitorRTORPO() {
    setInterval(async () => {
      const metrics = await this.calculateRecoveryMetrics();

      if (metrics.estimatedRTO > this.rto) {
        await this.alertTeam({
          severity: 'warning',
          message: `Estimated RTO (${metrics.estimatedRTO}ms) exceeds target (${this.rto}ms)`
        });
      }

      if (metrics.currentRPO > this.rpo) {
        await this.alertTeam({
          severity: 'warning',
          message: `Current RPO (${metrics.currentRPO}ms) exceeds target (${this.rpo}ms)`
        });
      }
    }, 60 * 60 * 1000); // 1ì‹œê°„ë§ˆë‹¤
  }

  // ë³µêµ¬ ë©”íŠ¸ë¦­ ê³„ì‚°
  async calculateRecoveryMetrics() {
    const backupService = require('./databaseBackup');
    const latestBackup = await backupService.getLatestBackup();

    return {
      estimatedRTO: this.estimateRecoveryTime(),
      currentRPO: Date.now() - new Date(latestBackup.created_at).getTime(),
      backupSize: latestBackup.size,
      lastTestDate: this.lastRecoveryTest
    };
  }

  // ë³µêµ¬ ì‹œê°„ ì¶”ì •
  estimateRecoveryTime() {
    // ê³¼ê±° ë³µêµ¬ í…ŒìŠ¤íŠ¸ ë°ì´í„° ê¸°ë°˜ ì¶”ì •
    const historicalData = this.getHistoricalRecoveryTimes();
    return historicalData.reduce((a, b) => a + b, 0) / historicalData.length;
  }
}

module.exports = new DisasterRecoveryPlan();

### 11.3.3 ë¡¤ë°± ì „ëµ

#### ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡¤ë°± ì‹œìŠ¤í…œ

```javascript
// deployment/rollbackStrategy.js
const { execSync } = require('child_process');
const semver = require('semver');

class RollbackStrategy {
  constructor() {
    this.deploymentHistory = [];
    this.maxHistorySize = 10;
    this.rollbackInProgress = false;
    this.healthCheckTimeout = 5 * 60 * 1000; // 5ë¶„
  }

  // ë°°í¬ ê¸°ë¡
  async recordDeployment(deployment) {
    const record = {
      id: deployment.id,
      version: deployment.version,
      timestamp: new Date().toISOString(),
      commit: deployment.commit,
      environment: deployment.environment,
      status: 'in_progress',
      metrics: {
        startTime: Date.now(),
        healthChecks: []
      }
    };

    this.deploymentHistory.unshift(record);

    // íˆìŠ¤í† ë¦¬ í¬ê¸° ì œí•œ
    if (this.deploymentHistory.length > this.maxHistorySize) {
      this.deploymentHistory.pop();
    }

    // ë°ì´í„°ë² ì´ìŠ¤ì—ë„ ì €ì¥
    await this.saveDeploymentRecord(record);

    return record;
  }

  // ìë™ ë¡¤ë°± ëª¨ë‹ˆí„°ë§
  async monitorDeployment(deploymentId) {
    const deployment = this.deploymentHistory.find(d => d.id === deploymentId);
    if (!deployment) {
      throw new Error(`Deployment ${deploymentId} not found`);
    }

    console.log(`Monitoring deployment ${deploymentId} for automatic rollback...`);

    const monitoringConfig = {
      errorRateThreshold: 5, // 5% ì—ëŸ¬ìœ¨
      responseTimeThreshold: 2000, // 2ì´ˆ
      availabilityThreshold: 99, // 99% ê°€ìš©ì„±
      monitoringDuration: 10 * 60 * 1000, // 10ë¶„
      checkInterval: 30 * 1000 // 30ì´ˆ
    };

    const endTime = Date.now() + monitoringConfig.monitoringDuration;
    let checksPassedCount = 0;
    let checksFailed = false;

    while (Date.now() < endTime && !checksFailed) {
      const healthStatus = await this.performHealthChecks(deployment);
      deployment.metrics.healthChecks.push(healthStatus);

      // ì„ê³„ê°’ ì²´í¬
      if (healthStatus.errorRate > monitoringConfig.errorRateThreshold ||
          healthStatus.avgResponseTime > monitoringConfig.responseTimeThreshold ||
          healthStatus.availability < monitoringConfig.availabilityThreshold) {

        console.error('Health check failed:', healthStatus);
        checksFailed = true;

        // ìë™ ë¡¤ë°± ì‹¤í–‰
        await this.automaticRollback(deploymentId, healthStatus);

      } else {
        checksPassedCount++;
        console.log(`Health check passed (${checksPassedCount})`);
      }

      if (!checksFailed) {
        await new Promise(resolve => setTimeout(resolve, monitoringConfig.checkInterval));
      }
    }

    // ëª¨ë‹ˆí„°ë§ ì™„ë£Œ
    if (!checksFailed) {
      deployment.status = 'success';
      console.log(`Deployment ${deploymentId} completed successfully`);
    }

    return deployment;
  }

  // í—¬ìŠ¤ì²´í¬ ìˆ˜í–‰
  async performHealthChecks(deployment) {
    const metrics = {
      timestamp: new Date().toISOString(),
      errorRate: 0,
      avgResponseTime: 0,
      availability: 100,
      checks: []
    };

    // 1. API ì—”ë“œí¬ì¸íŠ¸ ì²´í¬
    const apiChecks = await this.checkAPIEndpoints();
    metrics.checks.push(...apiChecks);

    // 2. ì—ëŸ¬ìœ¨ ê³„ì‚°
    metrics.errorRate = await this.calculateErrorRate();

    // 3. ì‘ë‹µ ì‹œê°„ ì¸¡ì •
    metrics.avgResponseTime = await this.measureResponseTime();

    // 4. ê°€ìš©ì„± ì²´í¬
    metrics.availability = await this.checkAvailability();

    // 5. ë¹„ì¦ˆë‹ˆìŠ¤ ë©”íŠ¸ë¦­ ì²´í¬
    const businessMetrics = await this.checkBusinessMetrics();
    metrics.businessHealth = businessMetrics;

    return metrics;
  }

  // API ì—”ë“œí¬ì¸íŠ¸ ì²´í¬
  async checkAPIEndpoints() {
    const endpoints = [
      { path: '/health', expectedStatus: 200 },
      { path: '/api/videos/trending', expectedStatus: 200 },
      { path: '/api/auth/status', expectedStatus: 200 }
    ];

    const results = await Promise.all(
      endpoints.map(async endpoint => {
        try {
          const response = await fetch(`${process.env.API_URL}${endpoint.path}`);
          return {
            endpoint: endpoint.path,
            status: response.status,
            success: response.status === endpoint.expectedStatus,
            responseTime: response.headers.get('x-response-time')
          };
        } catch (error) {
          return {
            endpoint: endpoint.path,
            success: false,
            error: error.message
          };
        }
      })
    );

    return results;
  }

  // ì—ëŸ¬ìœ¨ ê³„ì‚°
  async calculateErrorRate() {
    // ìµœê·¼ 5ë¶„ê°„ì˜ ì—ëŸ¬ìœ¨ ì¡°íšŒ
    const query = `
      SELECT
        COUNT(CASE WHEN status_code >= 500 THEN 1 END) * 100.0 / COUNT(*) as error_rate
      FROM api_logs
      WHERE created_at > NOW() - INTERVAL '5 minutes'
    `;

    const result = await this.executeQuery(query);
    return result.rows[0]?.error_rate || 0;
  }

  // ìë™ ë¡¤ë°± ì‹¤í–‰
  async automaticRollback(deploymentId, failureReason) {
    console.error(`Initiating automatic rollback for deployment ${deploymentId}`);

    if (this.rollbackInProgress) {
      console.warn('Rollback already in progress');
      return;
    }

    this.rollbackInProgress = true;

    try {
      // 1. ì´ì „ ì•ˆì • ë²„ì „ ì°¾ê¸°
      const targetVersion = await this.findLastStableVersion(deploymentId);

      if (!targetVersion) {
        throw new Error('No stable version found for rollback');
      }

      // 2. ì•Œë¦¼ ë°œì†¡
      await this.notifyRollback({
        deploymentId,
        targetVersion,
        reason: failureReason,
        type: 'automatic'
      });

      // 3. ë¡¤ë°± ì‹¤í–‰
      const rollbackResult = await this.executeRollback(targetVersion);

      // 4. ë¡¤ë°± ê²€ì¦
      await this.verifyRollback(rollbackResult);

      // 5. ë¡¤ë°± ì™„ë£Œ ì•Œë¦¼
      await this.notifyRollbackComplete({
        deploymentId,
        targetVersion,
        success: true
      });

      console.log(`Automatic rollback completed successfully to version ${targetVersion.version}`);

    } catch (error) {
      console.error('Automatic rollback failed:', error);

      await this.notifyRollbackComplete({
        deploymentId,
        success: false,
        error: error.message
      });

      // ìˆ˜ë™ ê°œì… ìš”ì²­
      await this.requestManualIntervention(deploymentId, error);

    } finally {
      this.rollbackInProgress = false;
    }
  }

  // ìˆ˜ë™ ë¡¤ë°±
  async manualRollback(targetVersion, reason) {
    console.log(`Initiating manual rollback to version ${targetVersion}`);

    const deployment = {
      id: `rollback-${Date.now()}`,
      version: targetVersion,
      type: 'rollback',
      reason
    };

    await this.recordDeployment(deployment);

    try {
      // Railwayë¥¼ í†µí•œ ë¡¤ë°±
      const result = await this.executeRollback({ version: targetVersion });

      deployment.status = 'success';
      return result;

    } catch (error) {
      deployment.status = 'failed';
      deployment.error = error.message;
      throw error;
    }
  }

  // ë¡¤ë°± ì‹¤í–‰
  async executeRollback(targetVersion) {
    console.log(`Executing rollback to ${targetVersion.version}`);

    // 1. Railway CLIë¥¼ ì‚¬ìš©í•œ ë¡¤ë°±
    try {
      // íŠ¹ì • ì»¤ë°‹ìœ¼ë¡œ ë¡¤ë°±
      execSync(`railway up --detach --commit ${targetVersion.commit}`, {
        stdio: 'inherit'
      });

      // ë°°í¬ ì™„ë£Œ ëŒ€ê¸°
      await this.waitForDeployment(targetVersion.version);

      return {
        success: true,
        version: targetVersion.version,
        timestamp: new Date().toISOString()
      };

    } catch (error) {
      console.error('Railway rollback failed:', error);

      // ëŒ€ì²´ ë¡¤ë°± ë°©ë²• ì‹œë„
      return await this.alternativeRollback(targetVersion);
    }
  }

  // ëŒ€ì²´ ë¡¤ë°± ë°©ë²•
  async alternativeRollback(targetVersion) {
    console.log('Attempting alternative rollback method...');

    // Docker ì´ë¯¸ì§€ ê¸°ë°˜ ë¡¤ë°±
    const imageName = `ytshorts-curator:${targetVersion.version}`;

    try {
      // ì´ì „ ë²„ì „ì˜ Docker ì´ë¯¸ì§€ë¡œ ì „í™˜
      execSync(`docker pull ${process.env.DOCKER_REGISTRY}/${imageName}`);
      execSync(`docker tag ${process.env.DOCKER_REGISTRY}/${imageName} ${imageName}`);

      // ì»¨í…Œì´ë„ˆ ì¬ì‹œì‘
      execSync(`docker-compose down && docker-compose up -d`);

      return {
        success: true,
        method: 'docker',
        version: targetVersion.version
      };

    } catch (error) {
      throw new Error(`Alternative rollback failed: ${error.message}`);
    }
  }

  // ë§ˆì§€ë§‰ ì•ˆì • ë²„ì „ ì°¾ê¸°
  async findLastStableVersion(currentDeploymentId) {
    // í˜„ì¬ ë°°í¬ ì´ì „ì˜ ì„±ê³µì ì¸ ë°°í¬ ì°¾ê¸°
    const currentIndex = this.deploymentHistory.findIndex(d => d.id === currentDeploymentId);

    for (let i = currentIndex + 1; i < this.deploymentHistory.length; i++) {
      const deployment = this.deploymentHistory[i];

      if (deployment.status === 'success' &&
          deployment.environment === this.deploymentHistory[currentIndex].environment) {

        // ì¶”ê°€ ì•ˆì •ì„± ê²€ì¦
        const isStable = await this.verifyVersionStability(deployment);
        if (isStable) {
          return deployment;
        }
      }
    }

    return null;
  }

  // ë²„ì „ ì•ˆì •ì„± ê²€ì¦
  async verifyVersionStability(deployment) {
    // í•´ë‹¹ ë²„ì „ì´ ìµœì†Œ 1ì‹œê°„ ì´ìƒ ì•ˆì •ì ìœ¼ë¡œ ìš´ì˜ë˜ì—ˆëŠ”ì§€ í™•ì¸
    const runningTime = Date.now() - new Date(deployment.timestamp).getTime();
    const minimumStableTime = 60 * 60 * 1000; // 1ì‹œê°„

    if (runningTime < minimumStableTime) {
      return false;
    }

    // í•´ë‹¹ ë²„ì „ì˜ ì—ëŸ¬ìœ¨ í™•ì¸
    const errorRate = await this.getVersionErrorRate(deployment.version);
    return errorRate < 1; // 1% ë¯¸ë§Œ
  }

  // ë¡¤ë°± ê²€ì¦
  async verifyRollback(rollbackResult) {
    console.log('Verifying rollback...');

    const verificationSteps = [
      {
        name: 'Version Check',
        verify: async () => {
          const currentVersion = await this.getCurrentVersion();
          return currentVersion === rollbackResult.version;
        }
      },
      {
        name: 'Health Check',
        verify: async () => {
          const health = await this.performHealthChecks({ version: rollbackResult.version });
          return health.availability >= 99;
        }
      },
      {
        name: 'Database Migration Check',
        verify: async () => {
          return await this.checkDatabaseCompatibility(rollbackResult.version);
        }
      },
      {
        name: 'API Compatibility Check',
        verify: async () => {
          return await this.checkAPICompatibility(rollbackResult.version);
        }
      }
    ];

    for (const step of verificationSteps) {
      console.log(`Running verification: ${step.name}`);
      const passed = await step.verify();

      if (!passed) {
        throw new Error(`Rollback verification failed: ${step.name}`);
      }
    }

    console.log('Rollback verification completed successfully');
  }

  // ë°ì´í„°ë² ì´ìŠ¤ í˜¸í™˜ì„± ì²´í¬
  async checkDatabaseCompatibility(version) {
    // ë²„ì „ë³„ ë§ˆì´ê·¸ë ˆì´ì…˜ í™•ì¸
    const migrations = await this.getDatabaseMigrations();
    const versionMigrations = migrations.filter(m =>
      semver.gt(m.version, version) && m.breaking
    );

    if (versionMigrations.length > 0) {
      console.warn('Breaking database changes detected:', versionMigrations);

      // ë¡¤ë°± ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰ í•„ìš”
      for (const migration of versionMigrations) {
        if (migration.rollback) {
          await this.executeMigrationRollback(migration);
        }
      }
    }

    return true;
  }

  // ë¡¤ë°± ì•Œë¦¼
  async notifyRollback(details) {
    const message = {
      title: 'ğŸ”„ Deployment Rollback Initiated',
      type: details.type,
      deployment: details.deploymentId,
      targetVersion: details.targetVersion.version,
      reason: details.reason,
      timestamp: new Date().toISOString()
    };

    // ë‹¤ì¤‘ ì±„ë„ ì•Œë¦¼
    await Promise.all([
      this.sendSlackNotification(message),
      this.sendEmailNotification(message),
      this.createIncidentTicket(message)
    ]);
  }

  // ì¹´ë‚˜ë¦¬ ë°°í¬ ì§€ì›
  async canaryRollback(percentage) {
    console.log(`Initiating canary rollback to ${percentage}% of traffic`);

    try {
      // ë¡œë“œë°¸ëŸ°ì„œ ì„¤ì • ì—…ë°ì´íŠ¸
      await this.updateLoadBalancerWeights({
        current: 100 - percentage,
        previous: percentage
      });

      // ë©”íŠ¸ë¦­ ëª¨ë‹ˆí„°ë§
      const canaryMetrics = await this.monitorCanaryDeployment(30 * 60 * 1000); // 30ë¶„

      if (canaryMetrics.success) {
        // ì ì§„ì  ë¡¤ë°± ì™„ë£Œ
        await this.completeCanaryRollback();
      } else {
        // ì „ì²´ ë¡¤ë°±
        await this.executeFullRollback();
      }

    } catch (error) {
      console.error('Canary rollback failed:', error);
      throw error;
    }
  }

  // ë¡¤ë°± íˆìŠ¤í† ë¦¬ ê´€ë¦¬
  async saveRollbackHistory(rollback) {
    const history = {
      ...rollback,
      id: `rollback-${Date.now()}`,
      timestamp: new Date().toISOString()
    };

    await this.supabase
      .from('rollback_history')
      .insert(history);

    return history;
  }
}

module.exports = new RollbackStrategy();

```

## DevOps í†µí•© ì˜ˆì œ

```jsx
// server.js - DevOps í†µí•©
const express = require('express');
const app = express();

// DevOps ëª¨ë“ˆ ì„í¬íŠ¸
const deploymentManager = require('./scripts/deploy');
const loggingService = require('./config/logging');
const tracingService = require('./config/tracing');
const errorTracking = require('./monitoring/errorTracking');
const alertingService = require('./monitoring/alerting');
const databaseBackup = require('./backup/databaseBackup');
const disasterRecovery = require('./disaster-recovery/drPlan');
const rollbackStrategy = require('./deployment/rollbackStrategy');

// ì´ˆê¸°í™”
async function initializeDevOps() {
  // ë¡œê¹… ì„¤ì •
  loggingService.setupExceptionHandlers();
  app.use(loggingService.expressMiddleware());

  // ì¶”ì  ì„¤ì •
  tracingService.initialize();
  app.use(tracingService.expressMiddleware());

  // ì—ëŸ¬ ì¶”ì  ì„¤ì •
  errorTracking.initialize(app);
  app.use(errorTracking.requestHandler());
  app.use(errorTracking.errorHandler());

  // ì¬í•´ ë³µêµ¬ ê³„íš ì´ˆê¸°í™”
  await disasterRecovery.initialize();
  disasterRecovery.monitorRTORPO();

  // ë°±ì—… ìŠ¤ì¼€ì¤„ ì„¤ì •
  databaseBackup.setupBackupSchedule();

  console.log('DevOps systems initialized');
}

// ë°°í¬ ì›¹í›… ì—”ë“œí¬ì¸íŠ¸
app.post('/webhook/deploy', async (req, res) => {
  const deployment = {
    id: req.body.deployment_id,
    version: req.body.version,
    commit: req.body.commit,
    environment: req.body.environment
  };

  try {
    // ë°°í¬ ê¸°ë¡
    const record = await rollbackStrategy.recordDeployment(deployment);

    // ë¹„ë™ê¸°ë¡œ ëª¨ë‹ˆí„°ë§ ì‹œì‘
    rollbackStrategy.monitorDeployment(deployment.id)
      .catch(error => {
        console.error('Deployment monitoring failed:', error);
      });

    res.json({ success: true, deploymentId: record.id });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

// ìˆ˜ë™ ë¡¤ë°± ì—”ë“œí¬ì¸íŠ¸
app.post('/api/rollback', async (req, res) => {
  try {
    const result = await rollbackStrategy.manualRollback(
      req.body.targetVersion,
      req.body.reason
    );
    res.json(result);
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

// ì‹œìŠ¤í…œ ìƒíƒœ ëŒ€ì‹œë³´ë“œ
app.get('/api/system/status', async (req, res) => {
  const status = {
    health: await disasterRecovery.getSystemHealth(),
    backups: await databaseBackup.getBackupStatus(),
    deployments: rollbackStrategy.deploymentHistory.slice(0, 5),
    alerts: await alertingService.getActiveAlerts()
  };

  res.json(status);
});

// ì„œë²„ ì‹œì‘
const PORT = process.env.PORT || 3000;
app.listen(PORT, async () => {
  await initializeDevOps();
  console.log(`Server running on port ${PORT} with full DevOps capabilities`);
});

// ì •ìƒ ì¢…ë£Œ ì²˜ë¦¬
process.on('SIGTERM', async () => {
  console.log('SIGTERM received, shutting down gracefully...');

  await tracingService.shutdown();
  await databaseBackup.performBackup('shutdown');

  process.exit(0);
});

```

### 11.3.2 ì¬í•´ ë³µêµ¬ ê³„íš

### ì¬í•´ ë³µêµ¬ ì „ëµ (Disaster Recovery Strategy)

```jsx
// disaster-recovery/drPlan.js
class DisasterRecoveryPlan {
  constructor() {
    this.rto = 4 * 60 * 60 * 1000; // Recovery Time Objective: 4ì‹œê°„
    this.rpo = 60 * 60 * 1000;     // Recovery Point Objective: 1ì‹œê°„
    this.healthChecks = new Map();
    this.failoverInProgress = false;
  }

  // DR ê³„íš ì´ˆê¸°í™”
  async initialize() {
    console.log('Initializing Disaster Recovery Plan...');

    // 1. ëª¨ë“  ì„œë¹„ìŠ¤ í—¬ìŠ¤ì²´í¬ ì„¤ì •
    this.setupHealthChecks();

    // 2. ë°±ì—… ì‹œìŠ¤í…œ ê²€ì¦
    await this.verifyBackupSystems();

    // 3. ë³µêµ¬ ì ˆì°¨ ë¬¸ì„œí™”
    this.documentRecoveryProcedures();

    // 4. íŒ€ ì•Œë¦¼ ì²´ê³„ êµ¬ì¶•
    this.setupAlertingChain();

    console.log('DR Plan initialized successfully');
  }

  // í—¬ìŠ¤ì²´í¬ ì„¤ì •
  setupHealthChecks() {
    const services = [
      {
        name: 'primary-api',
        url: process.env.PRIMARY_API_URL,
        interval: 30000, // 30ì´ˆ
        timeout: 5000,
        retries: 3
      },
      {
        name: 'database',
        checker: this.checkDatabase.bind(this),
        interval: 60000, // 1ë¶„
        timeout: 10000,
        retries: 2
      },
      {
        name: 'redis-cache',
        checker: this.checkRedis.bind(this),
        interval: 30000,
        timeout: 3000,
        retries: 3
      },
      {
        name: 'youtube-api',
        checker: this.checkYouTubeAPI.bind(this),
        interval: 300000, // 5ë¶„
        timeout: 15000,
        retries: 1
      }
    ];

    services.forEach(service => {
      this.startHealthCheck(service);
    });
  }

  // ê°œë³„ í—¬ìŠ¤ì²´í¬ ì‹œì‘
  startHealthCheck(service) {
    const check = {
      ...service,
      status: 'unknown',
      lastCheck: null,
      failureCount: 0,
      successCount: 0
    };

    this.healthChecks.set(service.name, check);

    setInterval(async () => {
      await this.performHealthCheck(service);
    }, service.interval);

    // ì´ˆê¸° ì²´í¬ ì‹¤í–‰
    this.performHealthCheck(service);
  }

  // í—¬ìŠ¤ì²´í¬ ìˆ˜í–‰
  async performHealthCheck(service) {
    const check = this.healthChecks.get(service.name);
    let isHealthy = false;

    try {
      if (service.url) {
        // URL ê¸°ë°˜ í—¬ìŠ¤ì²´í¬
        const response = await fetch(service.url, {
          timeout: service.timeout,
          signal: AbortSignal.timeout(service.timeout)
        });
        isHealthy = response.ok;
      } else if (service.checker) {
        // ì»¤ìŠ¤í…€ ì²´ì»¤
        isHealthy = await service.checker();
      }

      if (isHealthy) {
        check.status = 'healthy';
        check.successCount++;
        check.failureCount = 0;
      } else {
        throw new Error('Health check failed');
      }

    } catch (error) {
      check.failureCount++;

      if (check.failureCount >= service.retries) {
        check.status = 'unhealthy';
        await this.handleServiceFailure(service.name, error);
      } else {
        check.status = 'degraded';
      }
    }

    check.lastCheck = new Date().toISOString();
    this.healthChecks.set(service.name, check);
  }

  // ì„œë¹„ìŠ¤ ì¥ì•  ì²˜ë¦¬
  async handleServiceFailure(serviceName, error) {
    console.error(`Service failure detected: ${serviceName}`, error);

    // ì¥ì•  ìœ í˜•ë³„ ëŒ€ì‘
    switch (serviceName) {
      case 'primary-api':
        await this.initiateAPIFailover();
        break;
      case 'database':
        await this.initiateDatabaseFailover();
        break;
      case 'redis-cache':
        await this.handleCacheFailure();
        break;
      case 'youtube-api':
        await this.handleYouTubeAPIFailure();
        break;
    }

    // íŒ€ ì•Œë¦¼
    await this.alertTeam({
      severity: 'critical',
      service: serviceName,
      error: error.message,
      action: 'automatic-failover-initiated'
    });
  }

  // API í˜ì¼ì˜¤ë²„
  async initiateAPIFailover() {
    if (this.failoverInProgress) return;

    this.failoverInProgress = true;
    console.log('Initiating API failover...');

    try {
      // 1. íŠ¸ë˜í”½ ë¼ìš°íŒ… ë³€ê²½
      await this.updateLoadBalancer({
        primary: false,
        secondary: true
      });

      // 2. DNS ì—…ë°ì´íŠ¸
      await this.updateDNS({
        record: 'api.ytshorts-curator.com',
        target: process.env.SECONDARY_API_URL
      });

      // 3. ìºì‹œ ì›Œë°
      await this.warmSecondaryCache();

      // 4. í—¬ìŠ¤ì²´í¬ í™•ì¸
      await this.verifyFailover('api');

      console.log('API failover completed successfully');

    } catch (error) {
      console.error('API failover failed:', error);
      await this.initiateManualRecovery('api', error);
    } finally {
      this.failoverInProgress = false;
    }
  }

  // ë°ì´í„°ë² ì´ìŠ¤ í˜ì¼ì˜¤ë²„
  async initiateDatabaseFailover() {
    console.log('Initiating database failover...');

    try {
      // 1. ì½ê¸° ì „ìš© ëª¨ë“œ í™œì„±í™”
      await this.enableReadOnlyMode();

      // 2. ìŠ¤íƒ ë°”ì´ DB ìŠ¹ê²©
      await this.promoteStandbyDatabase();

      // 3. ì—°ê²° ë¬¸ìì—´ ì—…ë°ì´íŠ¸
      process.env.DATABASE_URL = process.env.STANDBY_DATABASE_URL;

      // 4. ì• í”Œë¦¬ì¼€ì´ì…˜ ì¬ì‹œì‘
      await this.gracefulRestart();

      // 5. ë°ì´í„° ë™ê¸°í™” í™•ì¸
      await this.verifyDatabaseSync();

      console.log('Database failover completed');

    } catch (error) {
      console.error('Database failover failed:', error);
      await this.executeEmergencyBackupRestore();
    }
  }

  // ìºì‹œ ì¥ì•  ì²˜ë¦¬
  async handleCacheFailure() {
    console.log('Handling cache failure...');

    // 1. ìºì‹œ ë°”ì´íŒ¨ìŠ¤ ëª¨ë“œ í™œì„±í™”
    process.env.CACHE_BYPASS = 'true';

    // 2. ë©”ëª¨ë¦¬ ìºì‹œë¡œ í´ë°±
    const memoryCache = require('../services/memoryCache');
    memoryCache.activate();

    // 3. Redis í´ëŸ¬ìŠ¤í„° ì¬êµ¬ì„± ì‹œë„
    try {
      await this.reconfigureRedisCluster();
    } catch (error) {
      console.error('Redis recovery failed, continuing with memory cache');
    }
  }

  // YouTube API ì¥ì•  ì²˜ë¦¬
  async handleYouTubeAPIFailure() {
    console.log('Handling YouTube API failure...');

    // 1. ìºì‹œ ì „ìš© ëª¨ë“œ í™œì„±í™”
    process.env.CACHE_ONLY_MODE = 'true';

    // 2. ëŒ€ì²´ ë°ì´í„° ì†ŒìŠ¤ í™œì„±í™”
    await this.activateAlternativeDataSources();

    // 3. ì‚¬ìš©ìì—ê²Œ ì œí•œëœ ê¸°ëŠ¥ ì•Œë¦¼
    await this.notifyUsersOfDegradedService();
  }

  // ë°±ì—… ì‹œìŠ¤í…œ ê²€ì¦
  async verifyBackupSystems() {
    const backupService = require('./databaseBackup');

    // 1. ìµœì‹  ë°±ì—… í™•ì¸
    const latestBackup = await backupService.getLatestBackup();
    const backupAge = Date.now() - new Date(latestBackup.created_at).getTime();

    if (backupAge > this.rpo) {
      throw new Error(`Latest backup is too old: ${backupAge / 1000 / 60} minutes`);
    }

    // 2. ë°±ì—… ë¬´ê²°ì„± ê²€ì¦
    const isValid = await backupService.verifyBackupIntegrity(latestBackup.id);
    if (!isValid) {
      throw new Error('Latest backup integrity check failed');
    }

    // 3. ë³µêµ¬ í…ŒìŠ¤íŠ¸ (ì›” 1íšŒ)
    if (this.shouldRunRecoveryTest()) {
      await this.runRecoveryTest();
    }
  }

  // ë³µêµ¬ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
  async runRecoveryTest() {
    console.log('Running recovery test...');

    const testEnv = process.env.DR_TEST_ENV;

    try {
      // 1. í…ŒìŠ¤íŠ¸ í™˜ê²½ì— ë°±ì—… ë³µì›
      await this.restoreToTestEnvironment(testEnv);

      // 2. ê¸°ëŠ¥ ê²€ì¦
      await this.verifyFunctionality(testEnv);

      // 3. ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
      const metrics = await this.runPerformanceBenchmark(testEnv);

      // 4. ê²°ê³¼ ë³´ê³ 
      await this.reportRecoveryTestResults({
        success: true,
        duration: metrics.duration,
        rto_achieved: metrics.duration < this.rto
      });

    } catch (error) {
      await this.reportRecoveryTestResults({
        success: false,
        error: error.message
      });
      throw error;
    }
  }

  // ë³µêµ¬ ì ˆì°¨ ë¬¸ì„œí™”
  documentRecoveryProcedures() {
    const procedures = {
      api_failure: [
        '1. API í—¬ìŠ¤ì²´í¬ ì‹¤íŒ¨ í™•ì¸',
        '2. ë¡œë“œë°¸ëŸ°ì„œì—ì„œ ì¥ì•  ì¸ìŠ¤í„´ìŠ¤ ì œì™¸',
        '3. ëŒ€ê¸° ì¸ìŠ¤í„´ìŠ¤ë¡œ íŠ¸ë˜í”½ ë¼ìš°íŒ…',
        '4. DNS ì—…ë°ì´íŠ¸ (í•„ìš”ì‹œ)',
        '5. ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ í™•ì¸',
        '6. ì„œë¹„ìŠ¤ ì •ìƒí™” í™•ì¸'
      ],
      database_failure: [
        '1. ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨ í™•ì¸',
        '2. ì½ê¸° ì „ìš© ëª¨ë“œ ì „í™˜',
        '3. ìŠ¤íƒ ë°”ì´ DB ìƒíƒœ í™•ì¸',
        '4. ìŠ¤íƒ ë°”ì´ DBë¥¼ í”„ë¼ì´ë¨¸ë¦¬ë¡œ ìŠ¹ê²©',
        '5. ì• í”Œë¦¬ì¼€ì´ì…˜ ì—°ê²° ë¬¸ìì—´ ì—…ë°ì´íŠ¸',
        '6. ë°ì´í„° ì¼ê´€ì„± ê²€ì¦'
      ],
      complete_outage: [
        '1. ëª¨ë“  ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸',
        '2. ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì„± ê²€ì¦',
        '3. í´ë¼ìš°ë“œ ì œê³µì ìƒíƒœ í™•ì¸',
        '4. DR ì‚¬ì´íŠ¸ í™œì„±í™”',
        '5. DNS í˜ì¼ì˜¤ë²„ ì‹¤í–‰',
        '6. ì‚¬ìš©ì ì»¤ë®¤ë‹ˆì¼€ì´ì…˜'
      ]
    };

    // ë¬¸ì„œë¥¼ íŒŒì¼ë¡œ ì €ì¥
    require('fs').writeFileSync(
      './docs/disaster-recovery-procedures.json',
      JSON.stringify(procedures, null, 2)
    );
  }

  // ì•Œë¦¼ ì²´ê³„ ì„¤ì •
  setupAlertingChain() {
    this.alertChain = [
      {
        level: 1,
        delay: 0,
        contacts: ['oncall@company.com'],
        method: ['email', 'slack']
      },
      {
        level: 2,
        delay: 15 * 60 * 1000, // 15ë¶„
        contacts: ['team-lead@company.com', 'oncall-backup@company.com'],
        method: ['email', 'slack', 'sms']
      },
      {
        level: 3,
        delay: 30 * 60 * 1000, // 30ë¶„
        contacts: ['cto@company.com', 'devops-team@company.com'],
        method: ['email', 'slack', 'sms', 'phone']
      }
    ];
  }

  // íŒ€ ì•Œë¦¼
  async alertTeam(incident) {
    const startTime = Date.now();

    for (const level of this.alertChain) {
      if (Date.now() - startTime >= level.delay) {
        await this.sendAlerts(level, incident);
      }
    }
  }

  // RTO/RPO ëª¨ë‹ˆí„°ë§
  monitorRTORPO() {
    setInterval(async () => {
      const metrics = await this.calculateRecoveryMetrics();

      if (metrics.estimatedRTO > this.rto) {
        await this.alertTeam({
          severity: 'warning',
          message: `Estimated RTO (${metrics.estimatedRTO}ms) exceeds target (${this.rto}ms)`
        });
      }

      if (metrics.currentRPO > this.rpo) {
        await this.alertTeam({
          severity: 'warning',
          message: `Current RPO (${metrics.currentRPO}ms) exceeds target (${this.rpo}ms)`
        });
      }
    }, 60 * 60 * 1000); // 1ì‹œê°„ë§ˆë‹¤
  }

  // ë³µêµ¬ ë©”íŠ¸ë¦­ ê³„ì‚°
  async calculateRecoveryMetrics() {
    const backupService = require('./databaseBackup');
    const latestBackup = await backupService.getLatestBackup();

    return {
      estimatedRTO: this.estimateRecoveryTime(),
      currentRPO: Date.now() - new Date(latestBackup.created_at).getTime(),
      backupSize: latestBackup.size,
      lastTestDate: this.lastRecoveryTest
    };
  }

  // ë³µêµ¬ ì‹œê°„ ì¶”ì •
  estimateRecoveryTime() {
    // ê³¼ê±° ë³µêµ¬ í…ŒìŠ¤íŠ¸ ë°ì´í„° ê¸°ë°˜ ì¶”ì •
    const historicalData = this.getHistoricalRecoveryTimes();
    return historicalData.reduce((a, b) => a + b, 0) / historicalData.length;
  }
}

module.exports = new DisasterRecoveryPlan();

```

### 11.3.3 ë¡¤ë°± ì „ëµ

### ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡¤ë°± ì‹œìŠ¤í…œ

```jsx
// deployment/rollbackStrategy.js
const { execSync } = require('child_process');
const semver = require('semver');

class RollbackStrategy {
  constructor() {
    this.deploymentHistory = [];
    this.maxHistorySize = 10;
    this.rollbackInProgress = false;
    this.healthCheckTimeout = 5 * 60 * 1000; // 5ë¶„
  }

  // ë°°í¬ ê¸°ë¡
  async recordDeployment(deployment) {
    const record = {
      id: deployment.id,
      version: deployment.version,
      timestamp: new Date().toISOString(),
      commit: deployment.commit,
      environment: deployment.environment,
      status: 'in_progress',
      metrics: {
        startTime: Date.now(),
        healthChecks: []
      }
    };

    this.deploymentHistory.unshift(record);

    // íˆìŠ¤í† ë¦¬ í¬ê¸° ì œí•œ
    if (this.deploymentHistory.length > this.maxHistorySize) {
      this.deploymentHistory.pop();
    }

    // ë°ì´í„°ë² ì´ìŠ¤ì—ë„ ì €ì¥
    await this.saveDeploymentRecord(record);

    return record;
  }

  // ìë™ ë¡¤ë°± ëª¨ë‹ˆí„°ë§
  async monitorDeployment(deploymentId) {
    const deployment = this.deploymentHistory.find(d => d.id === deploymentId);
    if (!deployment) {
      throw new Error(`Deployment ${deploymentId} not found`);
    }

    console.log(`Monitoring deployment ${deploymentId} for automatic rollback...`);

    const monitoringConfig = {
      errorRateThreshold: 5, // 5% ì—ëŸ¬ìœ¨
      responseTimeThreshold: 2000, // 2ì´ˆ
      availabilityThreshold: 99, // 99% ê°€ìš©ì„±
      monitoringDuration: 10 * 60 * 1000, // 10ë¶„
      checkInterval: 30 * 1000 // 30ì´ˆ
    };

    const endTime = Date.now() + monitoringConfig.monitoringDuration;
    let checksPassedCount = 0;
    let checksFailed = false;

    while (Date.now() < endTime && !checksFailed) {
      const healthStatus = await this.performHealthChecks(deployment);
      deployment.metrics.healthChecks.push(healthStatus);

      // ì„ê³„ê°’ ì²´í¬
      if (healthStatus.errorRate > monitoringConfig.errorRateThreshold ||
          healthStatus.avgResponseTime > monitoringConfig.responseTimeThreshold ||
          healthStatus.availability < monitoringConfig.availabilityThreshold) {

        console.error('Health check failed:', healthStatus);
        checksFailed = true;

        // ìë™ ë¡¤ë°± ì‹¤í–‰
        await this.automaticRollback(deploymentId, healthStatus);

      } else {
        checksPassedCount++;
        console.log(`Health check passed (${checksPassedCount})`);
      }

      if (!checksFailed) {
        await new Promise(resolve => setTimeout(resolve, monitoringConfig.checkInterval));
      }
    }

    // ëª¨ë‹ˆí„°ë§ ì™„ë£Œ
    if (!checksFailed) {
      deployment.status = 'success';
      console.log(`Deployment ${deploymentId} completed successfully`);
    }

    return deployment;
  }

  // í—¬ìŠ¤ì²´í¬ ìˆ˜í–‰
  async performHealthChecks(deployment) {
    const metrics = {
      timestamp: new Date().toISOString(),
      errorRate: 0,
      avgResponseTime: 0,
      availability: 100,
      checks: []
    };

    // 1. API ì—”ë“œí¬ì¸íŠ¸ ì²´í¬
    const apiChecks = await this.checkAPIEndpoints();
    metrics.checks.push(...apiChecks);

    // 2. ì—ëŸ¬ìœ¨ ê³„ì‚°
    metrics.errorRate = await this.calculateErrorRate();

    // 3. ì‘ë‹µ ì‹œê°„ ì¸¡ì •
    metrics.avgResponseTime = await this.measureResponseTime();

    // 4. ê°€ìš©ì„± ì²´í¬
    metrics.availability = await this.checkAvailability();

    // 5. ë¹„ì¦ˆë‹ˆìŠ¤ ë©”íŠ¸ë¦­ ì²´í¬
    const businessMetrics = await this.checkBusinessMetrics();
    metrics.businessHealth = businessMetrics;

    return metrics;
  }

  // API ì—”ë“œí¬ì¸íŠ¸ ì²´í¬
  async checkAPIEndpoints() {
    const endpoints = [
      { path: '/health', expectedStatus: 200 },
      { path: '/api/videos/trending', expectedStatus: 200 },
      { path: '/api/auth/status', expectedStatus: 200 }
    ];

    const results = await Promise.all(
      endpoints.map(async endpoint => {
        try {
          const response = await fetch(`${process.env.API_URL}${endpoint.path}`);
          return {
            endpoint: endpoint.path,
            status: response.status,
            success: response.status === endpoint.expectedStatus,
            responseTime: response.headers.get('x-response-time')
          };
        } catch (error) {
          return {
            endpoint: endpoint.path,
            success: false,
            error: error.message
          };
        }
      })
    );

    return results;
  }

  // ì—ëŸ¬ìœ¨ ê³„ì‚°
  async calculateErrorRate() {
    // ìµœê·¼ 5ë¶„ê°„ì˜ ì—ëŸ¬ìœ¨ ì¡°íšŒ
    const query = `
      SELECT
        COUNT(CASE WHEN status_code >= 500 THEN 1 END) * 100.0 / COUNT(*) as error_rate
      FROM api_logs
      WHERE created_at > NOW() - INTERVAL '5 minutes'
    `;

    const result = await this.executeQuery(query);
    return result.rows[0]?.error_rate || 0;
  }

  // ìë™ ë¡¤ë°± ì‹¤í–‰
  async automaticRollback(deploymentId, failureReason) {
    console.error(`Initiating automatic rollback for deployment ${deploymentId}`);

    if (this.rollbackInProgress) {
      console.warn('Rollback already in progress');
      return;
    }

    this.rollbackInProgress = true;

    try {
      // 1. ì´ì „ ì•ˆì • ë²„ì „ ì°¾ê¸°
      const targetVersion = await this.findLastStableVersion(deploymentId);

      if (!targetVersion) {
        throw new Error('No stable version found for rollback');
      }

      // 2. ì•Œë¦¼ ë°œì†¡
      await this.notifyRollback({
        deploymentId,
        targetVersion,
        reason: failureReason,
        type: 'automatic'
      });

      // 3. ë¡¤ë°± ì‹¤í–‰
      const rollbackResult = await this.executeRollback(targetVersion);

      // 4. ë¡¤ë°± ê²€ì¦
      await this.verifyRollback(rollbackResult);

      // 5. ë¡¤ë°± ì™„ë£Œ ì•Œë¦¼
      await this.notifyRollbackComplete({
        deploymentId,
        targetVersion,
        success: true
      });

      console.log(`Automatic rollback completed successfully to version ${targetVersion.version}`);

    } catch (error) {
      console.error('Automatic rollback failed:', error);

      await this.notifyRollbackComplete({
        deploymentId,
        success: false,
        error: error.message
      });

      // ìˆ˜ë™ ê°œì… ìš”ì²­
      await this.requestManualIntervention(deploymentId, error);

    } finally {
      this.rollbackInProgress = false;
    }
  }

  // ìˆ˜ë™ ë¡¤ë°±
  async manualRollback(targetVersion, reason) {
    console.log(`Initiating manual rollback to version ${targetVersion}`);

    const deployment = {
      id: `rollback-${Date.now()}`,
      version: targetVersion,
      type: 'rollback',
      reason
    };

    await this.recordDeployment(deployment);

    try {
      // Railwayë¥¼ í†µí•œ ë¡¤ë°±
      const result = await this.executeRollback({ version: targetVersion });

      deployment.status = 'success';
      return result;

    } catch (error) {
      deployment.status = 'failed';
      deployment.error = error.message;
      throw error;
    }
  }

  // ë¡¤ë°± ì‹¤í–‰
  async executeRollback(targetVersion) {
    console.log(`Executing rollback to ${targetVersion.version}`);

    // 1. Railway CLIë¥¼ ì‚¬ìš©í•œ ë¡¤ë°±
    try {
      // íŠ¹ì • ì»¤ë°‹ìœ¼ë¡œ ë¡¤ë°±
      execSync(`railway up --detach --commit ${targetVersion.commit}`, {
        stdio: 'inherit'
      });

      // ë°°í¬ ì™„ë£Œ ëŒ€ê¸°
      await this.waitForDeployment(targetVersion.version);

      return {
        success: true,
        version: targetVersion.version,
        timestamp: new Date().toISOString()
      };

    } catch (error) {
      console.error('Railway rollback failed:', error);

      // ëŒ€ì²´ ë¡¤ë°± ë°©ë²• ì‹œë„
      return await this.alternativeRollback(targetVersion);
    }
  }

  // ëŒ€ì²´ ë¡¤ë°± ë°©ë²•
  async alternativeRollback(targetVersion) {
    console.log('Attempting alternative rollback method...');

    // Docker ì´ë¯¸ì§€ ê¸°ë°˜ ë¡¤ë°±
    const imageName = `ytshorts-curator:${targetVersion.version}`;

    try {
      // ì´ì „ ë²„ì „ì˜ Docker ì´ë¯¸ì§€ë¡œ ì „í™˜
      execSync(`docker pull ${process.env.DOCKER_REGISTRY}/${imageName}`);
      execSync(`docker tag ${process.env.DOCKER_REGISTRY}/${imageName} ${imageName}`);

      // ì»¨í…Œì´ë„ˆ ì¬ì‹œì‘
      execSync(`docker-compose down && docker-compose up -d`);

      return {
        success: true,
        method: 'docker',
        version: targetVersion.version
      };

    } catch (error) {
      throw new Error(`Alternative rollback failed: ${error.message}`);
    }
  }

  // ë§ˆì§€ë§‰ ì•ˆì • ë²„ì „ ì°¾ê¸°
  async findLastStableVersion(currentDeploymentId) {
    // í˜„ì¬ ë°°í¬ ì´ì „ì˜ ì„±ê³µì ì¸ ë°°í¬ ì°¾ê¸°
    const currentIndex = this.deploymentHistory.findIndex(d => d.id === currentDeploymentId);

    for (let i = currentIndex + 1; i < this.deploymentHistory.length; i++) {
      const deployment = this.deploymentHistory[i];

      if (deployment.status === 'success' &&
          deployment.environment === this.deploymentHistory[currentIndex].environment) {

        // ì¶”ê°€ ì•ˆì •ì„± ê²€ì¦
        const isStable = await this.verifyVersionStability(deployment);
        if (isStable) {
          return deployment;
        }
      }
    }

    return null;
  }

  // ë²„ì „ ì•ˆì •ì„± ê²€ì¦
  async verifyVersionStability(deployment) {
    // í•´ë‹¹ ë²„ì „ì´ ìµœì†Œ 1ì‹œê°„ ì´ìƒ ì•ˆì •ì ìœ¼ë¡œ ìš´ì˜ë˜ì—ˆëŠ”ì§€ í™•ì¸
    const runningTime = Date.now() - new Date(deployment.timestamp).getTime();
    const minimumStableTime = 60 * 60 * 1000; // 1ì‹œê°„

    if (runningTime < minimumStableTime) {
      return false;
    }

    // í•´ë‹¹ ë²„ì „ì˜ ì—ëŸ¬ìœ¨ í™•ì¸
    const errorRate = await this.getVersionErrorRate(deployment.version);
    return errorRate < 1; // 1% ë¯¸ë§Œ
  }

  // ë¡¤ë°± ê²€ì¦
  async verifyRollback(rollbackResult) {
    console.log('Verifying rollback...');

    const verificationSteps = [
      {
        name: 'Version Check',
        verify: async () => {
          const currentVersion = await this.getCurrentVersion();
          return currentVersion === rollbackResult.version;
        }
      },
      {
        name: 'Health Check',
        verify: async () => {
          const health = await this.performHealthChecks({ version: rollbackResult.version });
          return health.availability >= 99;
        }
      },
      {
        name: 'Database Migration Check',
        verify: async () => {
          return await this.checkDatabaseCompatibility(rollbackResult.version);
        }
      },
      {
        name: 'API Compatibility Check',
        verify: async () => {
          return await this.checkAPICompatibility(rollbackResult.version);
        }
      }
    ];

    for (const step of verificationSteps) {
      console.log(`Running verification: ${step.name}`);
      const passed = await step.verify();

      if (!passed) {
        throw new Error(`Rollback verification failed: ${step.name}`);
      }
    }

    console.log('Rollback verification completed successfully');
  }

  // ë°ì´í„°ë² ì´ìŠ¤ í˜¸í™˜ì„± ì²´í¬
  async checkDatabaseCompatibility(version) {
    // ë²„ì „ë³„ ë§ˆì´ê·¸ë ˆì´ì…˜ í™•ì¸
    const migrations = await this.getDatabaseMigrations();
    const versionMigrations = migrations.filter(m =>
      semver.gt(m.version, version) && m.breaking
    );

    if (versionMigrations.length > 0) {
      console.warn('Breaking database changes detected:', versionMigrations);

      // ë¡¤ë°± ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰ í•„ìš”
      for (const migration of versionMigrations) {
        if (migration.rollback) {
          await this.executeMigrationRollback(migration);
        }
      }
    }

    return true;
  }

  // ë¡¤ë°± ì•Œë¦¼
  async notifyRollback(details) {
    const message = {
      title: 'ğŸ”„ Deployment Rollback Initiated',
      type: details.type,
      deployment: details.deploymentId,
      targetVersion: details.targetVersion.version,
      reason: details.reason,
      timestamp: new Date().toISOString()
    };

    // ë‹¤ì¤‘ ì±„ë„ ì•Œë¦¼
    await Promise.all([
      this.sendSlackNotification(message),
      this.sendEmailNotification(message),
      this.createIncidentTicket(message)
    ]);
  }

  // ì¹´ë‚˜ë¦¬ ë°°í¬ ì§€ì›
  async canaryRollback(percentage) {
    console.log(`Initiating canary rollback to ${percentage}% of traffic`);

    try {
      // ë¡œë“œë°¸ëŸ°ì„œ ì„¤ì • ì—…ë°ì´íŠ¸
      await this.updateLoadBalancerWeights({
        current: 100 - percentage,
        previous: percentage
      });

      // ë©”íŠ¸ë¦­ ëª¨ë‹ˆí„°ë§
      const canaryMetrics = await this.monitorCanaryDeployment(30 * 60 * 1000); // 30ë¶„

      if (canaryMetrics.success) {
        // ì ì§„ì  ë¡¤ë°± ì™„ë£Œ
        await this.completeCanaryRollback();
      } else {
        // ì „ì²´ ë¡¤ë°±
        await this.executeFullRollback();
      }

    } catch (error) {
      console.error('Canary rollback failed:', error);
      throw error;
    }
  }

  // ë¡¤ë°± íˆìŠ¤í† ë¦¬ ê´€ë¦¬
  async saveRollbackHistory(rollback) {
    const history = {
      ...rollback,
      id: `rollback-${Date.now()}`,
      timestamp: new Date().toISOString()
    };

    await this.supabase
      .from('rollback_history')
      .insert(history);

    return history;
  }
}

module.exports = new RollbackStrategy();

```

## DevOps í†µí•© ì˜ˆì œ

```jsx
// server.js - DevOps í†µí•©
const express = require('express');
const app = express();

// DevOps ëª¨ë“ˆ ì„í¬íŠ¸
const deploymentManager = require('./scripts/deploy');
const loggingService = require('./config/logging');
const tracingService = require('./config/tracing');
const errorTracking = require('./monitoring/errorTracking');
const alertingService = require('./monitoring/alerting');
const databaseBackup = require('./backup/databaseBackup');
const disasterRecovery = require('./disaster-recovery/drPlan');
const rollbackStrategy = require('./deployment/rollbackStrategy');

// ì´ˆê¸°í™”
async function initializeDevOps() {
  // ë¡œê¹… ì„¤ì •
  loggingService.setupExceptionHandlers();
  app.use(loggingService.expressMiddleware());

  // ì¶”ì  ì„¤ì •
  tracingService.initialize();
  app.use(tracingService.expressMiddleware());

  // ì—ëŸ¬ ì¶”ì  ì„¤ì •
  errorTracking.initialize(app);
  app.use(errorTracking.requestHandler());
  app.use(errorTracking.errorHandler());

  // ì¬í•´ ë³µêµ¬ ê³„íš ì´ˆê¸°í™”
  await disasterRecovery.initialize();
  disasterRecovery.monitorRTORPO();

  // ë°±ì—… ìŠ¤ì¼€ì¤„ ì„¤ì •
  databaseBackup.setupBackupSchedule();

  console.log('DevOps systems initialized');
}

// ë°°í¬ ì›¹í›… ì—”ë“œí¬ì¸íŠ¸
app.post('/webhook/deploy', async (req, res) => {
  const deployment = {
    id: req.body.deployment_id,
    version: req.body.version,
    commit: req.body.commit,
    environment: req.body.environment
  };

  try {
    // ë°°í¬ ê¸°ë¡
    const record = await rollbackStrategy.recordDeployment(deployment);

    // ë¹„ë™ê¸°ë¡œ ëª¨ë‹ˆí„°ë§ ì‹œì‘
    rollbackStrategy.monitorDeployment(deployment.id)
      .catch(error => {
        console.error('Deployment monitoring failed:', error);
      });

    res.json({ success: true, deploymentId: record.id });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

// ìˆ˜ë™ ë¡¤ë°± ì—”ë“œí¬ì¸íŠ¸
app.post('/api/rollback', async (req, res) => {
  try {
    const result = await rollbackStrategy.manualRollback(
      req.body.targetVersion,
      req.body.reason
    );
    res.json(result);
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

// ì‹œìŠ¤í…œ ìƒíƒœ ëŒ€ì‹œë³´ë“œ
app.get('/api/system/status', async (req, res) => {
  const status = {
    health: await disasterRecovery.getSystemHealth(),
    backups: await databaseBackup.getBackupStatus(),
    deployments: rollbackStrategy.deploymentHistory.slice(0, 5),
    alerts: await alertingService.getActiveAlerts()
  };

  res.json(status);
});

// ì„œë²„ ì‹œì‘
const PORT = process.env.PORT || 3000;
app.listen(PORT, async () => {
  await initializeDevOps();
  console.log(`Server running on port ${PORT} with full DevOps capabilities`);
});

// ì •ìƒ ì¢…ë£Œ ì²˜ë¦¬
process.on('SIGTERM', async () => {
  console.log('SIGTERM received, shutting down gracefully...');

  await tracingService.shutdown();
  await databaseBackup.performBackup('shutdown');

  process.exit(0);
});

```

### 11.3.2 ì¬í•´ ë³µêµ¬ ê³„íš

### ì¬í•´ ë³µêµ¬ ì „ëµ (Disaster Recovery Strategy)

```jsx
// disaster-recovery/drPlan.js
class DisasterRecoveryPlan {
  constructor() {
    this.rto = 4 * 60 * 60 * 1000; // Recovery Time Objective: 4ì‹œê°„
    this.rpo = 60 * 60 * 1000;     // Recovery Point Objective: 1ì‹œê°„
    this.healthChecks = new Map();
    this.failoverInProgress = false;
  }

  // DR ê³„íš ì´ˆê¸°í™”
  async initialize() {
    console.log('Initializing Disaster Recovery Plan...');

    // 1. ëª¨ë“  ì„œë¹„ìŠ¤ í—¬ìŠ¤ì²´í¬ ì„¤ì •
    this.setupHealthChecks();

    // 2. ë°±ì—… ì‹œìŠ¤í…œ ê²€ì¦
    await this.verifyBackupSystems();

    // 3. ë³µêµ¬ ì ˆì°¨ ë¬¸ì„œí™”
    this.documentRecoveryProcedures();

    // 4. íŒ€ ì•Œë¦¼ ì²´ê³„ êµ¬ì¶•
    this.setupAlertingChain();

    console.log('DR Plan initialized successfully');
  }

  // í—¬ìŠ¤ì²´í¬ ì„¤ì •
  setupHealthChecks() {
    const services = [
      {
        name: 'primary-api',
        url: process.env.PRIMARY_API_URL,
        interval: 30000, // 30ì´ˆ
        timeout: 5000,
        retries: 3
      },
      {
        name: 'database',
        checker: this.checkDatabase.bind(this),
        interval: 60000, // 1ë¶„
        timeout: 10000,
        retries: 2
      },
      {
        name: 'redis-cache',
        checker: this.checkRedis.bind(this),
        interval: 30000,
        timeout: 3000,
        retries: 3
      },
      {
        name: 'youtube-api',
        checker: this.checkYouTubeAPI.bind(this),
        interval: 300000, // 5ë¶„
        timeout: 15000,
        retries: 1
      }
    ];

    services.forEach(service => {
      this.startHealthCheck(service);
    });
  }

  // ê°œë³„ í—¬ìŠ¤ì²´í¬ ì‹œì‘
  startHealthCheck(service) {
    const check = {
      ...service,
      status: 'unknown',
      lastCheck: null,
      failureCount: 0,
      successCount: 0
    };

    this.healthChecks.set(service.name, check);

    setInterval(async () => {
      await this.performHealthCheck(service);
    }, service.interval);

    // ì´ˆê¸° ì²´í¬ ì‹¤í–‰
    this.performHealthCheck(service);
  }

  // í—¬ìŠ¤ì²´í¬ ìˆ˜í–‰
  async performHealthCheck(service) {
    const check = this.healthChecks.get(service.name);
    let isHealthy = false;

    try {
      if (service.url) {
        // URL ê¸°ë°˜ í—¬ìŠ¤ì²´í¬
        const response = await fetch(service.url, {
          timeout: service.timeout,
          signal: AbortSignal.timeout(service.timeout)
        });
        isHealthy = response.ok;
      } else if (service.checker) {
        // ì»¤ìŠ¤í…€ ì²´ì»¤
        isHealthy = await service.checker();
      }

      if (isHealthy) {
        check.status = 'healthy';
        check.successCount++;
        check.failureCount = 0;
      } else {
        throw new Error('Health check failed');
      }

    } catch (error) {
      check.failureCount++;

      if (check.failureCount >= service.retries) {
        check.status = 'unhealthy';
        await this.handleServiceFailure(service.name, error);
      } else {
        check.status = 'degraded';
      }
    }

    check.lastCheck = new Date().toISOString();
    this.healthChecks.set(service.name, check);
  }

  // ì„œë¹„ìŠ¤ ì¥ì•  ì²˜ë¦¬
  async handleServiceFailure(serviceName, error) {
    console.error(`Service failure detected: ${serviceName}`, error);

    // ì¥ì•  ìœ í˜•ë³„ ëŒ€ì‘
    switch (serviceName) {
      case 'primary-api':
        await this.initiateAPIFailover();
        break;
      case 'database':
        await this.initiateDatabaseFailover();
        break;
      case 'redis-cache':
        await this.handleCacheFailure();
        break;
      case 'youtube-api':
        await this.handleYouTubeAPIFailure();
        break;
    }

    // íŒ€ ì•Œë¦¼
    await this.alertTeam({
      severity: 'critical',
      service: serviceName,
      error: error.message,
      action: 'automatic-failover-initiated'
    });
  }

  // API í˜ì¼ì˜¤ë²„
  async initiateAPIFailover() {
    if (this.failoverInProgress) return;

    this.failoverInProgress = true;
    console.log('Initiating API failover...');

    try {
      // 1. íŠ¸ë˜í”½ ë¼ìš°íŒ… ë³€ê²½
      await this.updateLoadBalancer({
        primary: false,
        secondary: true
      });

      // 2. DNS ì—…ë°ì´íŠ¸
      await this.updateDNS({
        record: 'api.ytshorts-curator.com',
        target: process.env.SECONDARY_API_URL
      });

      // 3. ìºì‹œ ì›Œë°
      await this.warmSecondaryCache();

      // 4. í—¬ìŠ¤ì²´í¬ í™•ì¸
      await this.verifyFailover('api');

      console.log('API failover completed successfully');

    } catch (error) {
      console.error('API failover failed:', error);
      await this.initiateManualRecovery('api', error);
    } finally {
      this.failoverInProgress = false;
    }
  }

  // ë°ì´í„°ë² ì´ìŠ¤ í˜ì¼ì˜¤ë²„
  async initiateDatabaseFailover() {
    console.log('Initiating database failover...');

    try {
      // 1. ì½ê¸° ì „ìš© ëª¨ë“œ í™œì„±í™”
      await this.enableReadOnlyMode();

      // 2. ìŠ¤íƒ ë°”ì´ DB ìŠ¹ê²©
      await this.promoteStandbyDatabase();

      // 3. ì—°ê²° ë¬¸ìì—´ ì—…ë°ì´íŠ¸
      process.env.DATABASE_URL = process.env.STANDBY_DATABASE_URL;

      // 4. ì• í”Œë¦¬ì¼€ì´ì…˜ ì¬ì‹œì‘
      await this.gracefulRestart();

      // 5. ë°ì´í„° ë™ê¸°í™” í™•ì¸
      await this.verifyDatabaseSync();

      console.log('Database failover completed');

    } catch (error) {
      console.error('Database failover failed:', error);
      await this.executeEmergencyBackupRestore();
    }
  }

  // ìºì‹œ ì¥ì•  ì²˜ë¦¬
  async handleCacheFailure() {
    console.log('Handling cache failure...');

    // 1. ìºì‹œ ë°”ì´íŒ¨ìŠ¤ ëª¨ë“œ í™œì„±í™”
    process.env.CACHE_BYPASS = 'true';

    // 2. ë©”ëª¨ë¦¬ ìºì‹œë¡œ í´ë°±
    const memoryCache = require('../services/memoryCache');
    memoryCache.activate();

    // 3. Redis í´ëŸ¬ìŠ¤í„° ì¬êµ¬ì„± ì‹œë„
    try {
      await this.reconfigureRedisCluster();
    } catch (error) {
      console.error('Redis recovery failed, continuing with memory cache');
    }
  }

  // YouTube API ì¥ì•  ì²˜ë¦¬
  async handleYouTubeAPIFailure() {
    console.log('Handling YouTube API failure...');

    // 1. ìºì‹œ ì „ìš© ëª¨ë“œ í™œì„±í™”
    process.env.CACHE_ONLY_MODE = 'true';

    // 2. ëŒ€ì²´ ë°ì´í„° ì†ŒìŠ¤ í™œì„±í™”
    await this.activateAlternativeDataSources();

    // 3. ì‚¬ìš©ìì—ê²Œ ì œí•œëœ ê¸°ëŠ¥ ì•Œë¦¼
    await this.notifyUsersOfDegradedService();
  }

  // ë°±ì—… ì‹œìŠ¤í…œ ê²€ì¦
  async verifyBackupSystems() {
    const backupService = require('./databaseBackup');

    // 1. ìµœì‹  ë°±ì—… í™•ì¸
    const latestBackup = await backupService.getLatestBackup();
    const backupAge = Date.now() - new Date(latestBackup.created_at).getTime();

    if (backupAge > this.rpo) {
      throw new Error(`Latest backup is too old: ${backupAge / 1000 / 60} minutes`);
    }

    // 2. ë°±ì—… ë¬´ê²°ì„± ê²€ì¦
    const isValid = await backupService.verifyBackupIntegrity(latestBackup.id);
    if (!isValid) {
      throw new Error('Latest backup integrity check failed');
    }

    // 3. ë³µêµ¬ í…ŒìŠ¤íŠ¸ (ì›” 1íšŒ)
    if (this.shouldRunRecoveryTest()) {
      await this.runRecoveryTest();
    }
  }

  // ë³µêµ¬ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
  async runRecoveryTest() {
    console.log('Running recovery test...');

    const testEnv = process.env.DR_TEST_ENV;

    try {
      // 1. í…ŒìŠ¤íŠ¸ í™˜ê²½ì— ë°±ì—… ë³µì›
      await this.restoreToTestEnvironment(testEnv);

      // 2. ê¸°ëŠ¥ ê²€ì¦
      await this.verifyFunctionality(testEnv);

      // 3. ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
      const metrics = await this.runPerformanceBenchmark(testEnv);

      // 4. ê²°ê³¼ ë³´ê³ 
      await this.reportRecoveryTestResults({
        success: true,
        duration: metrics.duration,
        rto_achieved: metrics.duration < this.rto
      });

    } catch (error) {
      await this.reportRecoveryTestResults({
        success: false,
        error: error.message
      });
      throw error;
    }
  }

  // ë³µêµ¬ ì ˆì°¨ ë¬¸ì„œí™”
  documentRecoveryProcedures() {
    const procedures = {
      api_failure: [
        '1. API í—¬ìŠ¤ì²´í¬ ì‹¤íŒ¨ í™•ì¸',
        '2. ë¡œë“œë°¸ëŸ°ì„œì—ì„œ ì¥ì•  ì¸ìŠ¤í„´ìŠ¤ ì œì™¸',
        '3. ëŒ€ê¸° ì¸ìŠ¤í„´ìŠ¤ë¡œ íŠ¸ë˜í”½ ë¼ìš°íŒ…',
        '4. DNS ì—…ë°ì´íŠ¸ (í•„ìš”ì‹œ)',
        '5. ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ í™•ì¸',
        '6. ì„œë¹„ìŠ¤ ì •ìƒí™” í™•ì¸'
      ],
      database_failure: [
        '1. ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨ í™•ì¸',
        '2. ì½ê¸° ì „ìš© ëª¨ë“œ ì „í™˜',
        '3. ìŠ¤íƒ ë°”ì´ DB ìƒíƒœ í™•ì¸',
        '4. ìŠ¤íƒ ë°”ì´ DBë¥¼ í”„ë¼ì´ë¨¸ë¦¬ë¡œ ìŠ¹ê²©',
        '5. ì• í”Œë¦¬ì¼€ì´ì…˜ ì—°ê²° ë¬¸ìì—´ ì—…ë°ì´íŠ¸',
        '6. ë°ì´í„° ì¼ê´€ì„± ê²€ì¦'
      ],
      complete_outage: [
        '1. ëª¨ë“  ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸',
        '2. ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì„± ê²€ì¦',
        '3. í´ë¼ìš°ë“œ ì œê³µì ìƒíƒœ í™•ì¸',
        '4. DR ì‚¬ì´íŠ¸ í™œì„±í™”',
        '5. DNS í˜ì¼ì˜¤ë²„ ì‹¤í–‰',
        '6. ì‚¬ìš©ì ì»¤ë®¤ë‹ˆì¼€ì´ì…˜'
      ]
    };

    // ë¬¸ì„œë¥¼ íŒŒì¼ë¡œ ì €ì¥
    require('fs').writeFileSync(
      './docs/disaster-recovery-procedures.json',
      JSON.stringify(procedures, null, 2)
    );
  }

  // ì•Œë¦¼ ì²´ê³„ ì„¤ì •
  setupAlertingChain() {
    this.alertChain = [
      {
        level: 1,
        delay: 0,
        contacts: ['oncall@company.com'],
        method: ['email', 'slack']
      },
      {
        level: 2,
        delay: 15 * 60 * 1000, // 15ë¶„
        contacts: ['team-lead@company.com', 'oncall-backup@company.com'],
        method: ['email', 'slack', 'sms']
      },
      {
        level: 3,
        delay: 30 * 60 * 1000, // 30ë¶„
        contacts: ['cto@company.com', 'devops-team@company.com'],
        method: ['email', 'slack', 'sms', 'phone']
      }
    ];
  }

  // íŒ€ ì•Œë¦¼
  async alertTeam(incident) {
    const startTime = Date.now();

    for (const level of this.alertChain) {
      if (Date.now() - startTime >= level.delay) {
        await this.sendAlerts(level, incident);
      }
    }
  }

  // RTO/RPO ëª¨ë‹ˆí„°ë§
  monitorRTORPO() {
    setInterval(async () => {
      const metrics = await this.calculateRecoveryMetrics();

      if (metrics.estimatedRTO > this.rto) {
        await this.alertTeam({
          severity: 'warning',
          message: `Estimated RTO (${metrics.estimatedRTO}ms) exceeds target (${this.rto}ms)`
        });
      }

      if (metrics.currentRPO > this.rpo) {
        await this.alertTeam({
          severity: 'warning',
          message: `Current RPO (${metrics.currentRPO}ms) exceeds target (${this.rpo}ms)`
        });
      }
    }, 60 * 60 * 1000); // 1ì‹œê°„ë§ˆë‹¤
  }

  // ë³µêµ¬ ë©”íŠ¸ë¦­ ê³„ì‚°
  async calculateRecoveryMetrics() {
    const backupService = require('./databaseBackup');
    const latestBackup = await backupService.getLatestBackup();

    return {
      estimatedRTO: this.estimateRecoveryTime(),
      currentRPO: Date.now() - new Date(latestBackup.created_at).getTime(),
      backupSize: latestBackup.size,
      lastTestDate: this.lastRecoveryTest
    };
  }

  // ë³µêµ¬ ì‹œê°„ ì¶”ì •
  estimateRecoveryTime() {
    // ê³¼ê±° ë³µêµ¬ í…ŒìŠ¤íŠ¸ ë°ì´í„° ê¸°ë°˜ ì¶”ì •
    const historicalData = this.getHistoricalRecoveryTimes();
    return historicalData.reduce((a, b) => a + b, 0) / historicalData.length;
  }
}

module.exports = new DisasterRecoveryPlan();

```

### 11.3.3 ë¡¤ë°± ì „ëµ

### ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡¤ë°± ì‹œìŠ¤í…œ

```jsx
// deployment/rollbackStrategy.js
const { execSync } = require('child_process');
const semver = require('semver');

class RollbackStrategy {
  constructor() {
    this.deploymentHistory = [];
    this.maxHistorySize = 10;
    this.rollbackInProgress = false;
    this.healthCheckTimeout = 5 * 60 * 1000; // 5ë¶„
  }

  // ë°°í¬ ê¸°ë¡
  async recordDeployment(deployment) {
    const record = {
      id: deployment.id,
      version: deployment.version,
      timestamp: new Date().toISOString(),
      commit: deployment.commit,
      environment: deployment.environment,
      status: 'in_progress',
      metrics: {
        startTime: Date.now(),
        healthChecks: []
      }
    };

    this.deploymentHistory.unshift(record);

    // íˆìŠ¤í† ë¦¬ í¬ê¸° ì œí•œ
    if (this.deploymentHistory.length > this.maxHistorySize) {
      this.deploymentHistory.pop();
    }

    // ë°ì´í„°ë² ì´ìŠ¤ì—ë„ ì €ì¥
    await this.saveDeploymentRecord(record);

    return record;
  }

  // ìë™ ë¡¤ë°± ëª¨ë‹ˆí„°ë§
  async monitorDeployment(deploymentId) {
    const deployment = this.deploymentHistory.find(d => d.id === deploymentId);
    if (!deployment) {
      throw new Error(`Deployment ${deploymentId} not found`);
    }

    console.log(`Monitoring deployment ${deploymentId} for automatic rollback...`);

    const monitoringConfig = {
      errorRateThreshold: 5, // 5% ì—ëŸ¬ìœ¨
      responseTimeThreshold: 2000, // 2ì´ˆ
      availabilityThreshold: 99, // 99% ê°€ìš©ì„±
      monitoringDuration: 10 * 60 * 1000, // 10ë¶„
      checkInterval: 30 * 1000 // 30ì´ˆ
    };

    const endTime = Date.now() + monitoringConfig.monitoringDuration;
    let checksPassedCount = 0;
    let checksFailed = false;

    while (Date.now() < endTime && !checksFailed) {
      const healthStatus = await this.performHealthChecks(deployment);
      deployment.metrics.healthChecks.push(healthStatus);

      // ì„ê³„ê°’ ì²´í¬
      if (healthStatus.errorRate > monitoringConfig.errorRateThreshold ||
          healthStatus.avgResponseTime > monitoringConfig.responseTimeThreshold ||
          healthStatus.availability < monitoringConfig.availabilityThreshold) {

        console.error('Health check failed:', healthStatus);
        checksFailed = true;

        // ìë™ ë¡¤ë°± ì‹¤í–‰
        await this.automaticRollback(deploymentId, healthStatus);

      } else {
        checksPassedCount++;
        console.log(`Health check passed (${checksPassedCount})`);
      }

      if (!checksFailed) {
        await new Promise(resolve => setTimeout(resolve, monitoringConfig.checkInterval));
      }
    }

    // ëª¨ë‹ˆí„°ë§ ì™„ë£Œ
    if (!checksFailed) {
      deployment.status = 'success';
      console.log(`Deployment ${deploymentId} completed successfully`);
    }

    return deployment;
  }

  // í—¬ìŠ¤ì²´í¬ ìˆ˜í–‰
  async performHealthChecks(deployment) {
    const metrics = {
      timestamp: new Date().toISOString(),
      errorRate: 0,
      avgResponseTime: 0,
      availability: 100,
      checks: []
    };

    // 1. API ì—”ë“œí¬ì¸íŠ¸ ì²´í¬
    const apiChecks = await this.checkAPIEndpoints();
    metrics.checks.push(...apiChecks);

    // 2. ì—ëŸ¬ìœ¨ ê³„ì‚°
    metrics.errorRate = await this.calculateErrorRate();

    // 3. ì‘ë‹µ ì‹œê°„ ì¸¡ì •
    metrics.avgResponseTime = await this.measureResponseTime();

    // 4. ê°€ìš©ì„± ì²´í¬
    metrics.availability = await this.checkAvailability();

    // 5. ë¹„ì¦ˆë‹ˆìŠ¤ ë©”íŠ¸ë¦­ ì²´í¬
    const businessMetrics = await this.checkBusinessMetrics();
    metrics.businessHealth = businessMetrics;

    return metrics;
  }

  // API ì—”ë“œí¬ì¸íŠ¸ ì²´í¬
  async checkAPIEndpoints() {
    const endpoints = [
      { path: '/health', expectedStatus: 200 },
      { path: '/api/videos/trending', expectedStatus: 200 },
      { path: '/api/auth/status', expectedStatus: 200 }
    ];

    const results = await Promise.all(
      endpoints.map(async endpoint => {
        try {
          const response = await fetch(`${process.env.API_URL}${endpoint.path}`);
          return {
            endpoint: endpoint.path,
            status: response.status,
            success: response.status === endpoint.expectedStatus,
            responseTime: response.headers.get('x-response-time')
          };
        } catch (error) {
          return {
            endpoint: endpoint.path,
            success: false,
            error: error.message
          };
        }
      })
    );

    return results;
  }

  // ì—ëŸ¬ìœ¨ ê³„ì‚°
  async calculateErrorRate() {
    // ìµœê·¼ 5ë¶„ê°„ì˜ ì—ëŸ¬ìœ¨ ì¡°íšŒ
    const query = `
      SELECT
        COUNT(CASE WHEN status_code >= 500 THEN 1 END) * 100.0 / COUNT(*) as error_rate
      FROM api_logs
      WHERE created_at > NOW() - INTERVAL '5 minutes'
    `;

    const result = await this.executeQuery(query);
    return result.rows[0]?.error_rate || 0;
  }

  // ìë™ ë¡¤ë°± ì‹¤í–‰
  async automaticRollback(deploymentId, failureReason) {
    console.error(`Initiating automatic rollback for deployment ${deploymentId}`);

    if (this.rollbackInProgress) {
      console.warn('Rollback already in progress');
      return;
    }

    this.rollbackInProgress = true;

    try {
      // 1. ì´ì „ ì•ˆì • ë²„ì „ ì°¾ê¸°
      const targetVersion = await this.findLastStableVersion(deploymentId);

      if (!targetVersion) {
        throw new Error('No stable version found for rollback');
      }

      // 2. ì•Œë¦¼ ë°œì†¡
      await this.notifyRollback({
        deploymentId,
        targetVersion,
        reason: failureReason,
        type: 'automatic'
      });

      // 3. ë¡¤ë°± ì‹¤í–‰
      const rollbackResult = await this.executeRollback(targetVersion);

      // 4. ë¡¤ë°± ê²€ì¦
      await this.verifyRollback(rollbackResult);

      // 5. ë¡¤ë°± ì™„ë£Œ ì•Œë¦¼
      await this.notifyRollbackComplete({
        deploymentId,
        targetVersion,
        success: true
      });

      console.log(`Automatic rollback completed successfully to version ${targetVersion.version}`);

    } catch (error) {
      console.error('Automatic rollback failed:', error);

      await this.notifyRollbackComplete({
        deploymentId,
        success: false,
        error: error.message
      });

      // ìˆ˜ë™ ê°œì… ìš”ì²­
      await this.requestManualIntervention(deploymentId, error);

    } finally {
      this.rollbackInProgress = false;
    }
  }

  // ìˆ˜ë™ ë¡¤ë°±
  async manualRollback(targetVersion, reason) {
    console.log(`Initiating manual rollback to version ${targetVersion}`);

    const deployment = {
      id: `rollback-${Date.now()}`,
      version: targetVersion,
      type: 'rollback',
      reason
    };

    await this.recordDeployment(deployment);

    try {
      // Railwayë¥¼ í†µí•œ ë¡¤ë°±
      const result = await this.executeRollback({ version: targetVersion });

      deployment.status = 'success';
      return result;

    } catch (error) {
      deployment.status = 'failed';
      deployment.error = error.message;
      throw error;
    }
  }

  // ë¡¤ë°± ì‹¤í–‰
  async executeRollback(targetVersion) {
    console.log(`Executing rollback to ${targetVersion.version}`);

    // 1. Railway CLIë¥¼ ì‚¬ìš©í•œ ë¡¤ë°±
    try {
      // íŠ¹ì • ì»¤ë°‹ìœ¼ë¡œ ë¡¤ë°±
      execSync(`railway up --detach --commit ${targetVersion.commit}`, {
        stdio: 'inherit'
      });

      // ë°°í¬ ì™„ë£Œ ëŒ€ê¸°
      await this.waitForDeployment(targetVersion.version);

      return {
        success: true,
        version: targetVersion.version,
        timestamp: new Date().toISOString()
      };

    } catch (error) {
      console.error('Railway rollback failed:', error);

      // ëŒ€ì²´ ë¡¤ë°± ë°©ë²• ì‹œë„
      return await this.alternativeRollback(targetVersion);
    }
  }

  // ëŒ€ì²´ ë¡¤ë°± ë°©ë²•
  async alternativeRollback(targetVersion) {
    console.log('Attempting alternative rollback method...');

    // Docker ì´ë¯¸ì§€ ê¸°ë°˜ ë¡¤ë°±
    const imageName = `ytshorts-curator:${targetVersion.version}`;

    try {
      // ì´ì „ ë²„ì „ì˜ Docker ì´ë¯¸ì§€ë¡œ ì „í™˜
      execSync(`docker pull ${process.env.DOCKER_REGISTRY}/${imageName}`);
      execSync(`docker tag ${process.env.DOCKER_REGISTRY}/${imageName} ${imageName}`);

      // ì»¨í…Œì´ë„ˆ ì¬ì‹œì‘
      execSync(`docker-compose down && docker-compose up -d`);

      return {
        success: true,
        method: 'docker',
        version: targetVersion.version
      };

    } catch (error) {
      throw new Error(`Alternative rollback failed: ${error.message}`);
    }
  }

  // ë§ˆì§€ë§‰ ì•ˆì • ë²„ì „ ì°¾ê¸°
  async findLastStableVersion(currentDeploymentId) {
    // í˜„ì¬ ë°°í¬ ì´ì „ì˜ ì„±ê³µì ì¸ ë°°í¬ ì°¾ê¸°
    const currentIndex = this.deploymentHistory.findIndex(d => d.id === currentDeploymentId);

    for (let i = currentIndex + 1; i < this.deploymentHistory.length; i++) {
      const deployment = this.deploymentHistory[i];

      if (deployment.status === 'success' &&
          deployment.environment === this.deploymentHistory[currentIndex].environment) {

        // ì¶”ê°€ ì•ˆì •ì„± ê²€ì¦
        const isStable = await this.verifyVersionStability(deployment);
        if (isStable) {
          return deployment;
        }
      }
    }

    return null;
  }

  // ë²„ì „ ì•ˆì •ì„± ê²€ì¦
  async verifyVersionStability(deployment) {
    // í•´ë‹¹ ë²„ì „ì´ ìµœì†Œ 1ì‹œê°„ ì´ìƒ ì•ˆì •ì ìœ¼ë¡œ ìš´ì˜ë˜ì—ˆëŠ”ì§€ í™•ì¸
    const runningTime = Date.now() - new Date(deployment.timestamp).getTime();
    const minimumStableTime = 60 * 60 * 1000; // 1ì‹œê°„

    if (runningTime < minimumStableTime) {
      return false;
    }

    // í•´ë‹¹ ë²„ì „ì˜ ì—ëŸ¬ìœ¨ í™•ì¸
    const errorRate = await this.getVersionErrorRate(deployment.version);
    return errorRate < 1; // 1% ë¯¸ë§Œ
  }

  // ë¡¤ë°± ê²€ì¦
  async verifyRollback(rollbackResult) {
    console.log('Verifying rollback...');

    const verificationSteps = [
      {
        name: 'Version Check',
        verify: async () => {
          const currentVersion = await this.getCurrentVersion();
          return currentVersion === rollbackResult.version;
        }
      },
      {
        name: 'Health Check',
        verify: async () => {
          const health = await this.performHealthChecks({ version: rollbackResult.version });
          return health.availability >= 99;
        }
      },
      {
        name: 'Database Migration Check',
        verify: async () => {
          return await this.checkDatabaseCompatibility(rollbackResult.version);
        }
      },
      {
        name: 'API Compatibility Check',
        verify: async () => {
          return await this.checkAPICompatibility(rollbackResult.version);
        }
      }
    ];

    for (const step of verificationSteps) {
      console.log(`Running verification: ${step.name}`);
      const passed = await step.verify();

      if (!passed) {
        throw new Error(`Rollback verification failed: ${step.name}`);
      }
    }

    console.log('Rollback verification completed successfully');
  }

  // ë°ì´í„°ë² ì´ìŠ¤ í˜¸í™˜ì„± ì²´í¬
  async checkDatabaseCompatibility(version) {
    // ë²„ì „ë³„ ë§ˆì´ê·¸ë ˆì´ì…˜ í™•ì¸
    const migrations = await this.getDatabaseMigrations();
    const versionMigrations = migrations.filter(m =>
      semver.gt(m.version, version) && m.breaking
    );

    if (versionMigrations.length > 0) {
      console.warn('Breaking database changes detected:', versionMigrations);

      // ë¡¤ë°± ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰ í•„ìš”
      for (const migration of versionMigrations) {
        if (migration.rollback) {
          await this.executeMigrationRollback(migration);
        }
      }
    }

    return true;
  }

  // ë¡¤ë°± ì•Œë¦¼
  async notifyRollback(details) {
    const message = {
      title: 'ğŸ”„ Deployment Rollback Initiated',
      type: details.type,
      deployment: details.deploymentId,
      targetVersion: details.targetVersion.version,
      reason: details.reason,
      timestamp: new Date().toISOString()
    };

    // ë‹¤ì¤‘ ì±„ë„ ì•Œë¦¼
    await Promise.all([
      this.sendSlackNotification(message),
      this.sendEmailNotification(message),
      this.createIncidentTicket(message)
    ]);
  }

  // ì¹´ë‚˜ë¦¬ ë°°í¬ ì§€ì›
  async canaryRollback(percentage) {
    console.log(`Initiating canary rollback to ${percentage}% of traffic`);

    try {
      // ë¡œë“œë°¸ëŸ°ì„œ ì„¤ì • ì—…ë°ì´íŠ¸
      await this.updateLoadBalancerWeights({
        current: 100 - percentage,
        previous: percentage
      });

      // ë©”íŠ¸ë¦­ ëª¨ë‹ˆí„°ë§
      const canaryMetrics = await this.monitorCanaryDeployment(30 * 60 * 1000); // 30ë¶„

      if (canaryMetrics.success) {
        // ì ì§„ì  ë¡¤ë°± ì™„ë£Œ
        await this.completeCanaryRollback();
      } else {
        // ì „ì²´ ë¡¤ë°±
        await this.executeFullRollback();
      }

    } catch (error) {
      console.error('Canary rollback failed:', error);
      throw error;
    }
  }

  // ë¡¤ë°± íˆìŠ¤í† ë¦¬ ê´€ë¦¬
  async saveRollbackHistory(rollback) {
    const history = {
      ...rollback,
      id: `rollback-${Date.now()}`,
      timestamp: new Date().toISOString()
    };

    await this.supabase
      .from('rollback_history')
      .insert(history);

    return history;
  }
}

module.exports = new RollbackStrategy();

```

## DevOps í†µí•© ì˜ˆì œ

```jsx
// server.js - DevOps í†µí•©
const express = require('express');
const app = express();

// DevOps ëª¨ë“ˆ ì„í¬íŠ¸
const deploymentManager = require('./scripts/deploy');
const loggingService = require('./config/logging');
const tracingService = require('./config/tracing');
const errorTracking = require('./monitoring/errorTracking');
const alertingService = require('./monitoring/alerting');
const databaseBackup = require('./backup/databaseBackup');
const disasterRecovery = require('./disaster-recovery/drPlan');
const rollbackStrategy = require('./deployment/rollbackStrategy');

// ì´ˆê¸°í™”
async function initializeDevOps() {
  // ë¡œê¹… ì„¤ì •
  loggingService.setupExceptionHandlers();
  app.use(loggingService.expressMiddleware());

  // ì¶”ì  ì„¤ì •
  tracingService.initialize();
  app.use(tracingService.expressMiddleware());

  // ì—ëŸ¬ ì¶”ì  ì„¤ì •
  errorTracking.initialize(app);
  app.use(errorTracking.requestHandler());
  app.use(errorTracking.errorHandler());

  // ì¬í•´ ë³µêµ¬ ê³„íš ì´ˆê¸°í™”
  await disasterRecovery.initialize();
  disasterRecovery.monitorRTORPO();

  // ë°±ì—… ìŠ¤ì¼€ì¤„ ì„¤ì •
  databaseBackup.setupBackupSchedule();

  console.log('DevOps systems initialized');
}

// ë°°í¬ ì›¹í›… ì—”ë“œí¬ì¸íŠ¸
app.post('/webhook/deploy', async (req, res) => {
  const deployment = {
    id: req.body.deployment_id,
    version: req.body.version,
    commit: req.body.commit,
    environment: req.body.environment
  };

  try {
    // ë°°í¬ ê¸°ë¡
    const record = await rollbackStrategy.recordDeployment(deployment);

    // ë¹„ë™ê¸°ë¡œ ëª¨ë‹ˆí„°ë§ ì‹œì‘
    rollbackStrategy.monitorDeployment(deployment.id)
      .catch(error => {
        console.error('Deployment monitoring failed:', error);
      });

    res.json({ success: true, deploymentId: record.id });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

// ìˆ˜ë™ ë¡¤ë°± ì—”ë“œí¬ì¸íŠ¸
app.post('/api/rollback', async (req, res) => {
  try {
    const result = await rollbackStrategy.manualRollback(
      req.body.targetVersion,
      req.body.reason
    );
    res.json(result);
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

// ì‹œìŠ¤í…œ ìƒíƒœ ëŒ€ì‹œë³´ë“œ
app.get('/api/system/status', async (req, res) => {
  const status = {
    health: await disasterRecovery.getSystemHealth(),
    backups: await databaseBackup.getBackupStatus(),
    deployments: rollbackStrategy.deploymentHistory.slice(0, 5),
    alerts: await alertingService.getActiveAlerts()
  };

  res.json(status);
});

// ì„œë²„ ì‹œì‘
const PORT = process.env.PORT || 3000;
app.listen(PORT, async () => {
  await initializeDevOps();
  console.log(`Server running on port ${PORT} with full DevOps capabilities`);
});

// ì •ìƒ ì¢…ë£Œ ì²˜ë¦¬
process.on('SIGTERM', async () => {
  console.log('SIGTERM received, shutting down gracefully...');

  await tracingService.shutdown();
  await databaseBackup.performBackup('shutdown');

  process.exit(0);
});

```

```
return outputFile;

```

}

// S3 ì—…ë¡œë“œ
async uploadToS3(file, backupId) {
const key = `database/${new Date().getFullYear()}/${backupId}.gz.enc`;

```
const fileStream = await fs.readFile(file);

const params = {
  Bucket: this.backupBucket,
  Key: key,
  Body: fileStream,
  ServerSideEncryption: 'AES256',
  StorageClass: 'STANDARD_IA',
  Metadata: {
    'backup-id': backupId,
    'backup-date': new Date().toISOString(),
    'service': 'youtube-shorts-curator'
  }
};

await this.s3.upload(params).promise();

return `s3://${this.backupBucket}/${key}`;

```

}

// ë°±ì—… ë©”íƒ€ë°ì´í„° ì €ì¥
async saveBackupMetadata(metadata) {
const { error } = await this.supabase
.from('backup_history')
.insert({
...metadata,
created_at: new Date().toISOString()
});

```
if (error) {
  console.error('Failed to save backup metadata:', error);
}

```

}

// ë°±ì—… ID ìƒì„±
generateBackupId() {
const timestamp = new Date().toISOString().replace(/[:-]/g, '').replace(/..+/, '');
const random = Math.random().toString(36).substring(2, 8);
return `backup-${timestamp}-${random}`;
}

// íŒŒì¼ í¬ê¸° í™•ì¸
async getFileSize(file) {
const stats = await fs.stat(file);
return stats.size;
}

// ë¡œì»¬ íŒŒì¼ ì •ë¦¬
async cleanupLocalFiles(files) {
for (const file of files) {
try {
await fs.unlink(file);
} catch (error) {
console.error(`Failed to delete ${file}:`, error);
}
}
}

// ì˜¤ë˜ëœ ë°±ì—… ì •ë¦¬
async cleanupOldBackups() {
const retentionDays = {
daily: 7,
weekly: 30,
monthly: 365
};

```
// S3ì—ì„œ ì˜¤ë˜ëœ ë°±ì—… ì‚­ì œ
const cutoffDate = new Date();
cutoffDate.setDate(cutoffDate.getDate() - retentionDays.daily);

const listParams = {
  Bucket: this.backupBucket,
  Prefix: 'database/'
};

const objects = await this.s3.listObjectsV2(listParams).promise();

const toDelete = objects.Contents
  .filter(obj => new Date(obj.LastModified) < cutoffDate)
  .map(obj => ({ Key: obj.Key }));

if (toDelete.length > 0) {
  await this.s3.deleteObjects({
    Bucket: this.backupBucket,
    Delete: { Objects: toDelete }
  }).promise();

  console.log(`Deleted ${toDelete.length} old backups`);
}

```

}

// ë°±ì—… ë³µì›
async restoreBackup(backupId) {
console.log(`Starting restore for backup: ${backupId}`);

```
try {
  // 1. ë°±ì—… ë©”íƒ€ë°ì´í„° ì¡°íšŒ
  const { data: backup } = await this.supabase
    .from('backup_history')
    .select('*')
    .eq('id', backupId)
    .single();

  if (!backup) {
    throw new Error('Backup not found');
  }

  // 2. S3ì—ì„œ ë°±ì—… ë‹¤ìš´ë¡œë“œ
  const localFile = await this.downloadFromS3(backup.location);

  // 3. ë³µí˜¸í™” ë° ì••ì¶• í•´ì œ
  const sqlFile = await this.decryptAndDecompress(localFile);

  // 4. ë°ì´í„°ë² ì´ìŠ¤ ë³µì›
  await this.restoreDatabase(sqlFile);

  // 5. ë³µì› í›„ ê²€ì¦
  await this.verifyRestore();

  // 6. ì •ë¦¬
  await this.cleanupLocalFiles([localFile, sqlFile]);

  console.log(`Restore completed for backup: ${backupId}`);

  return { success: true };

} catch (error) {
  console.error(`Restore failed for backup: ${backupId}`, error);
  throw error;
}

```

}

// S3ì—ì„œ ë‹¤ìš´ë¡œë“œ
async downloadFromS3(s3Location) {
const match = s3Location.match(/s3://([^/]+)/(.+)/);
if (!match) {
throw new Error('Invalid S3 location');
}

```
const [, bucket, key] = match;
const localFile = path.join('/tmp', path.basename(key));

const params = {
  Bucket: bucket,
  Key: key
};

const data = await this.s3.getObject(params).promise();
await fs.writeFile(localFile, data.Body);

return localFile;

```

}

// ë³µí˜¸í™” ë° ì••ì¶• í•´ì œ
async decryptAndDecompress(inputFile) {
const outputFile = inputFile.replace('.gz.enc', '.sql');

```
const command = `openssl enc -aes-256-cbc \
  -d \
  -pbkdf2 \
  -pass pass:${process.env.BACKUP_ENCRYPTION_KEY} \
  -in ${inputFile} | \
  gzip -d > ${outputFile}`;

await exec(command);

return outputFile;

```

}

// ë°ì´í„°ë² ì´ìŠ¤ ë³µì›
async restoreDatabase(sqlFile) {
// ì£¼ì˜: í”„ë¡œë•ì…˜ì—ì„œëŠ” ë§¤ìš° ì‹ ì¤‘í•˜ê²Œ ì‹¤í–‰
const command = `psql ${process.env.DATABASE_URL} < ${sqlFile}`;

```
await exec(command);

```

}

// ë³µì› ê²€ì¦
async verifyRestore() {
// ê¸°ë³¸ì ì¸ í…Œì´ë¸” ì¡´ì¬ í™•ì¸
const tables = ['users', 'videos', 'search_logs'];

```
for (const table of tables) {
  const { data, error } = await this.supabase
    .from(table)
    .select('count')
    .limit(1);

  if (error) {
    throw new Error(`Table ${table} verification failed`);
  }
}

```

}

// ë°±ì—… ìŠ¤ì¼€ì¤„ ì„¤ì •
setupBackupSchedule() {
const cron = require('node-cron');

```
// ì¼ì¼ ë°±ì—… (ë§¤ì¼ ìƒˆë²½ 2ì‹œ)
cron.schedule('0 2 * * *', async () => {
  try {
    await this.performBackup('daily');
  } catch (error) {
    console.error('Daily backup failed:', error);
    await this.alertBackupFailure('daily', error);
  }
});

// ì£¼ê°„ ë°±ì—… (ë§¤ì£¼ ì¼ìš”ì¼ ìƒˆë²½ 3ì‹œ)
cron.schedule('0 3 * * 0', async () => {
  try {
    await this.performBackup('weekly');
  } catch (error) {
    console.error('Weekly backup failed:', error);
    await this.alertBackupFailure('weekly', error);
  }
});

// ì›”ê°„ ë°±ì—… (ë§¤ì›” 1ì¼ ìƒˆë²½ 4ì‹œ)
cron.schedule('0 4 1 * *', async () => {
  try {
    await this.performBackup('monthly');
  } catch (error) {
    console.error('Monthly backup failed:', error);
    await this.alertBackupFailure('monthly', error);
  }
});

console.log('Backup schedules configured');

```

}

// ë°±ì—… ì‹¤íŒ¨ ì•Œë¦¼
async alertBackupFailure(type, error) {
const alertingService = require('../monitoring/alerting');

```
await alertingService.sendAlert({
  title: 'Database Backup Failed',
  component: 'backup',
  rule: 'backup_failure',
  priority: 'high',
  message: `${type} backup failed: ${error.message}`,
  details: {
    type,
    error: error.stack
  }
});

```

}
}

```
return dumpFile;

```

}

// ì••ì¶• ë° ì•”í˜¸í™”
async compressAndEncrypt(inputFile) {
const outputFile = `${inputFile}.gz.enc`;

```
// gzip ì••ì¶• í›„ openssl ì•”í˜¸í™”
const command = `gzip -c ${inputFile} | \
  openssl enc -aes-256-cbc \
  -salt \
  -pbkdf2 \
  -pass pass:${process.env.BACKUP_ENCRYPTION_KEY} \
  -out ${outputFile}`;

await exec(command);

```