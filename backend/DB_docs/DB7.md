# ğŸš€ Momentum YouTube AI íë ˆì´ì…˜ ì„œë¹„ìŠ¤ - ìµœì¢… êµ¬í˜„ ê°€ì´ë“œ

## Part 7: ë°°í¬/ëª¨ë‹ˆí„°ë§/ë³´ì•ˆ/íŠ¸ëŸ¬ë¸”ìŠˆíŒ…/FAQ

> **Version**: 4.0 FINAL  
> **Last Updated**: 2025-01-13  
> **Dependencies**: Part 1-6

---

## ğŸ“‹ ëª©ì°¨

1. [ë°°í¬ ì „ëµ](#1-ë°°í¬-ì „ëµ)
2. [ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ](#2-ëª¨ë‹ˆí„°ë§-ì‹œìŠ¤í…œ)
3. [ë³´ì•ˆ ê°€ì´ë“œ](#3-ë³´ì•ˆ-ê°€ì´ë“œ)
4. [íŠ¸ëŸ¬ë¸”ìŠˆíŒ…](#4-íŠ¸ëŸ¬ë¸”ìŠˆíŒ…)
5. [FAQ](#5-faq)
6. [ë§ˆë¬´ë¦¬](#6-ë§ˆë¬´ë¦¬)

---

## 1. ë°°í¬ ì „ëµ

### 1.1 Docker ì»¨í…Œì´ë„ˆí™”

#### Dockerfile (API ì„œë²„)

```dockerfile
# Dockerfile
FROM node:18-alpine AS builder

# ì‘ì—… ë””ë ‰í† ë¦¬ ì„¤ì •
WORKDIR /app

# íŒ¨í‚¤ì§€ íŒŒì¼ ë³µì‚¬
COPY package*.json ./
COPY tsconfig.json ./

# ì˜ì¡´ì„± ì„¤ì¹˜
RUN npm ci --only=production
RUN npm install -g typescript

# ì†ŒìŠ¤ ì½”ë“œ ë³µì‚¬
COPY src ./src

# TypeScript ë¹Œë“œ
RUN npm run build

# ìš´ì˜ í™˜ê²½
FROM node:18-alpine

WORKDIR /app

# ìš´ì˜ì— í•„ìš”í•œ íŒ¨í‚¤ì§€ë§Œ ì„¤ì¹˜
COPY package*.json ./
RUN npm ci --only=production && npm cache clean --force

# ë¹Œë“œëœ íŒŒì¼ ë³µì‚¬
COPY --from=builder /app/dist ./dist
COPY --from=builder /app/node_modules ./node_modules

# í™˜ê²½ ë³€ìˆ˜
ENV NODE_ENV=production

# í—¬ìŠ¤ì²´í¬
HEALTHCHECK --interval=30s --timeout=3s --start-period=40s --retries=3 \
  CMD node healthcheck.js

# í¬íŠ¸ ë…¸ì¶œ
EXPOSE 3000

# ì‹¤í–‰
USER node
CMD ["node", "dist/server.js"]
```

#### Docker Compose

```yaml
# docker-compose.yml
version: "3.8"

services:
  api:
    build: .
    container_name: momentum-api
    restart: unless-stopped
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=production
      - SUPABASE_URL=${SUPABASE_URL}
      - SUPABASE_SERVICE_KEY=${SUPABASE_SERVICE_KEY}
      - REDIS_URL=redis://redis:6379
    depends_on:
      - redis
    networks:
      - momentum-network
    volumes:
      - ./logs:/app/logs
    deploy:
      resources:
        limits:
          cpus: "1"
          memory: 1G
        reservations:
          cpus: "0.5"
          memory: 512M

  redis:
    image: redis:7-alpine
    container_name: momentum-redis
    restart: unless-stopped
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    networks:
      - momentum-network
    command: redis-server --appendonly yes

  nginx:
    image: nginx:alpine
    container_name: momentum-nginx
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/nginx/ssl:ro
      - ./static:/usr/share/nginx/html:ro
    depends_on:
      - api
    networks:
      - momentum-network

  prometheus:
    image: prom/prometheus:latest
    container_name: momentum-prometheus
    restart: unless-stopped
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    networks:
      - momentum-network

  grafana:
    image: grafana/grafana:latest
    container_name: momentum-grafana
    restart: unless-stopped
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
    volumes:
      - grafana-data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning
    depends_on:
      - prometheus
    networks:
      - momentum-network

volumes:
  redis-data:
  prometheus-data:
  grafana-data:

networks:
  momentum-network:
    driver: bridge
```

#### Nginx ì„¤ì •

```nginx
# nginx.conf
user nginx;
worker_processes auto;
error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;

events {
    worker_connections 1024;
    use epoll;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    # ë¡œê¹… í¬ë§·
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for" '
                    'rt=$request_time uct="$upstream_connect_time" '
                    'uht="$upstream_header_time" urt="$upstream_response_time"';

    access_log /var/log/nginx/access.log main;

    # ì„±ëŠ¥ ìµœì í™”
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;
    client_max_body_size 10M;

    # Gzip ì••ì¶•
    gzip on;
    gzip_vary on;
    gzip_proxied any;
    gzip_comp_level 6;
    gzip_types text/plain text/css text/xml text/javascript
               application/json application/javascript application/xml+rss
               application/rss+xml application/atom+xml image/svg+xml;

    # Rate limiting
    limit_req_zone $binary_remote_addr zone=api_limit:10m rate=10r/s;
    limit_req_zone $binary_remote_addr zone=auth_limit:10m rate=5r/m;

    # SSL ì„¤ì •
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256;
    ssl_prefer_server_ciphers off;
    ssl_session_cache shared:SSL:10m;
    ssl_session_timeout 10m;
    ssl_stapling on;
    ssl_stapling_verify on;

    # API ì„œë²„ ì—…ìŠ¤íŠ¸ë¦¼
    upstream api_backend {
        least_conn;
        server api:3000 max_fails=3 fail_timeout=30s;
        keepalive 32;
    }

    # HTTP to HTTPS ë¦¬ë‹¤ì´ë ‰íŠ¸
    server {
        listen 80;
        server_name api.momentum.app;
        return 301 https://$server_name$request_uri;
    }

    # HTTPS ì„œë²„
    server {
        listen 443 ssl http2;
        server_name api.momentum.app;

        ssl_certificate /etc/nginx/ssl/cert.pem;
        ssl_certificate_key /etc/nginx/ssl/key.pem;

        # ë³´ì•ˆ í—¤ë”
        add_header X-Frame-Options "DENY" always;
        add_header X-Content-Type-Options "nosniff" always;
        add_header X-XSS-Protection "1; mode=block" always;
        add_header Referrer-Policy "strict-origin-when-cross-origin" always;
        add_header Content-Security-Policy "default-src 'self'" always;
        add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;

        # API ë¼ìš°íŒ…
        location /api/ {
            # Rate limiting
            limit_req zone=api_limit burst=20 nodelay;

            # í”„ë¡ì‹œ ì„¤ì •
            proxy_pass http://api_backend;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection 'upgrade';
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_cache_bypass $http_upgrade;

            # íƒ€ì„ì•„ì›ƒ ì„¤ì •
            proxy_connect_timeout 60s;
            proxy_send_timeout 60s;
            proxy_read_timeout 60s;
        }

        # ì¸ì¦ ì—”ë“œí¬ì¸íŠ¸ (ë” ì—„ê²©í•œ rate limit)
        location /api/v1/auth/ {
            limit_req zone=auth_limit burst=5 nodelay;
            proxy_pass http://api_backend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
        }

        # ì •ì  íŒŒì¼
        location /static/ {
            alias /usr/share/nginx/html/;
            expires 30d;
            add_header Cache-Control "public, immutable";
        }

        # í—¬ìŠ¤ì²´í¬
        location /health {
            access_log off;
            proxy_pass http://api_backend/api/v1/health;
        }
    }
}
```

### 1.2 CI/CD íŒŒì´í”„ë¼ì¸

#### GitHub Actions

```yaml
# .github/workflows/deploy.yml
name: Deploy to Production

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: "18"
          cache: "npm"

      - name: Install dependencies
        run: npm ci

      - name: Run tests
        run: npm test

      - name: Run linting
        run: npm run lint

      - name: Check types
        run: npm run type-check

  build:
    needs: test
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write

    steps:
      - uses: actions/checkout@v3

      - name: Setup Docker Buildx
        uses: docker/setup-buildx-action@v2

      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v2
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v4
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=semver,pattern={{version}}
            type=semver,pattern={{major}}.{{minor}}
            type=sha

      - name: Build and push Docker image
        uses: docker/build-push-action@v4
        with:
          context: .
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

  deploy:
    needs: build
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'

    steps:
      - name: Deploy to server
        uses: appleboy/ssh-action@v0.1.5
        with:
          host: ${{ secrets.DEPLOY_HOST }}
          username: ${{ secrets.DEPLOY_USER }}
          key: ${{ secrets.DEPLOY_KEY }}
          script: |
            cd /opt/momentum
            docker-compose pull
            docker-compose up -d --remove-orphans
            docker system prune -f

  database-migration:
    needs: deploy
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'

    steps:
      - uses: actions/checkout@v3

      - name: Run database migrations
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
        run: |
          npx supabase db push --db-url $DATABASE_URL
```

### 1.3 í™˜ê²½ë³„ ì„¤ì •

#### í™˜ê²½ ë³€ìˆ˜ ê´€ë¦¬

```typescript
// config/env.ts
import { z } from "zod";
import dotenv from "dotenv";

// í™˜ê²½ë³„ .env íŒŒì¼ ë¡œë“œ
const envFile = `.env.${process.env.NODE_ENV || "development"}`;
dotenv.config({ path: envFile });
dotenv.config(); // ê¸°ë³¸ .env íŒŒì¼

// í™˜ê²½ ë³€ìˆ˜ ìŠ¤í‚¤ë§ˆ
const envSchema = z.object({
  // ê¸°ë³¸ ì„¤ì •
  NODE_ENV: z.enum(["development", "test", "staging", "production"]),
  PORT: z.string().transform(Number),

  // ë°ì´í„°ë² ì´ìŠ¤
  SUPABASE_URL: z.string().url(),
  SUPABASE_SERVICE_KEY: z.string().min(1),
  SUPABASE_ANON_KEY: z.string().min(1),

  // Redis
  REDIS_URL: z.string().url().optional(),

  // ì™¸ë¶€ API
  YOUTUBE_API_KEY: z.string().min(1),
  ANTHROPIC_API_KEY: z.string().min(1),
  NEWS_API_KEY: z.string().min(1).optional(),

  // ë³´ì•ˆ
  JWT_SECRET: z.string().min(32),
  API_KEY_SECRET: z.string().min(32),

  // ëª¨ë‹ˆí„°ë§
  SENTRY_DSN: z.string().url().optional(),
  NEW_RELIC_LICENSE_KEY: z.string().optional(),

  // ê¸°íƒ€
  LOG_LEVEL: z.enum(["error", "warn", "info", "debug"]).default("info"),
  ALLOWED_ORIGINS: z.string().transform((s) => s.split(",")),
});

// í™˜ê²½ ë³€ìˆ˜ ê²€ì¦
const parseEnv = () => {
  try {
    return envSchema.parse(process.env);
  } catch (error) {
    console.error("Invalid environment variables:", error);
    process.exit(1);
  }
};

export const env = parseEnv();

// í™˜ê²½ë³„ ì„¤ì •
export const config = {
  isDevelopment: env.NODE_ENV === "development",
  isTest: env.NODE_ENV === "test",
  isStaging: env.NODE_ENV === "staging",
  isProduction: env.NODE_ENV === "production",

  api: {
    port: env.PORT,
    corsOrigins: env.ALLOWED_ORIGINS,
  },

  database: {
    url: env.SUPABASE_URL,
    serviceKey: env.SUPABASE_SERVICE_KEY,
    anonKey: env.SUPABASE_ANON_KEY,
  },

  redis: {
    url: env.REDIS_URL,
    enabled: !!env.REDIS_URL,
  },

  youtube: {
    apiKey: env.YOUTUBE_API_KEY,
    quota: {
      daily: env.NODE_ENV === "production" ? 10000 : 1000,
      perRequest: 100,
    },
  },

  security: {
    jwtSecret: env.JWT_SECRET,
    apiKeySecret: env.API_KEY_SECRET,
    bcryptRounds: env.NODE_ENV === "production" ? 12 : 10,
  },

  logging: {
    level: env.LOG_LEVEL,
    sentryDsn: env.SENTRY_DSN,
  },

  rateLimit: {
    windowMs: 15 * 60 * 1000, // 15ë¶„
    max: env.NODE_ENV === "production" ? 100 : 1000,
  },
};
```

#### í™˜ê²½ë³„ ë°°í¬ ìŠ¤í¬ë¦½íŠ¸

```bash
#!/bin/bash
# scripts/deploy.sh

set -e

ENVIRONMENT=$1
if [ -z "$ENVIRONMENT" ]; then
    echo "Usage: ./deploy.sh [development|staging|production]"
    exit 1
fi

echo "Deploying to $ENVIRONMENT..."

# í™˜ê²½ë³„ ì„¤ì •
case $ENVIRONMENT in
    development)
        SERVER="dev.momentum.app"
        COMPOSE_FILE="docker-compose.dev.yml"
        ;;
    staging)
        SERVER="staging.momentum.app"
        COMPOSE_FILE="docker-compose.staging.yml"
        ;;
    production)
        SERVER="api.momentum.app"
        COMPOSE_FILE="docker-compose.yml"
        ;;
    *)
        echo "Invalid environment: $ENVIRONMENT"
        exit 1
        ;;
esac

# ë¹Œë“œ ë° í…ŒìŠ¤íŠ¸
echo "Running tests..."
npm test

echo "Building Docker image..."
docker build -t momentum-api:$ENVIRONMENT .

# ë°°í¬
echo "Deploying to $SERVER..."
ssh deploy@$SERVER << EOF
    cd /opt/momentum
    git pull origin main
    docker-compose -f $COMPOSE_FILE pull
    docker-compose -f $COMPOSE_FILE up -d
    docker system prune -f
EOF

echo "Deployment complete!"

# í—¬ìŠ¤ ì²´í¬
sleep 10
curl -f https://$SERVER/health || exit 1
echo "Health check passed!"
```

---

## 2. ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ

### 2.1 ë¡œê·¸ ìˆ˜ì§‘ ë° ë¶„ì„

#### Winston ë¡œê·¸ ì„¤ì •

```typescript
// config/logger.ts
import winston from "winston";
import DailyRotateFile from "winston-daily-rotate-file";
import { ElasticsearchTransport } from "winston-elasticsearch";

const logFormat = winston.format.combine(
  winston.format.timestamp(),
  winston.format.errors({ stack: true }),
  winston.format.json()
);

// íŒŒì¼ ë¡œí…Œì´ì…˜ ì„¤ì •
const fileRotateTransport = new DailyRotateFile({
  filename: "logs/app-%DATE%.log",
  datePattern: "YYYY-MM-DD",
  maxSize: "20m",
  maxFiles: "14d",
  format: logFormat,
});

// Elasticsearch ì „ì†¡ (ì„ íƒì‚¬í•­)
const esTransport = new ElasticsearchTransport({
  level: "info",
  clientOpts: { node: process.env.ELASTICSEARCH_URL },
  index: "momentum-logs",
  format: winston.format.combine(
    winston.format.timestamp(),
    winston.format.json()
  ),
});

export const logger = winston.createLogger({
  level: process.env.LOG_LEVEL || "info",
  format: logFormat,
  defaultMeta: {
    service: "momentum-api",
    environment: process.env.NODE_ENV,
  },
  transports: [
    // ì½˜ì†” ì¶œë ¥
    new winston.transports.Console({
      format: winston.format.combine(
        winston.format.colorize(),
        winston.format.simple()
      ),
    }),
    // íŒŒì¼ ì €ì¥
    fileRotateTransport,
    // ì—ëŸ¬ ì „ìš© íŒŒì¼
    new winston.transports.File({
      filename: "logs/error.log",
      level: "error",
    }),
  ],
});

// Productionì—ì„œë§Œ Elasticsearch ì‚¬ìš©
if (process.env.NODE_ENV === "production" && process.env.ELASTICSEARCH_URL) {
  logger.add(esTransport);
}

// êµ¬ì¡°í™”ëœ ë¡œê¹… í—¬í¼
export const structuredLog = {
  request: (req: Request, message: string, meta?: any) => {
    logger.info(message, {
      requestId: req.id,
      userId: req.user?.id,
      method: req.method,
      path: req.path,
      ip: req.ip,
      ...meta,
    });
  },

  error: (error: Error, context: string, meta?: any) => {
    logger.error(`Error in ${context}`, {
      error: {
        message: error.message,
        stack: error.stack,
        name: error.name,
      },
      context,
      ...meta,
    });
  },

  performance: (operation: string, duration: number, meta?: any) => {
    logger.info(`Performance: ${operation}`, {
      operation,
      duration,
      ...meta,
    });
  },
};
```

### 2.2 ë©”íŠ¸ë¦­ ëª¨ë‹ˆí„°ë§

#### Prometheus ë©”íŠ¸ë¦­ ì„¤ì •

```typescript
// monitoring/metrics.ts
import { register, Counter, Histogram, Gauge } from "prom-client";

// HTTP ìš”ì²­ ì¹´ìš´í„°
export const httpRequestsTotal = new Counter({
  name: "http_requests_total",
  help: "Total number of HTTP requests",
  labelNames: ["method", "route", "status"],
});

// HTTP ìš”ì²­ ì§€ì† ì‹œê°„
export const httpRequestDuration = new Histogram({
  name: "http_request_duration_seconds",
  help: "Duration of HTTP requests in seconds",
  labelNames: ["method", "route", "status"],
  buckets: [0.1, 0.3, 0.5, 0.7, 1, 3, 5, 7, 10],
});

// í™œì„± ì—°ê²° ìˆ˜
export const activeConnections = new Gauge({
  name: "active_connections",
  help: "Number of active connections",
});

// API ì‚¬ìš©ëŸ‰
export const apiUsageCounter = new Counter({
  name: "api_usage_total",
  help: "Total API usage by service",
  labelNames: ["api", "endpoint"],
});

// ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ ë©”íŠ¸ë¦­
export const dbQueryDuration = new Histogram({
  name: "db_query_duration_seconds",
  help: "Duration of database queries",
  labelNames: ["operation", "table"],
  buckets: [0.01, 0.05, 0.1, 0.5, 1, 2, 5],
});

// ì¶”ì²œ ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­
export const recommendationMetrics = {
  generated: new Counter({
    name: "recommendations_generated_total",
    help: "Total recommendations generated",
    labelNames: ["type", "algorithm"],
  }),

  clickThrough: new Counter({
    name: "recommendations_clicked_total",
    help: "Total recommendations clicked",
    labelNames: ["type"],
  }),

  accuracy: new Gauge({
    name: "recommendation_accuracy",
    help: "Recommendation accuracy score",
    labelNames: ["algorithm"],
  }),
};

// ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­
export const systemMetrics = {
  memoryUsage: new Gauge({
    name: "nodejs_memory_usage_bytes",
    help: "Node.js memory usage",
  }),

  cpuUsage: new Gauge({
    name: "nodejs_cpu_usage_percent",
    help: "Node.js CPU usage percentage",
  }),

  eventLoopLag: new Gauge({
    name: "nodejs_event_loop_lag_seconds",
    help: "Node.js event loop lag",
  }),
};

// ë©”íŠ¸ë¦­ ë¯¸ë“¤ì›¨ì–´
export const metricsMiddleware = (
  req: Request,
  res: Response,
  next: NextFunction
) => {
  const start = Date.now();

  res.on("finish", () => {
    const duration = (Date.now() - start) / 1000;
    const route = req.route?.path || "unknown";
    const labels = {
      method: req.method,
      route,
      status: res.statusCode.toString(),
    };

    httpRequestsTotal.inc(labels);
    httpRequestDuration.observe(labels, duration);
  });

  next();
};

// ë©”íŠ¸ë¦­ ì—”ë“œí¬ì¸íŠ¸
export const metricsEndpoint = async (req: Request, res: Response) => {
  res.set("Content-Type", register.contentType);
  res.end(await register.metrics());
};

// ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ (1ë¶„ë§ˆë‹¤)
setInterval(() => {
  const memUsage = process.memoryUsage();
  systemMetrics.memoryUsage.set(memUsage.heapUsed);

  const cpuUsage = process.cpuUsage();
  systemMetrics.cpuUsage.set(cpuUsage.user / 1000000);
}, 60000);
```

#### Grafana ëŒ€ì‹œë³´ë“œ ì„¤ì •

```json
{
  "dashboard": {
    "title": "Momentum API Monitoring",
    "panels": [
      {
        "title": "Request Rate",
        "targets": [
          {
            "expr": "rate(http_requests_total[5m])",
            "legendFormat": "{{method}} {{route}}"
          }
        ],
        "type": "graph"
      },
      {
        "title": "Response Time (p95)",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))",
            "legendFormat": "95th percentile"
          }
        ],
        "type": "graph"
      },
      {
        "title": "Error Rate",
        "targets": [
          {
            "expr": "rate(http_requests_total{status=~\"5..\"}[5m])",
            "legendFormat": "5xx errors"
          }
        ],
        "type": "graph"
      },
      {
        "title": "API Usage",
        "targets": [
          {
            "expr": "rate(api_usage_total[1h])",
            "legendFormat": "{{api}}"
          }
        ],
        "type": "graph"
      },
      {
        "title": "Database Query Performance",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(db_query_duration_seconds_bucket[5m]))",
            "legendFormat": "{{operation}} on {{table}}"
          }
        ],
        "type": "graph"
      },
      {
        "title": "Memory Usage",
        "targets": [
          {
            "expr": "nodejs_memory_usage_bytes / 1024 / 1024",
            "legendFormat": "Heap Used (MB)"
          }
        ],
        "type": "graph"
      }
    ]
  }
}
```

### 2.3 ì•Œë¦¼ ì„¤ì •

#### ì•Œë¦¼ ê·œì¹™

```yaml
# prometheus/alerts.yml
groups:
  - name: api_alerts
    interval: 30s
    rules:
      # ë†’ì€ ì—ëŸ¬ìœ¨
      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.05
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value }} errors per second"

      # ì‘ë‹µ ì‹œê°„ ì¦ê°€
      - alert: SlowResponseTime
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 1
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "Slow response time"
          description: "95th percentile response time is {{ $value }} seconds"

      # API ì¿¼í„° ì„ê³„ê°’
      - alert: APIQuotaWarning
        expr: sum(api_usage_total) > 8000
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: "API quota usage high"
          description: "Used {{ $value }} out of 10000 daily quota"

      # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
      - alert: HighMemoryUsage
        expr: nodejs_memory_usage_bytes / 1024 / 1024 > 800
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High memory usage"
          description: "Memory usage is {{ $value }} MB"

      # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨
      - alert: DatabaseConnectionFailure
        expr: up{job="supabase"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Database connection failed"
          description: "Cannot connect to Supabase"
```

#### Slack ì•Œë¦¼ í†µí•©

```typescript
// monitoring/alerting.ts
import { WebClient } from "@slack/web-api";
import { logger } from "../config/logger";

const slack = new WebClient(process.env.SLACK_BOT_TOKEN);

interface Alert {
  level: "info" | "warning" | "error" | "critical";
  title: string;
  message: string;
  details?: any;
}

export class AlertManager {
  private readonly channel = process.env.SLACK_ALERT_CHANNEL || "#alerts";

  async sendAlert(alert: Alert) {
    try {
      const color = this.getAlertColor(alert.level);

      await slack.chat.postMessage({
        channel: this.channel,
        attachments: [
          {
            color,
            title: `${this.getEmoji(alert.level)} ${alert.title}`,
            text: alert.message,
            fields: alert.details ? this.formatDetails(alert.details) : [],
            footer: "Momentum API",
            ts: Math.floor(Date.now() / 1000).toString(),
          },
        ],
      });
    } catch (error) {
      logger.error("Failed to send Slack alert", error);
    }
  }

  private getAlertColor(level: Alert["level"]): string {
    const colors = {
      info: "#36a64f",
      warning: "#ff9900",
      error: "#ff0000",
      critical: "#990000",
    };
    return colors[level];
  }

  private getEmoji(level: Alert["level"]): string {
    const emojis = {
      info: "â„¹ï¸",
      warning: "âš ï¸",
      error: "âŒ",
      critical: "ğŸš¨",
    };
    return emojis[level];
  }

  private formatDetails(
    details: any
  ): Array<{ title: string; value: string; short: boolean }> {
    return Object.entries(details).map(([key, value]) => ({
      title: key,
      value: String(value),
      short: true,
    }));
  }
}

// ì‚¬ìš© ì˜ˆì‹œ
export const alerts = new AlertManager();

// ì¤‘ìš” ì´ë²¤íŠ¸ ì•Œë¦¼
export const sendCriticalAlert = async (
  title: string,
  message: string,
  details?: any
) => {
  await alerts.sendAlert({
    level: "critical",
    title,
    message,
    details,
  });
};
```

---

## 3. ë³´ì•ˆ ê°€ì´ë“œ

### 3.1 ë³´ì•ˆ ëª¨ë²” ì‚¬ë¡€

#### API í‚¤ ê´€ë¦¬

```typescript
// security/apiKey.ts
import crypto from "crypto";
import { Redis } from "ioredis";

export class APIKeyManager {
  constructor(private redis: Redis) {}

  /**
   * API í‚¤ ìƒì„±
   */
  async generateAPIKey(userId: string, tier: string): Promise<string> {
    // ì•ˆì „í•œ ëœë¤ í‚¤ ìƒì„±
    const key = crypto.randomBytes(32).toString("base64url");
    const hashedKey = this.hashKey(key);

    // ë©”íƒ€ë°ì´í„°ì™€ í•¨ê»˜ ì €ì¥
    await this.redis.hset(`apikey:${hashedKey}`, {
      userId,
      tier,
      createdAt: new Date().toISOString(),
      lastUsed: new Date().toISOString(),
      requestCount: 0,
    });

    // ì‚¬ìš©ìë³„ í‚¤ ëª©ë¡ì— ì¶”ê°€
    await this.redis.sadd(`user:${userId}:apikeys`, hashedKey);

    return key;
  }

  /**
   * API í‚¤ ê²€ì¦
   */
  async validateAPIKey(
    key: string
  ): Promise<{ valid: boolean; userId?: string; tier?: string }> {
    const hashedKey = this.hashKey(key);
    const keyData = await this.redis.hgetall(`apikey:${hashedKey}`);

    if (!keyData.userId) {
      return { valid: false };
    }

    // ì‚¬ìš© í†µê³„ ì—…ë°ì´íŠ¸
    await this.redis.hincrby(`apikey:${hashedKey}`, "requestCount", 1);
    await this.redis.hset(
      `apikey:${hashedKey}`,
      "lastUsed",
      new Date().toISOString()
    );

    return {
      valid: true,
      userId: keyData.userId,
      tier: keyData.tier,
    };
  }

  /**
   * API í‚¤ í•´ì‹œ
   */
  private hashKey(key: string): string {
    return crypto
      .createHash("sha256")
      .update(key + process.env.API_KEY_SECRET)
      .digest("hex");
  }

  /**
   * API í‚¤ íê¸°
   */
  async revokeAPIKey(key: string, userId: string): Promise<boolean> {
    const hashedKey = this.hashKey(key);

    // í‚¤ ì‚­ì œ
    const deleted = await this.redis.del(`apikey:${hashedKey}`);

    // ì‚¬ìš©ì í‚¤ ëª©ë¡ì—ì„œ ì œê±°
    await this.redis.srem(`user:${userId}:apikeys`, hashedKey);

    return deleted > 0;
  }

  /**
   * í‚¤ ë¡œí…Œì´ì…˜
   */
  async rotateAPIKey(oldKey: string, userId: string): Promise<string> {
    // ê¸°ì¡´ í‚¤ íê¸°
    await this.revokeAPIKey(oldKey, userId);

    // ìƒˆ í‚¤ ìƒì„±
    const tier = await this.getUserTier(userId);
    return this.generateAPIKey(userId, tier);
  }

  private async getUserTier(userId: string): Promise<string> {
    // ì‚¬ìš©ì í‹°ì–´ ì¡°íšŒ ë¡œì§
    return "free";
  }
}
```

#### ì…ë ¥ ê²€ì¦ ë° ì‚´ê· 

```typescript
// security/sanitizer.ts
import DOMPurify from "isomorphic-dompurify";
import { z } from "zod";

export class InputSanitizer {
  /**
   * HTML ì‚´ê· 
   */
  static sanitizeHTML(input: string): string {
    return DOMPurify.sanitize(input, {
      ALLOWED_TAGS: ["b", "i", "em", "strong", "a"],
      ALLOWED_ATTR: ["href"],
    });
  }

  /**
   * SQL ì¸ì ì…˜ ë°©ì§€
   */
  static sanitizeSQL(input: string): string {
    // SupabaseëŠ” íŒŒë¼ë¯¸í„°í™”ëœ ì¿¼ë¦¬ë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ ì¶”ê°€ ì‚´ê·  ë¶ˆí•„ìš”
    // í•˜ì§€ë§Œ ë™ì  ì¿¼ë¦¬ ìƒì„± ì‹œ ì‚¬ìš©
    return input.replace(/['";\\]/g, "");
  }

  /**
   * íŒŒì¼ëª… ì‚´ê· 
   */
  static sanitizeFilename(filename: string): string {
    return filename
      .replace(/[^a-zA-Z0-9.-]/g, "_")
      .replace(/\.{2,}/g, ".")
      .substring(0, 255);
  }

  /**
   * URL ê²€ì¦
   */
  static validateURL(url: string): boolean {
    try {
      const parsed = new URL(url);
      return ["http:", "https:"].includes(parsed.protocol);
    } catch {
      return false;
    }
  }

  /**
   * ì´ë©”ì¼ ê²€ì¦ ë° ì •ê·œí™”
   */
  static normalizeEmail(email: string): string {
    const schema = z.string().email().toLowerCase().trim();
    return schema.parse(email);
  }
}

// XSS ë°©ì§€ ë¯¸ë“¤ì›¨ì–´
export const xssProtection = (
  req: Request,
  res: Response,
  next: NextFunction
) => {
  // ìš”ì²­ ë°”ë”” ì‚´ê· 
  if (req.body) {
    req.body = sanitizeObject(req.body);
  }

  // ì¿¼ë¦¬ íŒŒë¼ë¯¸í„° ì‚´ê· 
  if (req.query) {
    req.query = sanitizeObject(req.query);
  }

  next();
};

function sanitizeObject(obj: any): any {
  if (typeof obj === "string") {
    return InputSanitizer.sanitizeHTML(obj);
  }

  if (Array.isArray(obj)) {
    return obj.map(sanitizeObject);
  }

  if (obj && typeof obj === "object") {
    const sanitized: any = {};
    for (const [key, value] of Object.entries(obj)) {
      sanitized[key] = sanitizeObject(value);
    }
    return sanitized;
  }

  return obj;
}
```

### 3.2 ì·¨ì•½ì  ëŒ€ì‘

#### OWASP Top 10 ëŒ€ì‘

```typescript
// security/owasp.ts

// 1. Injection ë°©ì§€
export const preventInjection = {
  // SQL Injection: Supabase íŒŒë¼ë¯¸í„°í™”ëœ ì¿¼ë¦¬ ì‚¬ìš©
  sql: (query: string, params: any[]) => {
    return supabase.rpc("safe_query", { query, params });
  },

  // NoSQL Injection: ê°ì²´ í‚¤ ê²€ì¦
  validateObjectKeys: (obj: any, allowedKeys: string[]) => {
    const keys = Object.keys(obj);
    for (const key of keys) {
      if (!allowedKeys.includes(key)) {
        throw new Error(`Invalid key: ${key}`);
      }
    }
  },
};

// 2. Broken Authentication ë°©ì§€
export const authSecurity = {
  // ë¹„ë°€ë²ˆí˜¸ ê°•ë„ ê²€ì¦
  validatePassword: (password: string): boolean => {
    const minLength = 8;
    const hasUpperCase = /[A-Z]/.test(password);
    const hasLowerCase = /[a-z]/.test(password);
    const hasNumbers = /\d/.test(password);
    const hasSpecialChar = /[!@#$%^&*]/.test(password);

    return (
      password.length >= minLength &&
      hasUpperCase &&
      hasLowerCase &&
      hasNumbers &&
      hasSpecialChar
    );
  },

  // ê³„ì • ì ê¸ˆ
  accountLockout: async (userId: string, attempts: number) => {
    const MAX_ATTEMPTS = 5;
    const LOCKOUT_DURATION = 15 * 60 * 1000; // 15ë¶„

    if (attempts >= MAX_ATTEMPTS) {
      await redis.setex(`lockout:${userId}`, LOCKOUT_DURATION / 1000, "locked");
      return true;
    }
    return false;
  },

  // ì„¸ì…˜ ê´€ë¦¬
  sessionSecurity: {
    regenerateOnLogin: true,
    httpOnly: true,
    secure: true,
    sameSite: "strict",
    maxAge: 24 * 60 * 60 * 1000, // 24ì‹œê°„
  },
};

// 3. Sensitive Data Exposure ë°©ì§€
export const dataProtection = {
  // ë¯¼ê° ë°ì´í„° ë§ˆìŠ¤í‚¹
  maskSensitiveData: (data: any): any => {
    const sensitiveFields = ["password", "credit_card", "ssn", "api_key"];

    if (typeof data === "object") {
      const masked = { ...data };
      for (const field of sensitiveFields) {
        if (masked[field]) {
          masked[field] = "***MASKED***";
        }
      }
      return masked;
    }
    return data;
  },

  // ì•”í˜¸í™”
  encrypt: (text: string): string => {
    const algorithm = "aes-256-gcm";
    const key = Buffer.from(process.env.ENCRYPTION_KEY!, "hex");
    const iv = crypto.randomBytes(16);

    const cipher = crypto.createCipheriv(algorithm, key, iv);

    let encrypted = cipher.update(text, "utf8", "hex");
    encrypted += cipher.final("hex");

    const authTag = cipher.getAuthTag();

    return iv.toString("hex") + ":" + authTag.toString("hex") + ":" + encrypted;
  },

  decrypt: (encryptedText: string): string => {
    const parts = encryptedText.split(":");
    const iv = Buffer.from(parts[0], "hex");
    const authTag = Buffer.from(parts[1], "hex");
    const encrypted = parts[2];

    const algorithm = "aes-256-gcm";
    const key = Buffer.from(process.env.ENCRYPTION_KEY!, "hex");

    const decipher = crypto.createDecipheriv(algorithm, key, iv);
    decipher.setAuthTag(authTag);

    let decrypted = decipher.update(encrypted, "hex", "utf8");
    decrypted += decipher.final("utf8");

    return decrypted;
  },
};

// 4. XXE (XML External Entities) ë°©ì§€
export const xxePrevention = {
  parseXML: (xml: string) => {
    // XML íŒŒì‹± ë¹„í™œì„±í™” ë˜ëŠ” ì•ˆì „í•œ íŒŒì„œ ì‚¬ìš©
    throw new Error("XML parsing is disabled for security reasons");
  },
};

// 5. Broken Access Control ë°©ì§€
export const accessControl = {
  // ë¦¬ì†ŒìŠ¤ ì†Œìœ ê¶Œ í™•ì¸
  checkResourceOwnership: async (
    userId: string,
    resourceType: string,
    resourceId: string
  ): Promise<boolean> => {
    const { data, error } = await supabase
      .from(resourceType)
      .select("user_id")
      .eq("id", resourceId)
      .single();

    return data?.user_id === userId;
  },

  // ì—­í•  ê¸°ë°˜ ì ‘ê·¼ ì œì–´
  checkPermission: (userRole: string, requiredRole: string): boolean => {
    const roleHierarchy = {
      admin: 4,
      pro: 3,
      premium: 2,
      free: 1,
    };

    return (roleHierarchy[userRole] || 0) >= (roleHierarchy[requiredRole] || 0);
  },
};

// 6. Security Misconfiguration ë°©ì§€
export const securityHeaders = {
  "X-Content-Type-Options": "nosniff",
  "X-Frame-Options": "DENY",
  "X-XSS-Protection": "1; mode=block",
  "Strict-Transport-Security": "max-age=31536000; includeSubDomains",
  "Content-Security-Policy": "default-src 'self'",
  "Referrer-Policy": "strict-origin-when-cross-origin",
  "Permissions-Policy": "geolocation=(), microphone=(), camera=()",
};

// 7. Cross-Site Scripting (XSS) ë°©ì§€
export const xssPrevention = {
  // ReactëŠ” ê¸°ë³¸ì ìœ¼ë¡œ XSS ë°©ì§€
  // ì¶”ê°€ ë³´ì•ˆì„ ìœ„í•œ Content Security Policy
  csp: {
    directives: {
      defaultSrc: ["'self'"],
      scriptSrc: ["'self'", "'unsafe-inline'"],
      styleSrc: ["'self'", "'unsafe-inline'"],
      imgSrc: ["'self'", "data:", "https:"],
      connectSrc: ["'self'", "https://api.momentum.app"],
      fontSrc: ["'self'"],
      objectSrc: ["'none'"],
      mediaSrc: ["'self'"],
      frameSrc: ["'none'"],
    },
  },
};

// 8. Insecure Deserialization ë°©ì§€
export const deserializationSecurity = {
  // JSON íŒŒì‹± ì „ ê²€ì¦
  safeJSONParse: (text: string, schema: z.ZodSchema): any => {
    try {
      const parsed = JSON.parse(text);
      return schema.parse(parsed);
    } catch (error) {
      throw new Error("Invalid JSON or schema validation failed");
    }
  },
};

// 9. Using Components with Known Vulnerabilities
// package.jsonì—ì„œ ì •ê¸°ì ì¸ ì˜ì¡´ì„± ì—…ë°ì´íŠ¸
// npm audit ì •ê¸° ì‹¤í–‰

// 10. Insufficient Logging & Monitoring
export const securityLogging = {
  logSecurityEvent: async (event: {
    type: string;
    userId?: string;
    ip?: string;
    details?: any;
  }) => {
    await supabase.from("security_logs").insert({
      event_type: event.type,
      user_id: event.userId,
      ip_address: event.ip,
      details: event.details,
      created_at: new Date().toISOString(),
    });

    // ì¤‘ìš” ì´ë²¤íŠ¸ëŠ” ì‹¤ì‹œê°„ ì•Œë¦¼
    if (
      ["failed_login", "suspicious_activity", "data_breach"].includes(
        event.type
      )
    ) {
      await alerts.sendAlert({
        level: "critical",
        title: `Security Event: ${event.type}`,
        message: `User: ${event.userId}, IP: ${event.ip}`,
        details: event.details,
      });
    }
  },
};
```

### 3.3 ë°ì´í„° ë³´í˜¸

#### ê°œì¸ì •ë³´ ë³´í˜¸

```typescript
// security/privacy.ts
export class PrivacyManager {
  /**
   * ê°œì¸ì •ë³´ ìµëª…í™”
   */
  static anonymizeUser(userData: any): any {
    return {
      ...userData,
      email: this.anonymizeEmail(userData.email),
      display_name: this.anonymizeName(userData.display_name),
      ip_address: this.anonymizeIP(userData.ip_address),
    };
  }

  private static anonymizeEmail(email: string): string {
    const [local, domain] = email.split("@");
    const anonymized = local.substring(0, 2) + "****";
    return `${anonymized}@${domain}`;
  }

  private static anonymizeName(name: string): string {
    if (name.length <= 2) return "**";
    return name[0] + "*".repeat(name.length - 2) + name[name.length - 1];
  }

  private static anonymizeIP(ip: string): string {
    const parts = ip.split(".");
    return `${parts[0]}.${parts[1]}.***.***`;
  }

  /**
   * GDPR ì¤€ìˆ˜ - ë°ì´í„° ë‚´ë³´ë‚´ê¸°
   */
  static async exportUserData(userId: string): Promise<any> {
    const tables = [
      "user_profiles",
      "user_keyword_preferences",
      "user_video_interactions",
      "search_sessions",
    ];

    const data: Record<string, any> = {};

    for (const table of tables) {
      const { data: tableData } = await supabase
        .from(table)
        .select("*")
        .eq("user_id", userId);

      data[table] = tableData;
    }

    return data;
  }

  /**
   * GDPR ì¤€ìˆ˜ - ë°ì´í„° ì‚­ì œ (ìŠí˜€ì§ˆ ê¶Œë¦¬)
   */
  static async deleteUserData(userId: string): Promise<void> {
    // íŠ¸ëœì­ì…˜ìœ¼ë¡œ ì²˜ë¦¬
    await supabase.rpc("delete_user_data", { p_user_id: userId });

    // ë¡œê·¸ ê¸°ë¡
    await securityLogging.logSecurityEvent({
      type: "user_data_deleted",
      userId,
      details: { reason: "GDPR request" },
    });
  }
}
```

#### ë°±ì—… ë° ë³µêµ¬

```bash
#!/bin/bash
# scripts/backup.sh

set -e

# ì„¤ì •
BACKUP_DIR="/backups"
S3_BUCKET="momentum-backups"
RETENTION_DAYS=30

# ë‚ ì§œ í¬ë§·
DATE=$(date +%Y%m%d_%H%M%S)

echo "Starting backup at $(date)"

# 1. ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—…
echo "Backing up database..."
pg_dump $DATABASE_URL \
  --no-owner \
  --no-privileges \
  --format=custom \
  --file="$BACKUP_DIR/db_$DATE.dump"

# 2. ë°±ì—… ì•”í˜¸í™”
echo "Encrypting backup..."
openssl enc -aes-256-cbc \
  -salt \
  -in "$BACKUP_DIR/db_$DATE.dump" \
  -out "$BACKUP_DIR/db_$DATE.dump.enc" \
  -pass env:BACKUP_ENCRYPTION_KEY

# 3. S3 ì—…ë¡œë“œ
echo "Uploading to S3..."
aws s3 cp "$BACKUP_DIR/db_$DATE.dump.enc" \
  "s3://$S3_BUCKET/daily/db_$DATE.dump.enc" \
  --storage-class STANDARD_IA

# 4. ë¡œì»¬ ë°±ì—… ì •ë¦¬
echo "Cleaning up local backups..."
find $BACKUP_DIR -name "*.dump" -mtime +7 -delete
find $BACKUP_DIR -name "*.dump.enc" -mtime +7 -delete

# 5. S3 ë°±ì—… ì •ë¦¬ (lifecycle policy ëŒ€ì‹  ìˆ˜ë™)
echo "Cleaning up old S3 backups..."
aws s3 ls "s3://$S3_BUCKET/daily/" | \
  while read -r line; do
    createDate=$(echo $line | awk '{print $1" "$2}')
    createDate=$(date -d "$createDate" +%s)
    olderThan=$(date -d "$RETENTION_DAYS days ago" +%s)
    if [[ $createDate -lt $olderThan ]]; then
      fileName=$(echo $line | awk '{print $4}')
      aws s3 rm "s3://$S3_BUCKET/daily/$fileName"
    fi
  done

echo "Backup completed at $(date)"

# ë³µêµ¬ ìŠ¤í¬ë¦½íŠ¸
cat > "$BACKUP_DIR/restore.sh" << 'EOF'
#!/bin/bash
# Usage: ./restore.sh backup_date

BACKUP_DATE=$1
if [ -z "$BACKUP_DATE" ]; then
    echo "Usage: ./restore.sh YYYYMMDD_HHMMSS"
    exit 1
fi

# S3ì—ì„œ ë‹¤ìš´ë¡œë“œ
aws s3 cp "s3://$S3_BUCKET/daily/db_$BACKUP_DATE.dump.enc" .

# ë³µí˜¸í™”
openssl enc -aes-256-cbc -d \
  -in "db_$BACKUP_DATE.dump.enc" \
  -out "db_$BACKUP_DATE.dump" \
  -pass env:BACKUP_ENCRYPTION_KEY

# ë³µêµ¬
pg_restore --clean --no-owner --no-privileges \
  -d $DATABASE_URL "db_$BACKUP_DATE.dump"

echo "Restore completed"
EOF

chmod +x "$BACKUP_DIR/restore.sh"
```

---

## 4. íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### 4.1 ì¼ë°˜ì ì¸ ë¬¸ì œ í•´ê²°

#### ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë¬¸ì œ

```typescript
// troubleshooting/database.ts
export class DatabaseTroubleshooter {
  /**
   * ì—°ê²° ë¬¸ì œ ì§„ë‹¨
   */
  static async diagnoseConnection(): Promise<{
    connected: boolean;
    latency?: number;
    error?: string;
    suggestions?: string[];
  }> {
    const start = Date.now();

    try {
      const { data, error } = await supabase
        .from("user_profiles")
        .select("count")
        .limit(1)
        .single();

      if (error) throw error;

      const latency = Date.now() - start;

      return {
        connected: true,
        latency,
        suggestions:
          latency > 1000
            ? [
                "High latency detected",
                "Check network connection",
                "Consider using connection pooling",
              ]
            : [],
      };
    } catch (error) {
      return {
        connected: false,
        error: error.message,
        suggestions: this.getConnectionSuggestions(error),
      };
    }
  }

  private static getConnectionSuggestions(error: any): string[] {
    const message = error.message.toLowerCase();

    if (message.includes("econnrefused")) {
      return [
        "Database server is not running",
        "Check Supabase dashboard status",
        "Verify SUPABASE_URL environment variable",
      ];
    }

    if (message.includes("auth")) {
      return [
        "Authentication failed",
        "Check SUPABASE_SERVICE_KEY",
        "Ensure service key has proper permissions",
      ];
    }

    if (message.includes("timeout")) {
      return [
        "Connection timeout",
        "Check network connectivity",
        "Increase connection timeout",
        "Check firewall rules",
      ];
    }

    return ["Unknown error", "Check logs for details"];
  }

  /**
   * ì¿¼ë¦¬ ì„±ëŠ¥ ë¶„ì„
   */
  static async analyzeQueryPerformance(query: string): Promise<any> {
    const { data, error } = await supabase.rpc("explain_analyze", {
      query_text: query,
    });

    if (error) throw error;

    return this.parseExplainOutput(data);
  }

  private static parseExplainOutput(output: string): any {
    // EXPLAIN ANALYZE ê²°ê³¼ íŒŒì‹±
    const lines = output.split("\n");
    const stats = {
      totalTime: 0,
      planning: 0,
      execution: 0,
      scans: [],
      suggestions: [],
    };

    // íŒŒì‹± ë¡œì§...

    return stats;
  }
}
```

#### API ì„±ëŠ¥ ë¬¸ì œ

```typescript
// troubleshooting/performance.ts
export class PerformanceTroubleshooter {
  /**
   * ë³‘ëª© ì§€ì  ì°¾ê¸°
   */
  static async findBottlenecks(): Promise<any> {
    const metrics = {
      database: await this.measureDatabasePerformance(),
      redis: await this.measureRedisPerformance(),
      api: await this.measureAPIPerformance(),
      memory: this.getMemoryUsage(),
      cpu: await this.getCPUUsage(),
    };

    return {
      metrics,
      bottlenecks: this.identifyBottlenecks(metrics),
      recommendations: this.getRecommendations(metrics),
    };
  }

  private static async measureDatabasePerformance(): Promise<any> {
    const queries = [
      "SELECT 1",
      "SELECT * FROM videos LIMIT 100",
      "SELECT * FROM user_profiles WHERE user_id = $1",
    ];

    const results = [];

    for (const query of queries) {
      const start = Date.now();
      await supabase.rpc("execute_query", { query });
      const duration = Date.now() - start;

      results.push({ query, duration });
    }

    return results;
  }

  private static identifyBottlenecks(metrics: any): string[] {
    const bottlenecks = [];

    // ë°ì´í„°ë² ì´ìŠ¤ ì²´í¬
    const slowQueries = metrics.database.filter((q) => q.duration > 100);
    if (slowQueries.length > 0) {
      bottlenecks.push("Slow database queries detected");
    }

    // ë©”ëª¨ë¦¬ ì²´í¬
    if (metrics.memory.percentage > 80) {
      bottlenecks.push("High memory usage");
    }

    // CPU ì²´í¬
    if (metrics.cpu.percentage > 70) {
      bottlenecks.push("High CPU usage");
    }

    return bottlenecks;
  }

  private static getMemoryUsage(): any {
    const used = process.memoryUsage();
    const total = os.totalmem();

    return {
      heapUsed: Math.round(used.heapUsed / 1024 / 1024),
      heapTotal: Math.round(used.heapTotal / 1024 / 1024),
      external: Math.round(used.external / 1024 / 1024),
      percentage: (used.heapUsed / total) * 100,
    };
  }
}
```

### 4.2 ì„±ëŠ¥ ìµœì í™”

#### ì¿¼ë¦¬ ìµœì í™”

```sql
-- ëŠë¦° ì¿¼ë¦¬ ì°¾ê¸°
CREATE OR REPLACE FUNCTION find_slow_queries()
RETURNS TABLE(
  query TEXT,
  calls BIGINT,
  total_time DOUBLE PRECISION,
  mean_time DOUBLE PRECISION,
  max_time DOUBLE PRECISION
) AS $$
BEGIN
  RETURN QUERY
  SELECT
    pg_stat_statements.query,
    pg_stat_statements.calls,
    pg_stat_statements.total_time,
    pg_stat_statements.mean_time,
    pg_stat_statements.max_time
  FROM pg_stat_statements
  WHERE pg_stat_statements.mean_time > 100 -- 100ms ì´ìƒ
  ORDER BY pg_stat_statements.mean_time DESC
  LIMIT 20;
END;
$$ LANGUAGE plpgsql;

-- ì¸ë±ìŠ¤ ì‚¬ìš© í˜„í™©
CREATE OR REPLACE FUNCTION check_index_usage()
RETURNS TABLE(
  tablename NAME,
  indexname NAME,
  index_size TEXT,
  idx_scan BIGINT,
  idx_tup_read BIGINT,
  idx_tup_fetch BIGINT
) AS $$
BEGIN
  RETURN QUERY
  SELECT
    t.tablename,
    i.indexname,
    pg_size_pretty(pg_relation_size(i.indexrelid)) as index_size,
    idx_scan,
    idx_tup_read,
    idx_tup_fetch
  FROM pg_stat_user_indexes i
  JOIN pg_tables t ON i.tablename = t.tablename
  WHERE i.idx_scan = 0 -- ì‚¬ìš©ë˜ì§€ ì•ŠëŠ” ì¸ë±ìŠ¤
    AND i.indexrelname NOT LIKE '%_pkey' -- ê¸°ë³¸ í‚¤ ì œì™¸
  ORDER BY pg_relation_size(i.indexrelid) DESC;
END;
$$ LANGUAGE plpgsql;

-- í…Œì´ë¸” í†µê³„ ì—…ë°ì´íŠ¸
VACUUM ANALYZE;
```

#### ìºì‹± ì „ëµ

```typescript
// performance/caching.ts
export class CacheOptimizer {
  /**
   * ìºì‹œ íˆíŠ¸ìœ¨ ë¶„ì„
   */
  static async analyzeCachePerformance(): Promise<any> {
    const info = await redis.info("stats");
    const stats = this.parseRedisInfo(info);

    const hitRate =
      stats.keyspace_hits / (stats.keyspace_hits + stats.keyspace_misses);

    return {
      hitRate: (hitRate * 100).toFixed(2) + "%",
      totalCommands: stats.total_commands_processed,
      connectedClients: stats.connected_clients,
      usedMemory: stats.used_memory_human,
      recommendations: this.getCacheRecommendations(hitRate),
    };
  }

  private static getCacheRecommendations(hitRate: number): string[] {
    const recommendations = [];

    if (hitRate < 0.8) {
      recommendations.push(
        "Low cache hit rate detected",
        "Consider increasing cache TTL",
        "Review cache key strategy",
        "Pre-warm cache for popular items"
      );
    }

    return recommendations;
  }

  /**
   * ìºì‹œ ì›Œë°
   */
  static async warmCache(): Promise<void> {
    // ì¸ê¸° ì˜ìƒ ìºì‹±
    const { data: popularVideos } = await supabase
      .from("videos")
      .select("*")
      .order("view_count", { ascending: false })
      .limit(100);

    for (const video of popularVideos || []) {
      await redis.setex(`video:${video.video_id}`, 3600, JSON.stringify(video));
    }

    // íŠ¸ë Œë“œ í‚¤ì›Œë“œ ìºì‹±
    const { data: trends } = await supabase
      .from("trend_keywords")
      .select("*")
      .eq("is_active", true);

    await redis.setex(
      "trends:active",
      900, // 15ë¶„
      JSON.stringify(trends)
    );
  }
}
```

### 4.3 ë””ë²„ê¹… ê°€ì´ë“œ

#### ë¡œê·¸ ë¶„ì„ ë„êµ¬

```typescript
// debugging/logAnalyzer.ts
export class LogAnalyzer {
  /**
   * ì—ëŸ¬ íŒ¨í„´ ë¶„ì„
   */
  static async analyzeErrors(timeRange: {
    start: Date;
    end: Date;
  }): Promise<any> {
    const logs = await this.fetchLogs(timeRange);

    const errorPatterns = {};
    const errorFrequency = {};

    for (const log of logs) {
      if (log.level === "error") {
        const pattern = this.extractErrorPattern(log.message);
        errorPatterns[pattern] = (errorPatterns[pattern] || 0) + 1;

        const hour = new Date(log.timestamp).getHours();
        errorFrequency[hour] = (errorFrequency[hour] || 0) + 1;
      }
    }

    return {
      topErrors: this.getTopErrors(errorPatterns),
      errorsByHour: errorFrequency,
      totalErrors: logs.filter((l) => l.level === "error").length,
      suggestions: this.getErrorSuggestions(errorPatterns),
    };
  }

  private static extractErrorPattern(message: string): string {
    // ì¼ë°˜ì ì¸ ì—ëŸ¬ íŒ¨í„´ ì¶”ì¶œ
    if (message.includes("ECONNREFUSED")) return "Connection Refused";
    if (message.includes("ETIMEDOUT")) return "Timeout";
    if (message.includes("PGRST")) return "Database Error";
    if (message.includes("rate limit")) return "Rate Limit";
    if (message.includes("memory")) return "Memory Error";
    return "Other";
  }

  /**
   * ìš”ì²­ ì¶”ì 
   */
  static async traceRequest(requestId: string): Promise<any> {
    const logs = await this.fetchLogs({ requestId });

    return {
      timeline: this.buildTimeline(logs),
      totalDuration: this.calculateDuration(logs),
      bottlenecks: this.identifySlowOperations(logs),
    };
  }

  private static buildTimeline(logs: any[]): any[] {
    return logs
      .sort((a, b) => a.timestamp - b.timestamp)
      .map((log, index) => ({
        step: index + 1,
        timestamp: log.timestamp,
        operation: log.operation,
        duration: log.duration,
        details: log.details,
      }));
  }
}
```

#### ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ

```typescript
// debugging/realtimeDashboard.ts
import { Server } from "socket.io";

export class RealtimeDashboard {
  private io: Server;

  constructor(server: any) {
    this.io = new Server(server);
    this.setupMetricsStream();
  }

  private setupMetricsStream() {
    setInterval(() => {
      const metrics = {
        timestamp: new Date(),
        requests: {
          total: httpRequestsTotal.get(),
          rate: this.calculateRate("requests"),
          errors: this.getErrorRate(),
        },
        performance: {
          responseTime: this.getAverageResponseTime(),
          activeConnections: activeConnections.get(),
        },
        system: {
          cpu: process.cpuUsage(),
          memory: process.memoryUsage(),
          uptime: process.uptime(),
        },
      };

      this.io.emit("metrics", metrics);
    }, 1000);
  }

  private calculateRate(metric: string): number {
    // ì§€ë‚œ 1ë¶„ê°„ì˜ rate ê³„ì‚°
    return 0; // êµ¬í˜„
  }
}
```

---

## 5. FAQ

### 5.1 ìì£¼ ë¬»ëŠ” ì§ˆë¬¸

#### Q1: API Rate Limitì— ê±¸ë ¸ì„ ë•Œ ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?

**A:** Rate Limitì€ ì„œë¹„ìŠ¤ ì•ˆì •ì„±ì„ ìœ„í•´ í•„ìš”í•©ë‹ˆë‹¤. ë‹¤ìŒ ë°©ë²•ë“¤ì„ ì‹œë„í•´ë³´ì„¸ìš”:

1. **ì¬ì‹œë„ ë¡œì§ êµ¬í˜„**

```typescript
async function retryWithBackoff(fn: Function, maxRetries = 3) {
  for (let i = 0; i < maxRetries; i++) {
    try {
      return await fn();
    } catch (error) {
      if (error.status === 429 && i < maxRetries - 1) {
        const delay = Math.pow(2, i) * 1000; // Exponential backoff
        await new Promise((resolve) => setTimeout(resolve, delay));
      } else {
        throw error;
      }
    }
  }
}
```

2. **ìš”ì²­ ë°°ì¹˜ ì²˜ë¦¬**
3. **ìºì‹± í™œìš©**
4. **Premium í‹°ì–´ ì—…ê·¸ë ˆì´ë“œ**

#### Q2: ì¶”ì²œ ì •í™•ë„ë¥¼ ì–´ë–»ê²Œ ê°œì„ í•  ìˆ˜ ìˆë‚˜ìš”?

**A:** ì¶”ì²œ ì •í™•ë„ ê°œì„  ë°©ë²•:

1. **ë” ë§ì€ ì‚¬ìš©ì ë°ì´í„° ìˆ˜ì§‘**

   - ìƒí˜¸ì‘ìš© ì¶”ì  ê°•í™”
   - í”¼ë“œë°± ì‹œìŠ¤í…œ êµ¬í˜„

2. **ì•Œê³ ë¦¬ì¦˜ ê°œì„ **

```sql
-- ì„ í˜¸ë„ ê°€ì¤‘ì¹˜ ì¡°ì •
UPDATE user_keyword_preferences
SET boost_factor =
  CASE
    WHEN interaction_score > 0.8 THEN 1.5
    WHEN interaction_score < 0.3 THEN 0.5
    ELSE 1.0
  END;
```

3. **A/B í…ŒìŠ¤íŠ¸**
4. **í˜‘ì—… í•„í„°ë§ ì¶”ê°€**

#### Q3: ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—…ì€ ì–¼ë§ˆë‚˜ ìì£¼ í•´ì•¼ í•˜ë‚˜ìš”?

**A:** ê¶Œì¥ ë°±ì—… ì£¼ê¸°:

- **ì¼ì¼ ë°±ì—…**: ì „ì²´ ë°ì´í„°ë² ì´ìŠ¤
- **ì‹œê°„ë³„ ë°±ì—…**: ì¤‘ìš” í…Œì´ë¸” (user_profiles, videos)
- **ì‹¤ì‹œê°„ ë³µì œ**: í¬ë¦¬í‹°ì»¬ ë°ì´í„°

```yaml
# ë°±ì—… ìŠ¤ì¼€ì¤„ ì˜ˆì‹œ
backup_schedule:
  full:
    frequency: daily
    time: "02:00"
    retention: 30_days

  incremental:
    frequency: hourly
    retention: 7_days

  transaction_logs:
    frequency: continuous
    retention: 3_days
```

#### Q4: YouTube API ì¿¼í„°ê°€ ë¶€ì¡±í•  ë•ŒëŠ”?

**A:** ì¿¼í„° ìµœì í™” ì „ëµ:

1. **íš¨ìœ¨ì ì¸ API ì‚¬ìš©**

```typescript
// ë°°ì¹˜ ìš”ì²­ìœ¼ë¡œ ì¿¼í„° ì ˆì•½
const batchRequest = {
  requests: videoIds.map((id) => ({
    method: "GET",
    url: `/videos?id=${id}&part=snippet,statistics`,
  })),
};
```

2. **ìºì‹± ê°•í™”**
3. **ë¶ˆí•„ìš”í•œ í˜¸ì¶œ ì œê±°**
4. **ì¿¼í„° ëª¨ë‹ˆí„°ë§ ë° ì•Œë¦¼**

#### Q5: ì„±ëŠ¥ì´ ëŠë ¤ì¡Œì„ ë•Œ ì²´í¬ë¦¬ìŠ¤íŠ¸?

**A:** ì„±ëŠ¥ ë¬¸ì œ í•´ê²° ì²´í¬ë¦¬ìŠ¤íŠ¸:

- [ ] ë°ì´í„°ë² ì´ìŠ¤ ì¸ë±ìŠ¤ í™•ì¸
- [ ] ëŠë¦° ì¿¼ë¦¬ ë¶„ì„
- [ ] ìºì‹œ íˆíŠ¸ìœ¨ í™•ì¸
- [ ] API ì‘ë‹µ ì‹œê°„ ì¸¡ì •
- [ ] ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
- [ ] ë„¤íŠ¸ì›Œí¬ ì§€ì—° í™•ì¸
- [ ] ì™¸ë¶€ API ìƒíƒœ í™•ì¸

### 5.2 ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤

#### ì½”ë“œ í’ˆì§ˆ

```typescript
// âœ… Good
export async function getVideoById(id: string): Promise<Video> {
  try {
    const cached = await redis.get(`video:${id}`);
    if (cached) return JSON.parse(cached);

    const video = await fetchVideoFromDB(id);
    await redis.setex(`video:${id}`, 3600, JSON.stringify(video));

    return video;
  } catch (error) {
    logger.error("Failed to get video", { id, error });
    throw new ApiError(500, "VIDEO_FETCH_ERROR", "Failed to fetch video");
  }
}

// âŒ Bad
export async function getVideo(id) {
  const video = await db.query(`SELECT * FROM videos WHERE id = ${id}`);
  return video;
}
```

#### ì—ëŸ¬ ì²˜ë¦¬

```typescript
// ê³„ì¸µë³„ ì—ëŸ¬ ì²˜ë¦¬
class ServiceError extends Error {
  constructor(
    public code: string,
    message: string,
    public statusCode: number = 500
  ) {
    super(message);
  }
}

// Service Layer
throw new ServiceError("VIDEO_NOT_FOUND", "Video not found", 404);

// Controller Layer
try {
  const result = await service.getVideo(id);
  res.json(result);
} catch (error) {
  if (error instanceof ServiceError) {
    res.status(error.statusCode).json({
      error: { code: error.code, message: error.message },
    });
  } else {
    next(error); // ì „ì—­ ì—ëŸ¬ í•¸ë“¤ëŸ¬ë¡œ
  }
}
```

#### í…ŒìŠ¤íŠ¸ ì „ëµ

```typescript
// ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
describe("VideoService", () => {
  it("should calculate quality score correctly", () => {
    const score = calculateQualityScore(1000000, 50000, 45);
    expect(score).toBeCloseTo(0.85, 2);
  });
});

// í†µí•© í…ŒìŠ¤íŠ¸
describe("Video API", () => {
  it("should return personalized recommendations", async () => {
    const response = await request(app)
      .get("/api/v1/recommendations")
      .set("Authorization", `Bearer ${token}`);

    expect(response.status).toBe(200);
    expect(response.body.data).toHaveLength(20);
  });
});

// E2E í…ŒìŠ¤íŠ¸
describe("User Flow", () => {
  it("should complete video discovery flow", async () => {
    // 1. ë¡œê·¸ì¸
    // 2. ê²€ìƒ‰
    // 3. ì˜ìƒ ì‹œì²­
    // 4. ìƒí˜¸ì‘ìš© ê¸°ë¡
    // 5. ì¶”ì²œ í™•ì¸
  });
});
```

---

## 6. ë§ˆë¬´ë¦¬

### 6.1 í”„ë¡œì íŠ¸ ì™„ì„±ë„ ì²´í¬ë¦¬ìŠ¤íŠ¸

#### ê¸°ëŠ¥ ì™„ì„±ë„

- [x] ì‚¬ìš©ì ì¸ì¦ ë° í”„ë¡œí•„ ê´€ë¦¬
- [x] YouTube ì˜ìƒ ê²€ìƒ‰ ë° ìˆ˜ì§‘
- [x] Claude API ì˜ìƒ ë¶„ë¥˜
- [x] ê°œì¸í™” ì¶”ì²œ ì‹œìŠ¤í…œ
- [x] ê°ì • ê¸°ë°˜ ì¶”ì²œ
- [x] ì‹¤ì‹œê°„ íŠ¸ë Œë“œ ë¶„ì„
- [x] ì‚¬ìš©ì í–‰ë™ ì¶”ì 
- [x] API Rate Limiting
- [x] ìºì‹± ì‹œìŠ¤í…œ
- [x] ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹…

#### ê¸°ìˆ ì  ì™„ì„±ë„

- [x] TypeScript íƒ€ì… ì•ˆì „ì„±
- [x] ì—ëŸ¬ ì²˜ë¦¬ ë° ë³µêµ¬
- [x] ë³´ì•ˆ (OWASP Top 10)
- [x] ì„±ëŠ¥ ìµœì í™”
- [x] í™•ì¥ ê°€ëŠ¥í•œ ì•„í‚¤í…ì²˜
- [x] CI/CD íŒŒì´í”„ë¼ì¸
- [x] ë¬¸ì„œí™”
- [x] í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ (>80%)

#### ìš´ì˜ ì¤€ë¹„ë„

- [x] í”„ë¡œë•ì…˜ ë°°í¬ ì„¤ì •
- [x] ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ
- [x] ì•Œë¦¼ ì‹œìŠ¤í…œ
- [x] ë°±ì—… ë° ë³µêµ¬
- [x] ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
- [x] ë³´ì•ˆ ê°ì‚¬
- [x] ì‚¬ìš©ì ë¬¸ì„œ

### 6.2 í–¥í›„ ë¡œë“œë§µ

#### Phase 1: ì•ˆì •í™” (1-2ê°œì›”)

- ë²„ê·¸ ìˆ˜ì • ë° ì„±ëŠ¥ ê°œì„ 
- ì‚¬ìš©ì í”¼ë“œë°± ë°˜ì˜
- ëª¨ë‹ˆí„°ë§ ê°•í™”

#### Phase 2: ê¸°ëŠ¥ í™•ì¥ (3-4ê°œì›”)

- ì‹¤ì‹œê°„ ì±„íŒ… ì¶”ì²œ
- ì†Œì…œ ê¸°ëŠ¥ ì¶”ê°€
- ë‹¤êµ­ì–´ ì§€ì›
- ëª¨ë°”ì¼ ì•± ê°œë°œ

#### Phase 3: AI ê³ ë„í™” (5-6ê°œì›”)

- ìì²´ ML ëª¨ë¸ ê°œë°œ
- ë²¡í„° ê²€ìƒ‰ ë„ì…
- ì‹¤ì‹œê°„ ê°œì¸í™”
- ì˜ˆì¸¡ ë¶„ì„

### 6.3 íŒ€ êµ¬ì„± ì œì•ˆ

```yaml
recommended_team:
  backend:
    - senior_engineer: 1
    - mid_engineer: 2
    - junior_engineer: 1

  frontend:
    - senior_engineer: 1
    - mid_engineer: 1

  devops:
    - devops_engineer: 1

  data:
    - data_scientist: 1
    - ml_engineer: 1

  product:
    - product_manager: 1
    - ui_ux_designer: 1
```

### 6.4 ì˜ˆìƒ ë¹„ìš©

```yaml
monthly_costs:
  infrastructure:
    supabase: $25-$599 # ì‚¬ìš©ëŸ‰ ê¸°ë°˜
    redis: $50-$200
    monitoring: $100-$300
    cdn: $50-$200

  apis:
    youtube: $0 # ë¬´ë£Œ ì¿¼í„° ë‚´
    claude: $200-$1000 # ì‚¬ìš©ëŸ‰ ê¸°ë°˜

  total_estimate: $425-$2,299/month
```

### 6.5 ì„±ê³µ ì§€í‘œ

```yaml
kpis:
  user_metrics:
    - dau: 10,000+
    - mau: 100,000+
    - retention_d7: >40%
    - retention_d30: >20%

  engagement_metrics:
    - avg_session_duration: >15min
    - videos_per_session: >5
    - ctr: >30%

  technical_metrics:
    - api_response_time: <100ms
    - uptime: >99.9%
    - error_rate: <0.1%

  business_metrics:
    - conversion_rate: >5%
    - premium_users: >10%
    - churn_rate: <10%
```

---

## ğŸ‰ í”„ë¡œì íŠ¸ ì™„ë£Œ

**Momentum YouTube AI íë ˆì´ì…˜ ì„œë¹„ìŠ¤**ì˜ ì „ì²´ êµ¬í˜„ ê°€ì´ë“œë¥¼ ì™„ì„±í–ˆìŠµë‹ˆë‹¤!

### êµ¬í˜„ëœ ë‚´ìš©:

- âœ… ì™„ì „í•œ ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ (16ê°œ í…Œì´ë¸”)
- âœ… 5ê°œ í•µì‹¬ ì„œë¹„ìŠ¤ êµ¬í˜„
- âœ… RESTful API ì„¤ê³„ ë° êµ¬í˜„
- âœ… ë³´ì•ˆ ë° ì„±ëŠ¥ ìµœì í™”
- âœ… ë°°í¬ ë° ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ
- âœ… íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ê°€ì´ë“œ

### ë‹¤ìŒ ë‹¨ê³„:

1. ì½”ë“œ ë¦¬ë·° ë° í…ŒìŠ¤íŠ¸
2. ìŠ¤í…Œì´ì§• í™˜ê²½ êµ¬ì¶•
3. ë² íƒ€ í…ŒìŠ¤íŠ¸
4. í”„ë¡œë•ì…˜ ë°°í¬
5. ì§€ì†ì ì¸ ê°œì„ 

**Wave Team**ì´ ë§Œë“  ì´ ì„œë¹„ìŠ¤ê°€ ë§ì€ ì‚¬ìš©ìë“¤ì—ê²Œ ê°€ì¹˜ë¥¼ ì œê³µí•˜ê¸¸ ë°”ëë‹ˆë‹¤! ğŸš€

---

## ğŸ“ ë¬¸ì˜ ë° ì§€ì›

- **ê¸°ìˆ  ì§€ì›**: tech@momentum.app
- **ë¹„ì¦ˆë‹ˆìŠ¤ ë¬¸ì˜**: business@momentum.app
- **ë²„ê·¸ ë¦¬í¬íŠ¸**: github.com/momentum/issues
- **ë¬¸ì„œ**: docs.momentum.app

**Happy Coding! ğŸ’»**
